{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Device Name: NVIDIA GeForce GTX 1050\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Memastikan penggunaan GPU jika tersedia\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Device Name:\", torch.cuda.get_device_name(0))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Setup Dataset ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "data = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "train_size = int(0.8 * len(data))\n",
    "val_size = len(data) - train_size\n",
    "train_data, val_data = random_split(data, [train_size, val_size])\n",
    "test_data = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, kernel_size=3, pooling='max'):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        if pooling == 'max':\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "        elif pooling == 'avg':\n",
    "            self.pool = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=kernel_size, padding=kernel_size//2)  # Ganti 3 dengan 1\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 256)  # Sesuaikan ukuran input\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)  # Sesuaikan ukuran flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with Early Stopping trigger\n",
    "def train_model(model, optimizer, criterion, scheduler, num_epochs=5, early_stopping_patience=10):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_loss = float('inf')\n",
    "    patience = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:  # Ganti trainloader dengan train_loader\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation loss\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:  # Ganti testloader dengan val_loader\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping trigger logic\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= early_stopping_patience:\n",
    "                print(\"Early stopping triggered due to no improvement in validation loss.\")\n",
    "                break\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: 3, Pooling: max, Optimizer: SGD, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 0.9474, Val Loss: 0.6012\n",
      "Epoch 2/5, Train Loss: 0.5423, Val Loss: 0.5234\n",
      "Epoch 3/5, Train Loss: 0.4672, Val Loss: 0.4503\n",
      "Epoch 4/5, Train Loss: 0.4191, Val Loss: 0.4072\n",
      "Epoch 5/5, Train Loss: 0.3884, Val Loss: 0.3802\n",
      "Kernel: 3, Pooling: max, Optimizer: SGD, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 1.0165, Val Loss: 0.6218\n",
      "Epoch 2/50, Train Loss: 0.5493, Val Loss: 0.5056\n",
      "Epoch 3/50, Train Loss: 0.4736, Val Loss: 0.4574\n",
      "Epoch 4/50, Train Loss: 0.4259, Val Loss: 0.4123\n",
      "Epoch 5/50, Train Loss: 0.3944, Val Loss: 0.3877\n",
      "Epoch 6/50, Train Loss: 0.3729, Val Loss: 0.3825\n",
      "Epoch 7/50, Train Loss: 0.3549, Val Loss: 0.3639\n",
      "Epoch 8/50, Train Loss: 0.3394, Val Loss: 0.3576\n",
      "Epoch 9/50, Train Loss: 0.3251, Val Loss: 0.3401\n",
      "Epoch 10/50, Train Loss: 0.3130, Val Loss: 0.3328\n",
      "Epoch 11/50, Train Loss: 0.3029, Val Loss: 0.3183\n",
      "Epoch 12/50, Train Loss: 0.2922, Val Loss: 0.3033\n",
      "Epoch 13/50, Train Loss: 0.2839, Val Loss: 0.3078\n",
      "Epoch 14/50, Train Loss: 0.2758, Val Loss: 0.3058\n",
      "Epoch 15/50, Train Loss: 0.2689, Val Loss: 0.2937\n",
      "Epoch 16/50, Train Loss: 0.2615, Val Loss: 0.2970\n",
      "Epoch 17/50, Train Loss: 0.2555, Val Loss: 0.2805\n",
      "Epoch 18/50, Train Loss: 0.2486, Val Loss: 0.2903\n",
      "Epoch 19/50, Train Loss: 0.2441, Val Loss: 0.2927\n",
      "Epoch 20/50, Train Loss: 0.2388, Val Loss: 0.2773\n",
      "Epoch 21/50, Train Loss: 0.2339, Val Loss: 0.2699\n",
      "Epoch 22/50, Train Loss: 0.2278, Val Loss: 0.2678\n",
      "Epoch 23/50, Train Loss: 0.2243, Val Loss: 0.2745\n",
      "Epoch 24/50, Train Loss: 0.2193, Val Loss: 0.2681\n",
      "Epoch 25/50, Train Loss: 0.2160, Val Loss: 0.2596\n",
      "Epoch 26/50, Train Loss: 0.2109, Val Loss: 0.2665\n",
      "Epoch 27/50, Train Loss: 0.2087, Val Loss: 0.2596\n",
      "Epoch 28/50, Train Loss: 0.2049, Val Loss: 0.2656\n",
      "Epoch 29/50, Train Loss: 0.1994, Val Loss: 0.2816\n",
      "Epoch 30/50, Train Loss: 0.1955, Val Loss: 0.2611\n",
      "Epoch 31/50, Train Loss: 0.1927, Val Loss: 0.2608\n",
      "Epoch 32/50, Train Loss: 0.1726, Val Loss: 0.2419\n",
      "Epoch 33/50, Train Loss: 0.1703, Val Loss: 0.2430\n",
      "Epoch 34/50, Train Loss: 0.1695, Val Loss: 0.2406\n",
      "Epoch 35/50, Train Loss: 0.1686, Val Loss: 0.2412\n",
      "Epoch 36/50, Train Loss: 0.1679, Val Loss: 0.2428\n",
      "Epoch 37/50, Train Loss: 0.1676, Val Loss: 0.2401\n",
      "Epoch 38/50, Train Loss: 0.1670, Val Loss: 0.2404\n",
      "Epoch 39/50, Train Loss: 0.1663, Val Loss: 0.2401\n",
      "Epoch 40/50, Train Loss: 0.1658, Val Loss: 0.2407\n",
      "Epoch 41/50, Train Loss: 0.1652, Val Loss: 0.2391\n",
      "Epoch 42/50, Train Loss: 0.1648, Val Loss: 0.2393\n",
      "Epoch 43/50, Train Loss: 0.1641, Val Loss: 0.2388\n",
      "Epoch 44/50, Train Loss: 0.1636, Val Loss: 0.2405\n",
      "Epoch 45/50, Train Loss: 0.1633, Val Loss: 0.2399\n",
      "Epoch 46/50, Train Loss: 0.1626, Val Loss: 0.2397\n",
      "Epoch 47/50, Train Loss: 0.1622, Val Loss: 0.2397\n",
      "Epoch 48/50, Train Loss: 0.1617, Val Loss: 0.2404\n",
      "Epoch 49/50, Train Loss: 0.1613, Val Loss: 0.2401\n",
      "Epoch 50/50, Train Loss: 0.1592, Val Loss: 0.2387\n",
      "Kernel: 3, Pooling: max, Optimizer: SGD, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 0.9820, Val Loss: 0.6739\n",
      "Epoch 2/100, Train Loss: 0.5352, Val Loss: 0.5301\n",
      "Epoch 3/100, Train Loss: 0.4635, Val Loss: 0.4405\n",
      "Epoch 4/100, Train Loss: 0.4196, Val Loss: 0.4170\n",
      "Epoch 5/100, Train Loss: 0.3909, Val Loss: 0.3892\n",
      "Epoch 6/100, Train Loss: 0.3688, Val Loss: 0.3733\n",
      "Epoch 7/100, Train Loss: 0.3518, Val Loss: 0.3799\n",
      "Epoch 8/100, Train Loss: 0.3368, Val Loss: 0.3458\n",
      "Epoch 9/100, Train Loss: 0.3250, Val Loss: 0.3454\n",
      "Epoch 10/100, Train Loss: 0.3147, Val Loss: 0.3278\n",
      "Epoch 11/100, Train Loss: 0.3048, Val Loss: 0.3267\n",
      "Epoch 12/100, Train Loss: 0.2954, Val Loss: 0.3140\n",
      "Epoch 13/100, Train Loss: 0.2872, Val Loss: 0.3156\n",
      "Epoch 14/100, Train Loss: 0.2796, Val Loss: 0.3082\n",
      "Epoch 15/100, Train Loss: 0.2731, Val Loss: 0.2974\n",
      "Epoch 16/100, Train Loss: 0.2672, Val Loss: 0.2998\n",
      "Epoch 17/100, Train Loss: 0.2607, Val Loss: 0.2865\n",
      "Epoch 18/100, Train Loss: 0.2545, Val Loss: 0.2856\n",
      "Epoch 19/100, Train Loss: 0.2494, Val Loss: 0.3058\n",
      "Epoch 20/100, Train Loss: 0.2445, Val Loss: 0.2851\n",
      "Epoch 21/100, Train Loss: 0.2394, Val Loss: 0.2754\n",
      "Epoch 22/100, Train Loss: 0.2353, Val Loss: 0.2784\n",
      "Epoch 23/100, Train Loss: 0.2302, Val Loss: 0.2655\n",
      "Epoch 24/100, Train Loss: 0.2256, Val Loss: 0.2766\n",
      "Epoch 25/100, Train Loss: 0.2205, Val Loss: 0.2770\n",
      "Epoch 26/100, Train Loss: 0.2161, Val Loss: 0.2729\n",
      "Epoch 27/100, Train Loss: 0.2121, Val Loss: 0.2850\n",
      "Epoch 28/100, Train Loss: 0.2096, Val Loss: 0.2674\n",
      "Epoch 29/100, Train Loss: 0.2037, Val Loss: 0.2572\n",
      "Epoch 30/100, Train Loss: 0.2014, Val Loss: 0.2594\n",
      "Epoch 31/100, Train Loss: 0.1967, Val Loss: 0.2607\n",
      "Epoch 32/100, Train Loss: 0.1931, Val Loss: 0.2616\n",
      "Epoch 33/100, Train Loss: 0.1894, Val Loss: 0.2567\n",
      "Epoch 34/100, Train Loss: 0.1867, Val Loss: 0.2522\n",
      "Epoch 35/100, Train Loss: 0.1831, Val Loss: 0.2456\n",
      "Epoch 36/100, Train Loss: 0.1800, Val Loss: 0.2673\n",
      "Epoch 37/100, Train Loss: 0.1755, Val Loss: 0.2552\n",
      "Epoch 38/100, Train Loss: 0.1736, Val Loss: 0.2551\n",
      "Epoch 39/100, Train Loss: 0.1706, Val Loss: 0.2521\n",
      "Epoch 40/100, Train Loss: 0.1670, Val Loss: 0.2561\n",
      "Epoch 41/100, Train Loss: 0.1636, Val Loss: 0.2514\n",
      "Epoch 42/100, Train Loss: 0.1426, Val Loss: 0.2387\n",
      "Epoch 43/100, Train Loss: 0.1402, Val Loss: 0.2389\n",
      "Epoch 44/100, Train Loss: 0.1393, Val Loss: 0.2388\n",
      "Epoch 45/100, Train Loss: 0.1386, Val Loss: 0.2373\n",
      "Epoch 46/100, Train Loss: 0.1381, Val Loss: 0.2391\n",
      "Epoch 47/100, Train Loss: 0.1375, Val Loss: 0.2383\n",
      "Epoch 48/100, Train Loss: 0.1368, Val Loss: 0.2400\n",
      "Epoch 49/100, Train Loss: 0.1362, Val Loss: 0.2381\n",
      "Epoch 50/100, Train Loss: 0.1359, Val Loss: 0.2398\n",
      "Epoch 51/100, Train Loss: 0.1355, Val Loss: 0.2382\n",
      "Epoch 52/100, Train Loss: 0.1332, Val Loss: 0.2378\n",
      "Epoch 53/100, Train Loss: 0.1330, Val Loss: 0.2378\n",
      "Epoch 54/100, Train Loss: 0.1329, Val Loss: 0.2377\n",
      "Epoch 55/100, Train Loss: 0.1329, Val Loss: 0.2379\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: max, Optimizer: SGD, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 0.9917, Val Loss: 0.6081\n",
      "Epoch 2/250, Train Loss: 0.5542, Val Loss: 0.5676\n",
      "Epoch 3/250, Train Loss: 0.4783, Val Loss: 0.4452\n",
      "Epoch 4/250, Train Loss: 0.4287, Val Loss: 0.4530\n",
      "Epoch 5/250, Train Loss: 0.3944, Val Loss: 0.4320\n",
      "Epoch 6/250, Train Loss: 0.3700, Val Loss: 0.3930\n",
      "Epoch 7/250, Train Loss: 0.3515, Val Loss: 0.3585\n",
      "Epoch 8/250, Train Loss: 0.3374, Val Loss: 0.3627\n",
      "Epoch 9/250, Train Loss: 0.3234, Val Loss: 0.3497\n",
      "Epoch 10/250, Train Loss: 0.3124, Val Loss: 0.3316\n",
      "Epoch 11/250, Train Loss: 0.3034, Val Loss: 0.3211\n",
      "Epoch 12/250, Train Loss: 0.2930, Val Loss: 0.3227\n",
      "Epoch 13/250, Train Loss: 0.2865, Val Loss: 0.3267\n",
      "Epoch 14/250, Train Loss: 0.2781, Val Loss: 0.3218\n",
      "Epoch 15/250, Train Loss: 0.2704, Val Loss: 0.3281\n",
      "Epoch 16/250, Train Loss: 0.2649, Val Loss: 0.2994\n",
      "Epoch 17/250, Train Loss: 0.2580, Val Loss: 0.3003\n",
      "Epoch 18/250, Train Loss: 0.2517, Val Loss: 0.2940\n",
      "Epoch 19/250, Train Loss: 0.2485, Val Loss: 0.2851\n",
      "Epoch 20/250, Train Loss: 0.2409, Val Loss: 0.2895\n",
      "Epoch 21/250, Train Loss: 0.2383, Val Loss: 0.2810\n",
      "Epoch 22/250, Train Loss: 0.2324, Val Loss: 0.2852\n",
      "Epoch 23/250, Train Loss: 0.2286, Val Loss: 0.2793\n",
      "Epoch 24/250, Train Loss: 0.2233, Val Loss: 0.2850\n",
      "Epoch 25/250, Train Loss: 0.2192, Val Loss: 0.2634\n",
      "Epoch 26/250, Train Loss: 0.2151, Val Loss: 0.2665\n",
      "Epoch 27/250, Train Loss: 0.2121, Val Loss: 0.2709\n",
      "Epoch 28/250, Train Loss: 0.2066, Val Loss: 0.2619\n",
      "Epoch 29/250, Train Loss: 0.2034, Val Loss: 0.2644\n",
      "Epoch 30/250, Train Loss: 0.2012, Val Loss: 0.2660\n",
      "Epoch 31/250, Train Loss: 0.1974, Val Loss: 0.2667\n",
      "Epoch 32/250, Train Loss: 0.1924, Val Loss: 0.2699\n",
      "Epoch 33/250, Train Loss: 0.1909, Val Loss: 0.2576\n",
      "Epoch 34/250, Train Loss: 0.1868, Val Loss: 0.2619\n",
      "Epoch 35/250, Train Loss: 0.1832, Val Loss: 0.2584\n",
      "Epoch 36/250, Train Loss: 0.1811, Val Loss: 0.2525\n",
      "Epoch 37/250, Train Loss: 0.1762, Val Loss: 0.2604\n",
      "Epoch 38/250, Train Loss: 0.1749, Val Loss: 0.2485\n",
      "Epoch 39/250, Train Loss: 0.1703, Val Loss: 0.2473\n",
      "Epoch 40/250, Train Loss: 0.1676, Val Loss: 0.2575\n",
      "Epoch 41/250, Train Loss: 0.1652, Val Loss: 0.2594\n",
      "Epoch 42/250, Train Loss: 0.1619, Val Loss: 0.2506\n",
      "Epoch 43/250, Train Loss: 0.1587, Val Loss: 0.2543\n",
      "Epoch 44/250, Train Loss: 0.1555, Val Loss: 0.2611\n",
      "Epoch 45/250, Train Loss: 0.1531, Val Loss: 0.2572\n",
      "Epoch 46/250, Train Loss: 0.1305, Val Loss: 0.2396\n",
      "Epoch 47/250, Train Loss: 0.1275, Val Loss: 0.2395\n",
      "Epoch 48/250, Train Loss: 0.1267, Val Loss: 0.2400\n",
      "Epoch 49/250, Train Loss: 0.1259, Val Loss: 0.2394\n",
      "Epoch 50/250, Train Loss: 0.1253, Val Loss: 0.2386\n",
      "Epoch 51/250, Train Loss: 0.1246, Val Loss: 0.2386\n",
      "Epoch 52/250, Train Loss: 0.1240, Val Loss: 0.2414\n",
      "Epoch 53/250, Train Loss: 0.1236, Val Loss: 0.2390\n",
      "Epoch 54/250, Train Loss: 0.1231, Val Loss: 0.2399\n",
      "Epoch 55/250, Train Loss: 0.1225, Val Loss: 0.2404\n",
      "Epoch 56/250, Train Loss: 0.1220, Val Loss: 0.2404\n",
      "Epoch 57/250, Train Loss: 0.1199, Val Loss: 0.2384\n",
      "Epoch 58/250, Train Loss: 0.1196, Val Loss: 0.2390\n",
      "Epoch 59/250, Train Loss: 0.1195, Val Loss: 0.2387\n",
      "Epoch 60/250, Train Loss: 0.1194, Val Loss: 0.2388\n",
      "Epoch 61/250, Train Loss: 0.1193, Val Loss: 0.2389\n",
      "Epoch 62/250, Train Loss: 0.1193, Val Loss: 0.2389\n",
      "Epoch 63/250, Train Loss: 0.1192, Val Loss: 0.2389\n",
      "Epoch 64/250, Train Loss: 0.1190, Val Loss: 0.2389\n",
      "Epoch 65/250, Train Loss: 0.1189, Val Loss: 0.2388\n",
      "Epoch 66/250, Train Loss: 0.1189, Val Loss: 0.2388\n",
      "Epoch 67/250, Train Loss: 0.1189, Val Loss: 0.2388\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: max, Optimizer: SGD, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 0.9547, Val Loss: 0.6128\n",
      "Epoch 2/350, Train Loss: 0.5529, Val Loss: 0.5201\n",
      "Epoch 3/350, Train Loss: 0.4776, Val Loss: 0.4569\n",
      "Epoch 4/350, Train Loss: 0.4285, Val Loss: 0.4198\n",
      "Epoch 5/350, Train Loss: 0.3969, Val Loss: 0.3961\n",
      "Epoch 6/350, Train Loss: 0.3722, Val Loss: 0.3957\n",
      "Epoch 7/350, Train Loss: 0.3541, Val Loss: 0.3532\n",
      "Epoch 8/350, Train Loss: 0.3392, Val Loss: 0.3465\n",
      "Epoch 9/350, Train Loss: 0.3261, Val Loss: 0.3496\n",
      "Epoch 10/350, Train Loss: 0.3160, Val Loss: 0.3425\n",
      "Epoch 11/350, Train Loss: 0.3045, Val Loss: 0.3325\n",
      "Epoch 12/350, Train Loss: 0.2964, Val Loss: 0.3123\n",
      "Epoch 13/350, Train Loss: 0.2872, Val Loss: 0.3107\n",
      "Epoch 14/350, Train Loss: 0.2810, Val Loss: 0.3065\n",
      "Epoch 15/350, Train Loss: 0.2727, Val Loss: 0.3083\n",
      "Epoch 16/350, Train Loss: 0.2668, Val Loss: 0.3456\n",
      "Epoch 17/350, Train Loss: 0.2614, Val Loss: 0.2944\n",
      "Epoch 18/350, Train Loss: 0.2551, Val Loss: 0.2884\n",
      "Epoch 19/350, Train Loss: 0.2491, Val Loss: 0.2850\n",
      "Epoch 20/350, Train Loss: 0.2436, Val Loss: 0.2919\n",
      "Epoch 21/350, Train Loss: 0.2382, Val Loss: 0.2877\n",
      "Epoch 22/350, Train Loss: 0.2347, Val Loss: 0.2735\n",
      "Epoch 23/350, Train Loss: 0.2296, Val Loss: 0.2903\n",
      "Epoch 24/350, Train Loss: 0.2247, Val Loss: 0.2599\n",
      "Epoch 25/350, Train Loss: 0.2203, Val Loss: 0.2691\n",
      "Epoch 26/350, Train Loss: 0.2170, Val Loss: 0.2716\n",
      "Epoch 27/350, Train Loss: 0.2125, Val Loss: 0.2659\n",
      "Epoch 28/350, Train Loss: 0.2069, Val Loss: 0.2609\n",
      "Epoch 29/350, Train Loss: 0.2059, Val Loss: 0.2646\n",
      "Epoch 30/350, Train Loss: 0.2009, Val Loss: 0.2747\n",
      "Epoch 31/350, Train Loss: 0.1796, Val Loss: 0.2472\n",
      "Epoch 32/350, Train Loss: 0.1775, Val Loss: 0.2482\n",
      "Epoch 33/350, Train Loss: 0.1765, Val Loss: 0.2472\n",
      "Epoch 34/350, Train Loss: 0.1759, Val Loss: 0.2462\n",
      "Epoch 35/350, Train Loss: 0.1753, Val Loss: 0.2482\n",
      "Epoch 36/350, Train Loss: 0.1745, Val Loss: 0.2482\n",
      "Epoch 37/350, Train Loss: 0.1738, Val Loss: 0.2467\n",
      "Epoch 38/350, Train Loss: 0.1735, Val Loss: 0.2465\n",
      "Epoch 39/350, Train Loss: 0.1728, Val Loss: 0.2465\n",
      "Epoch 40/350, Train Loss: 0.1725, Val Loss: 0.2461\n",
      "Epoch 41/350, Train Loss: 0.1716, Val Loss: 0.2476\n",
      "Epoch 42/350, Train Loss: 0.1711, Val Loss: 0.2456\n",
      "Epoch 43/350, Train Loss: 0.1704, Val Loss: 0.2462\n",
      "Epoch 44/350, Train Loss: 0.1700, Val Loss: 0.2469\n",
      "Epoch 45/350, Train Loss: 0.1697, Val Loss: 0.2457\n",
      "Epoch 46/350, Train Loss: 0.1691, Val Loss: 0.2463\n",
      "Epoch 47/350, Train Loss: 0.1685, Val Loss: 0.2450\n",
      "Epoch 48/350, Train Loss: 0.1679, Val Loss: 0.2462\n",
      "Epoch 49/350, Train Loss: 0.1674, Val Loss: 0.2467\n",
      "Epoch 50/350, Train Loss: 0.1668, Val Loss: 0.2476\n",
      "Epoch 51/350, Train Loss: 0.1664, Val Loss: 0.2449\n",
      "Epoch 52/350, Train Loss: 0.1659, Val Loss: 0.2453\n",
      "Epoch 53/350, Train Loss: 0.1655, Val Loss: 0.2458\n",
      "Epoch 54/350, Train Loss: 0.1648, Val Loss: 0.2458\n",
      "Epoch 55/350, Train Loss: 0.1644, Val Loss: 0.2470\n",
      "Epoch 56/350, Train Loss: 0.1639, Val Loss: 0.2455\n",
      "Epoch 57/350, Train Loss: 0.1633, Val Loss: 0.2467\n",
      "Epoch 58/350, Train Loss: 0.1610, Val Loss: 0.2446\n",
      "Epoch 59/350, Train Loss: 0.1608, Val Loss: 0.2446\n",
      "Epoch 60/350, Train Loss: 0.1606, Val Loss: 0.2446\n",
      "Epoch 61/350, Train Loss: 0.1606, Val Loss: 0.2443\n",
      "Epoch 62/350, Train Loss: 0.1605, Val Loss: 0.2441\n",
      "Epoch 63/350, Train Loss: 0.1605, Val Loss: 0.2444\n",
      "Epoch 64/350, Train Loss: 0.1604, Val Loss: 0.2442\n",
      "Epoch 65/350, Train Loss: 0.1603, Val Loss: 0.2444\n",
      "Epoch 66/350, Train Loss: 0.1603, Val Loss: 0.2444\n",
      "Epoch 67/350, Train Loss: 0.1602, Val Loss: 0.2443\n",
      "Epoch 68/350, Train Loss: 0.1602, Val Loss: 0.2442\n",
      "Epoch 69/350, Train Loss: 0.1599, Val Loss: 0.2442\n",
      "Epoch 70/350, Train Loss: 0.1598, Val Loss: 0.2442\n",
      "Epoch 71/350, Train Loss: 0.1598, Val Loss: 0.2442\n",
      "Epoch 72/350, Train Loss: 0.1598, Val Loss: 0.2442\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: max, Optimizer: RMSProp, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 4.0754, Val Loss: 0.4885\n",
      "Epoch 2/5, Train Loss: 0.4946, Val Loss: 0.4656\n",
      "Epoch 3/5, Train Loss: 0.5141, Val Loss: 0.4221\n",
      "Epoch 4/5, Train Loss: 0.3836, Val Loss: 0.4243\n",
      "Epoch 5/5, Train Loss: 0.3582, Val Loss: 0.3465\n",
      "Kernel: 3, Pooling: max, Optimizer: RMSProp, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 7.9846, Val Loss: 0.4813\n",
      "Epoch 2/50, Train Loss: 0.4523, Val Loss: 0.4508\n",
      "Epoch 3/50, Train Loss: 0.4427, Val Loss: 1.2143\n",
      "Epoch 4/50, Train Loss: 0.3818, Val Loss: 0.3891\n",
      "Epoch 5/50, Train Loss: 0.3408, Val Loss: 0.4673\n",
      "Epoch 6/50, Train Loss: 0.3296, Val Loss: 0.3815\n",
      "Epoch 7/50, Train Loss: 0.3115, Val Loss: 0.3527\n",
      "Epoch 8/50, Train Loss: 0.3081, Val Loss: 0.3783\n",
      "Epoch 9/50, Train Loss: 0.2935, Val Loss: 0.3708\n",
      "Epoch 10/50, Train Loss: 0.2886, Val Loss: 0.3609\n",
      "Epoch 11/50, Train Loss: 0.2813, Val Loss: 0.3552\n",
      "Epoch 12/50, Train Loss: 0.2792, Val Loss: 0.3472\n",
      "Epoch 13/50, Train Loss: 0.2771, Val Loss: 0.3426\n",
      "Epoch 14/50, Train Loss: 0.2687, Val Loss: 0.3733\n",
      "Epoch 15/50, Train Loss: 0.2656, Val Loss: 0.3914\n",
      "Epoch 16/50, Train Loss: 0.2701, Val Loss: 0.3855\n",
      "Epoch 17/50, Train Loss: 0.2641, Val Loss: 0.3610\n",
      "Epoch 18/50, Train Loss: 0.2572, Val Loss: 0.4177\n",
      "Epoch 19/50, Train Loss: 0.2554, Val Loss: 0.3922\n",
      "Epoch 20/50, Train Loss: 0.1789, Val Loss: 0.3690\n",
      "Epoch 21/50, Train Loss: 0.1586, Val Loss: 0.3726\n",
      "Epoch 22/50, Train Loss: 0.1500, Val Loss: 0.3774\n",
      "Epoch 23/50, Train Loss: 0.1439, Val Loss: 0.3968\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: max, Optimizer: RMSProp, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 4.5223, Val Loss: 0.4928\n",
      "Epoch 2/100, Train Loss: 0.4555, Val Loss: 0.4070\n",
      "Epoch 3/100, Train Loss: 0.3923, Val Loss: 0.4275\n",
      "Epoch 4/100, Train Loss: 0.3585, Val Loss: 0.3732\n",
      "Epoch 5/100, Train Loss: 0.3536, Val Loss: 0.4056\n",
      "Epoch 6/100, Train Loss: 0.3239, Val Loss: 0.3967\n",
      "Epoch 7/100, Train Loss: 0.3196, Val Loss: 0.3669\n",
      "Epoch 8/100, Train Loss: 0.3037, Val Loss: 0.3523\n",
      "Epoch 9/100, Train Loss: 0.2960, Val Loss: 0.3585\n",
      "Epoch 10/100, Train Loss: 0.2877, Val Loss: 0.3882\n",
      "Epoch 11/100, Train Loss: 0.2777, Val Loss: 0.3782\n",
      "Epoch 12/100, Train Loss: 0.2727, Val Loss: 0.3920\n",
      "Epoch 13/100, Train Loss: 0.2690, Val Loss: 0.3695\n",
      "Epoch 14/100, Train Loss: 0.2665, Val Loss: 0.3975\n",
      "Epoch 15/100, Train Loss: 0.1917, Val Loss: 0.3383\n",
      "Epoch 16/100, Train Loss: 0.1670, Val Loss: 0.3421\n",
      "Epoch 17/100, Train Loss: 0.1582, Val Loss: 0.3459\n",
      "Epoch 18/100, Train Loss: 0.1512, Val Loss: 0.3571\n",
      "Epoch 19/100, Train Loss: 0.1451, Val Loss: 0.3570\n",
      "Epoch 20/100, Train Loss: 0.1402, Val Loss: 0.3607\n",
      "Epoch 21/100, Train Loss: 0.1354, Val Loss: 0.3629\n",
      "Epoch 22/100, Train Loss: 0.1249, Val Loss: 0.3722\n",
      "Epoch 23/100, Train Loss: 0.1225, Val Loss: 0.3779\n",
      "Epoch 24/100, Train Loss: 0.1216, Val Loss: 0.3766\n",
      "Epoch 25/100, Train Loss: 0.1209, Val Loss: 0.3797\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: max, Optimizer: RMSProp, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 2.4389, Val Loss: 0.5229\n",
      "Epoch 2/250, Train Loss: 0.5053, Val Loss: 0.4507\n",
      "Epoch 3/250, Train Loss: 0.4448, Val Loss: 0.4470\n",
      "Epoch 4/250, Train Loss: 0.4286, Val Loss: 0.4364\n",
      "Epoch 5/250, Train Loss: 0.4121, Val Loss: 0.4244\n",
      "Epoch 6/250, Train Loss: 0.4441, Val Loss: 0.4435\n",
      "Epoch 7/250, Train Loss: 0.3988, Val Loss: 0.4453\n",
      "Epoch 8/250, Train Loss: 0.3870, Val Loss: 0.3953\n",
      "Epoch 9/250, Train Loss: 0.3791, Val Loss: 0.3839\n",
      "Epoch 10/250, Train Loss: 0.3670, Val Loss: 0.4267\n",
      "Epoch 11/250, Train Loss: 0.3640, Val Loss: 0.4225\n",
      "Epoch 12/250, Train Loss: 0.3694, Val Loss: 0.3781\n",
      "Epoch 13/250, Train Loss: 0.3421, Val Loss: 0.3757\n",
      "Epoch 14/250, Train Loss: 0.3439, Val Loss: 0.4156\n",
      "Epoch 15/250, Train Loss: 0.3352, Val Loss: 0.3856\n",
      "Epoch 16/250, Train Loss: 0.3376, Val Loss: 0.3923\n",
      "Epoch 17/250, Train Loss: 0.3232, Val Loss: 0.3952\n",
      "Epoch 18/250, Train Loss: 0.3272, Val Loss: 0.3908\n",
      "Epoch 19/250, Train Loss: 0.3203, Val Loss: 0.4112\n",
      "Epoch 20/250, Train Loss: 0.2470, Val Loss: 0.3303\n",
      "Epoch 21/250, Train Loss: 0.2284, Val Loss: 0.3249\n",
      "Epoch 22/250, Train Loss: 0.2215, Val Loss: 0.3302\n",
      "Epoch 23/250, Train Loss: 0.2173, Val Loss: 0.3258\n",
      "Epoch 24/250, Train Loss: 0.2136, Val Loss: 0.3306\n",
      "Epoch 25/250, Train Loss: 0.2098, Val Loss: 0.3311\n",
      "Epoch 26/250, Train Loss: 0.2070, Val Loss: 0.3382\n",
      "Epoch 27/250, Train Loss: 0.2039, Val Loss: 0.3357\n",
      "Epoch 28/250, Train Loss: 0.1943, Val Loss: 0.3366\n",
      "Epoch 29/250, Train Loss: 0.1930, Val Loss: 0.3364\n",
      "Epoch 30/250, Train Loss: 0.1920, Val Loss: 0.3373\n",
      "Epoch 31/250, Train Loss: 0.1915, Val Loss: 0.3378\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: max, Optimizer: RMSProp, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 3.9036, Val Loss: 0.6500\n",
      "Epoch 2/350, Train Loss: 0.4771, Val Loss: 0.4734\n",
      "Epoch 3/350, Train Loss: 0.4410, Val Loss: 0.4823\n",
      "Epoch 4/350, Train Loss: 0.4560, Val Loss: 0.4189\n",
      "Epoch 5/350, Train Loss: 0.4066, Val Loss: 0.3727\n",
      "Epoch 6/350, Train Loss: 0.3850, Val Loss: 0.3642\n",
      "Epoch 7/350, Train Loss: 0.4928, Val Loss: 0.3849\n",
      "Epoch 8/350, Train Loss: 0.3217, Val Loss: 0.3613\n",
      "Epoch 9/350, Train Loss: 0.3079, Val Loss: 0.4452\n",
      "Epoch 10/350, Train Loss: 0.2941, Val Loss: 0.3766\n",
      "Epoch 11/350, Train Loss: 0.2937, Val Loss: 0.3534\n",
      "Epoch 12/350, Train Loss: 0.3412, Val Loss: 0.3451\n",
      "Epoch 13/350, Train Loss: 0.2797, Val Loss: 0.3828\n",
      "Epoch 14/350, Train Loss: 0.2799, Val Loss: 0.3793\n",
      "Epoch 15/350, Train Loss: 0.2662, Val Loss: 0.3811\n",
      "Epoch 16/350, Train Loss: 0.2633, Val Loss: 0.4124\n",
      "Epoch 17/350, Train Loss: 0.2618, Val Loss: 0.3965\n",
      "Epoch 18/350, Train Loss: 0.2639, Val Loss: 0.3629\n",
      "Epoch 19/350, Train Loss: 0.1780, Val Loss: 0.3474\n",
      "Epoch 20/350, Train Loss: 0.1569, Val Loss: 0.3500\n",
      "Epoch 21/350, Train Loss: 0.1478, Val Loss: 0.3584\n",
      "Epoch 22/350, Train Loss: 0.1417, Val Loss: 0.3721\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: max, Optimizer: Adam, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 0.6139, Val Loss: 0.5815\n",
      "Epoch 2/5, Train Loss: 0.4695, Val Loss: 0.4663\n",
      "Epoch 3/5, Train Loss: 0.4369, Val Loss: 0.4835\n",
      "Epoch 4/5, Train Loss: 0.4220, Val Loss: 0.4299\n",
      "Epoch 5/5, Train Loss: 0.4096, Val Loss: 0.4377\n",
      "Kernel: 3, Pooling: max, Optimizer: Adam, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 0.4659, Val Loss: 0.3857\n",
      "Epoch 2/50, Train Loss: 0.3225, Val Loss: 0.3220\n",
      "Epoch 3/50, Train Loss: 0.2955, Val Loss: 0.3102\n",
      "Epoch 4/50, Train Loss: 0.2813, Val Loss: 0.3376\n",
      "Epoch 5/50, Train Loss: 0.2634, Val Loss: 0.3364\n",
      "Epoch 6/50, Train Loss: 0.2520, Val Loss: 0.3343\n",
      "Epoch 7/50, Train Loss: 0.2448, Val Loss: 0.3611\n",
      "Epoch 8/50, Train Loss: 0.2450, Val Loss: 0.3565\n",
      "Epoch 9/50, Train Loss: 0.2332, Val Loss: 0.3422\n",
      "Epoch 10/50, Train Loss: 0.1600, Val Loss: 0.2946\n",
      "Epoch 11/50, Train Loss: 0.1355, Val Loss: 0.2978\n",
      "Epoch 12/50, Train Loss: 0.1251, Val Loss: 0.3042\n",
      "Epoch 13/50, Train Loss: 0.1164, Val Loss: 0.3173\n",
      "Epoch 14/50, Train Loss: 0.1089, Val Loss: 0.3220\n",
      "Epoch 15/50, Train Loss: 0.1024, Val Loss: 0.3318\n",
      "Epoch 16/50, Train Loss: 0.0961, Val Loss: 0.3500\n",
      "Epoch 17/50, Train Loss: 0.0847, Val Loss: 0.3489\n",
      "Epoch 18/50, Train Loss: 0.0824, Val Loss: 0.3510\n",
      "Epoch 19/50, Train Loss: 0.0814, Val Loss: 0.3545\n",
      "Epoch 20/50, Train Loss: 0.0805, Val Loss: 0.3565\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: max, Optimizer: Adam, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 0.5190, Val Loss: 0.3897\n",
      "Epoch 2/100, Train Loss: 0.3729, Val Loss: 0.3813\n",
      "Epoch 3/100, Train Loss: 0.3458, Val Loss: 0.3531\n",
      "Epoch 4/100, Train Loss: 0.3269, Val Loss: 0.3495\n",
      "Epoch 5/100, Train Loss: 0.3134, Val Loss: 0.3643\n",
      "Epoch 6/100, Train Loss: 0.3056, Val Loss: 0.3688\n",
      "Epoch 7/100, Train Loss: 0.2974, Val Loss: 0.3424\n",
      "Epoch 8/100, Train Loss: 0.2933, Val Loss: 0.3832\n",
      "Epoch 9/100, Train Loss: 0.2900, Val Loss: 0.3360\n",
      "Epoch 10/100, Train Loss: 0.2820, Val Loss: 0.3405\n",
      "Epoch 11/100, Train Loss: 0.2789, Val Loss: 0.3658\n",
      "Epoch 12/100, Train Loss: 0.2722, Val Loss: 0.3337\n",
      "Epoch 13/100, Train Loss: 0.2724, Val Loss: 0.3559\n",
      "Epoch 14/100, Train Loss: 0.2670, Val Loss: 0.3593\n",
      "Epoch 15/100, Train Loss: 0.2652, Val Loss: 0.3637\n",
      "Epoch 16/100, Train Loss: 0.2621, Val Loss: 0.3543\n",
      "Epoch 17/100, Train Loss: 0.2641, Val Loss: 0.3657\n",
      "Epoch 18/100, Train Loss: 0.2536, Val Loss: 0.3688\n",
      "Epoch 19/100, Train Loss: 0.2021, Val Loss: 0.3297\n",
      "Epoch 20/100, Train Loss: 0.1850, Val Loss: 0.3348\n",
      "Epoch 21/100, Train Loss: 0.1776, Val Loss: 0.3445\n",
      "Epoch 22/100, Train Loss: 0.1723, Val Loss: 0.3446\n",
      "Epoch 23/100, Train Loss: 0.1676, Val Loss: 0.3422\n",
      "Epoch 24/100, Train Loss: 0.1640, Val Loss: 0.3555\n",
      "Epoch 25/100, Train Loss: 0.1605, Val Loss: 0.3582\n",
      "Epoch 26/100, Train Loss: 0.1518, Val Loss: 0.3575\n",
      "Epoch 27/100, Train Loss: 0.1502, Val Loss: 0.3586\n",
      "Epoch 28/100, Train Loss: 0.1494, Val Loss: 0.3613\n",
      "Epoch 29/100, Train Loss: 0.1489, Val Loss: 0.3623\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: max, Optimizer: Adam, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 0.4539, Val Loss: 0.3768\n",
      "Epoch 2/250, Train Loss: 0.3221, Val Loss: 0.3422\n",
      "Epoch 3/250, Train Loss: 0.2949, Val Loss: 0.3457\n",
      "Epoch 4/250, Train Loss: 0.2769, Val Loss: 0.3301\n",
      "Epoch 5/250, Train Loss: 0.2703, Val Loss: 0.3367\n",
      "Epoch 6/250, Train Loss: 0.2629, Val Loss: 0.3190\n",
      "Epoch 7/250, Train Loss: 0.2518, Val Loss: 0.3380\n",
      "Epoch 8/250, Train Loss: 0.2403, Val Loss: 0.3675\n",
      "Epoch 9/250, Train Loss: 0.2449, Val Loss: 0.3738\n",
      "Epoch 10/250, Train Loss: 0.2393, Val Loss: 0.3902\n",
      "Epoch 11/250, Train Loss: 0.2353, Val Loss: 0.3723\n",
      "Epoch 12/250, Train Loss: 0.2184, Val Loss: 0.3549\n",
      "Epoch 13/250, Train Loss: 0.1519, Val Loss: 0.3313\n",
      "Epoch 14/250, Train Loss: 0.1298, Val Loss: 0.3314\n",
      "Epoch 15/250, Train Loss: 0.1199, Val Loss: 0.3441\n",
      "Epoch 16/250, Train Loss: 0.1120, Val Loss: 0.3535\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: max, Optimizer: Adam, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 0.5353, Val Loss: 0.4511\n",
      "Epoch 2/350, Train Loss: 0.3944, Val Loss: 0.3885\n",
      "Epoch 3/350, Train Loss: 0.3720, Val Loss: 0.3825\n",
      "Epoch 4/350, Train Loss: 0.3534, Val Loss: 0.3779\n",
      "Epoch 5/350, Train Loss: 0.3414, Val Loss: 0.3720\n",
      "Epoch 6/350, Train Loss: 0.3266, Val Loss: 0.3536\n",
      "Epoch 7/350, Train Loss: 0.3239, Val Loss: 0.3530\n",
      "Epoch 8/350, Train Loss: 0.3108, Val Loss: 0.3580\n",
      "Epoch 9/350, Train Loss: 0.3014, Val Loss: 0.3552\n",
      "Epoch 10/350, Train Loss: 0.2964, Val Loss: 0.3672\n",
      "Epoch 11/350, Train Loss: 0.2935, Val Loss: 0.3335\n",
      "Epoch 12/350, Train Loss: 0.2893, Val Loss: 0.3525\n",
      "Epoch 13/350, Train Loss: 0.2857, Val Loss: 0.3510\n",
      "Epoch 14/350, Train Loss: 0.2811, Val Loss: 0.3654\n",
      "Epoch 15/350, Train Loss: 0.2769, Val Loss: 0.3791\n",
      "Epoch 16/350, Train Loss: 0.2725, Val Loss: 0.3580\n",
      "Epoch 17/350, Train Loss: 0.2647, Val Loss: 0.3805\n",
      "Epoch 18/350, Train Loss: 0.2034, Val Loss: 0.3164\n",
      "Epoch 19/350, Train Loss: 0.1832, Val Loss: 0.3183\n",
      "Epoch 20/350, Train Loss: 0.1758, Val Loss: 0.3183\n",
      "Epoch 21/350, Train Loss: 0.1704, Val Loss: 0.3223\n",
      "Epoch 22/350, Train Loss: 0.1657, Val Loss: 0.3225\n",
      "Epoch 23/350, Train Loss: 0.1616, Val Loss: 0.3258\n",
      "Epoch 24/350, Train Loss: 0.1575, Val Loss: 0.3292\n",
      "Epoch 25/350, Train Loss: 0.1475, Val Loss: 0.3290\n",
      "Epoch 26/350, Train Loss: 0.1459, Val Loss: 0.3309\n",
      "Epoch 27/350, Train Loss: 0.1453, Val Loss: 0.3303\n",
      "Epoch 28/350, Train Loss: 0.1446, Val Loss: 0.3320\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: avg, Optimizer: SGD, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 1.1670, Val Loss: 0.7873\n",
      "Epoch 2/5, Train Loss: 0.6341, Val Loss: 0.6001\n",
      "Epoch 3/5, Train Loss: 0.5706, Val Loss: 0.5547\n",
      "Epoch 4/5, Train Loss: 0.5316, Val Loss: 0.5312\n",
      "Epoch 5/5, Train Loss: 0.4950, Val Loss: 0.4927\n",
      "Kernel: 3, Pooling: avg, Optimizer: SGD, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 1.2390, Val Loss: 0.7113\n",
      "Epoch 2/50, Train Loss: 0.6388, Val Loss: 0.6597\n",
      "Epoch 3/50, Train Loss: 0.5692, Val Loss: 0.5854\n",
      "Epoch 4/50, Train Loss: 0.5263, Val Loss: 0.6496\n",
      "Epoch 5/50, Train Loss: 0.4937, Val Loss: 0.5071\n",
      "Epoch 6/50, Train Loss: 0.4673, Val Loss: 0.4632\n",
      "Epoch 7/50, Train Loss: 0.4462, Val Loss: 0.4676\n",
      "Epoch 8/50, Train Loss: 0.4300, Val Loss: 0.4318\n",
      "Epoch 9/50, Train Loss: 0.4164, Val Loss: 0.4390\n",
      "Epoch 10/50, Train Loss: 0.4018, Val Loss: 0.4161\n",
      "Epoch 11/50, Train Loss: 0.3924, Val Loss: 0.4186\n",
      "Epoch 12/50, Train Loss: 0.3818, Val Loss: 0.3877\n",
      "Epoch 13/50, Train Loss: 0.3733, Val Loss: 0.3997\n",
      "Epoch 14/50, Train Loss: 0.3647, Val Loss: 0.3955\n",
      "Epoch 15/50, Train Loss: 0.3576, Val Loss: 0.3848\n",
      "Epoch 16/50, Train Loss: 0.3506, Val Loss: 0.3769\n",
      "Epoch 17/50, Train Loss: 0.3445, Val Loss: 0.3683\n",
      "Epoch 18/50, Train Loss: 0.3389, Val Loss: 0.3597\n",
      "Epoch 19/50, Train Loss: 0.3315, Val Loss: 0.3654\n",
      "Epoch 20/50, Train Loss: 0.3268, Val Loss: 0.3625\n",
      "Epoch 21/50, Train Loss: 0.3218, Val Loss: 0.3492\n",
      "Epoch 22/50, Train Loss: 0.3165, Val Loss: 0.3501\n",
      "Epoch 23/50, Train Loss: 0.3122, Val Loss: 0.3360\n",
      "Epoch 24/50, Train Loss: 0.3073, Val Loss: 0.3338\n",
      "Epoch 25/50, Train Loss: 0.3023, Val Loss: 0.3410\n",
      "Epoch 26/50, Train Loss: 0.3001, Val Loss: 0.3456\n",
      "Epoch 27/50, Train Loss: 0.2944, Val Loss: 0.3326\n",
      "Epoch 28/50, Train Loss: 0.2905, Val Loss: 0.3307\n",
      "Epoch 29/50, Train Loss: 0.2865, Val Loss: 0.3607\n",
      "Epoch 30/50, Train Loss: 0.2836, Val Loss: 0.3256\n",
      "Epoch 31/50, Train Loss: 0.2803, Val Loss: 0.3305\n",
      "Epoch 32/50, Train Loss: 0.2763, Val Loss: 0.3179\n",
      "Epoch 33/50, Train Loss: 0.2728, Val Loss: 0.3101\n",
      "Epoch 34/50, Train Loss: 0.2691, Val Loss: 0.3186\n",
      "Epoch 35/50, Train Loss: 0.2662, Val Loss: 0.3065\n",
      "Epoch 36/50, Train Loss: 0.2631, Val Loss: 0.3018\n",
      "Epoch 37/50, Train Loss: 0.2599, Val Loss: 0.3178\n",
      "Epoch 38/50, Train Loss: 0.2571, Val Loss: 0.3087\n",
      "Epoch 39/50, Train Loss: 0.2548, Val Loss: 0.3084\n",
      "Epoch 40/50, Train Loss: 0.2524, Val Loss: 0.3067\n",
      "Epoch 41/50, Train Loss: 0.2491, Val Loss: 0.2960\n",
      "Epoch 42/50, Train Loss: 0.2464, Val Loss: 0.3061\n",
      "Epoch 43/50, Train Loss: 0.2431, Val Loss: 0.2952\n",
      "Epoch 44/50, Train Loss: 0.2401, Val Loss: 0.3245\n",
      "Epoch 45/50, Train Loss: 0.2381, Val Loss: 0.3188\n",
      "Epoch 46/50, Train Loss: 0.2366, Val Loss: 0.2884\n",
      "Epoch 47/50, Train Loss: 0.2323, Val Loss: 0.2987\n",
      "Epoch 48/50, Train Loss: 0.2309, Val Loss: 0.2996\n",
      "Epoch 49/50, Train Loss: 0.2297, Val Loss: 0.2862\n",
      "Epoch 50/50, Train Loss: 0.2272, Val Loss: 0.2824\n",
      "Kernel: 3, Pooling: avg, Optimizer: SGD, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 1.1320, Val Loss: 0.6787\n",
      "Epoch 2/100, Train Loss: 0.6238, Val Loss: 0.5819\n",
      "Epoch 3/100, Train Loss: 0.5654, Val Loss: 0.5504\n",
      "Epoch 4/100, Train Loss: 0.5230, Val Loss: 0.5088\n",
      "Epoch 5/100, Train Loss: 0.4922, Val Loss: 0.5352\n",
      "Epoch 6/100, Train Loss: 0.4663, Val Loss: 0.4657\n",
      "Epoch 7/100, Train Loss: 0.4455, Val Loss: 0.4475\n",
      "Epoch 8/100, Train Loss: 0.4285, Val Loss: 0.4477\n",
      "Epoch 9/100, Train Loss: 0.4146, Val Loss: 0.4131\n",
      "Epoch 10/100, Train Loss: 0.4038, Val Loss: 0.4124\n",
      "Epoch 11/100, Train Loss: 0.3923, Val Loss: 0.4101\n",
      "Epoch 12/100, Train Loss: 0.3832, Val Loss: 0.3884\n",
      "Epoch 13/100, Train Loss: 0.3746, Val Loss: 0.3895\n",
      "Epoch 14/100, Train Loss: 0.3645, Val Loss: 0.3864\n",
      "Epoch 15/100, Train Loss: 0.3568, Val Loss: 0.3828\n",
      "Epoch 16/100, Train Loss: 0.3497, Val Loss: 0.3634\n",
      "Epoch 17/100, Train Loss: 0.3430, Val Loss: 0.3731\n",
      "Epoch 18/100, Train Loss: 0.3374, Val Loss: 0.3619\n",
      "Epoch 19/100, Train Loss: 0.3317, Val Loss: 0.3615\n",
      "Epoch 20/100, Train Loss: 0.3258, Val Loss: 0.3863\n",
      "Epoch 21/100, Train Loss: 0.3213, Val Loss: 0.3509\n",
      "Epoch 22/100, Train Loss: 0.3153, Val Loss: 0.3363\n",
      "Epoch 23/100, Train Loss: 0.3101, Val Loss: 0.3424\n",
      "Epoch 24/100, Train Loss: 0.3059, Val Loss: 0.3451\n",
      "Epoch 25/100, Train Loss: 0.3002, Val Loss: 0.3313\n",
      "Epoch 26/100, Train Loss: 0.2981, Val Loss: 0.3233\n",
      "Epoch 27/100, Train Loss: 0.2942, Val Loss: 0.3216\n",
      "Epoch 28/100, Train Loss: 0.2912, Val Loss: 0.3241\n",
      "Epoch 29/100, Train Loss: 0.2864, Val Loss: 0.3126\n",
      "Epoch 30/100, Train Loss: 0.2841, Val Loss: 0.3175\n",
      "Epoch 31/100, Train Loss: 0.2801, Val Loss: 0.3251\n",
      "Epoch 32/100, Train Loss: 0.2767, Val Loss: 0.3114\n",
      "Epoch 33/100, Train Loss: 0.2725, Val Loss: 0.3263\n",
      "Epoch 34/100, Train Loss: 0.2707, Val Loss: 0.3305\n",
      "Epoch 35/100, Train Loss: 0.2680, Val Loss: 0.3095\n",
      "Epoch 36/100, Train Loss: 0.2646, Val Loss: 0.3007\n",
      "Epoch 37/100, Train Loss: 0.2611, Val Loss: 0.3038\n",
      "Epoch 38/100, Train Loss: 0.2602, Val Loss: 0.3019\n",
      "Epoch 39/100, Train Loss: 0.2568, Val Loss: 0.3002\n",
      "Epoch 40/100, Train Loss: 0.2547, Val Loss: 0.3243\n",
      "Epoch 41/100, Train Loss: 0.2516, Val Loss: 0.2989\n",
      "Epoch 42/100, Train Loss: 0.2498, Val Loss: 0.2902\n",
      "Epoch 43/100, Train Loss: 0.2462, Val Loss: 0.2964\n",
      "Epoch 44/100, Train Loss: 0.2441, Val Loss: 0.2946\n",
      "Epoch 45/100, Train Loss: 0.2414, Val Loss: 0.2984\n",
      "Epoch 46/100, Train Loss: 0.2395, Val Loss: 0.2864\n",
      "Epoch 47/100, Train Loss: 0.2364, Val Loss: 0.3038\n",
      "Epoch 48/100, Train Loss: 0.2342, Val Loss: 0.2937\n",
      "Epoch 49/100, Train Loss: 0.2319, Val Loss: 0.2803\n",
      "Epoch 50/100, Train Loss: 0.2304, Val Loss: 0.2941\n",
      "Epoch 51/100, Train Loss: 0.2279, Val Loss: 0.2826\n",
      "Epoch 52/100, Train Loss: 0.2255, Val Loss: 0.2802\n",
      "Epoch 53/100, Train Loss: 0.2233, Val Loss: 0.2852\n",
      "Epoch 54/100, Train Loss: 0.2208, Val Loss: 0.2809\n",
      "Epoch 55/100, Train Loss: 0.2202, Val Loss: 0.2744\n",
      "Epoch 56/100, Train Loss: 0.2181, Val Loss: 0.2861\n",
      "Epoch 57/100, Train Loss: 0.2146, Val Loss: 0.3031\n",
      "Epoch 58/100, Train Loss: 0.2133, Val Loss: 0.2780\n",
      "Epoch 59/100, Train Loss: 0.2117, Val Loss: 0.2820\n",
      "Epoch 60/100, Train Loss: 0.2103, Val Loss: 0.2755\n",
      "Epoch 61/100, Train Loss: 0.2080, Val Loss: 0.2779\n",
      "Epoch 62/100, Train Loss: 0.1875, Val Loss: 0.2626\n",
      "Epoch 63/100, Train Loss: 0.1850, Val Loss: 0.2647\n",
      "Epoch 64/100, Train Loss: 0.1844, Val Loss: 0.2631\n",
      "Epoch 65/100, Train Loss: 0.1839, Val Loss: 0.2645\n",
      "Epoch 66/100, Train Loss: 0.1835, Val Loss: 0.2637\n",
      "Epoch 67/100, Train Loss: 0.1829, Val Loss: 0.2632\n",
      "Epoch 68/100, Train Loss: 0.1825, Val Loss: 0.2623\n",
      "Epoch 69/100, Train Loss: 0.1820, Val Loss: 0.2661\n",
      "Epoch 70/100, Train Loss: 0.1818, Val Loss: 0.2664\n",
      "Epoch 71/100, Train Loss: 0.1813, Val Loss: 0.2643\n",
      "Epoch 72/100, Train Loss: 0.1811, Val Loss: 0.2644\n",
      "Epoch 73/100, Train Loss: 0.1807, Val Loss: 0.2643\n",
      "Epoch 74/100, Train Loss: 0.1803, Val Loss: 0.2631\n",
      "Epoch 75/100, Train Loss: 0.1781, Val Loss: 0.2630\n",
      "Epoch 76/100, Train Loss: 0.1779, Val Loss: 0.2630\n",
      "Epoch 77/100, Train Loss: 0.1778, Val Loss: 0.2631\n",
      "Epoch 78/100, Train Loss: 0.1777, Val Loss: 0.2630\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: avg, Optimizer: SGD, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 1.1137, Val Loss: 0.6714\n",
      "Epoch 2/250, Train Loss: 0.6180, Val Loss: 0.5825\n",
      "Epoch 3/250, Train Loss: 0.5590, Val Loss: 0.5422\n",
      "Epoch 4/250, Train Loss: 0.5159, Val Loss: 0.5575\n",
      "Epoch 5/250, Train Loss: 0.4838, Val Loss: 0.4983\n",
      "Epoch 6/250, Train Loss: 0.4602, Val Loss: 0.4511\n",
      "Epoch 7/250, Train Loss: 0.4386, Val Loss: 0.4576\n",
      "Epoch 8/250, Train Loss: 0.4230, Val Loss: 0.4560\n",
      "Epoch 9/250, Train Loss: 0.4095, Val Loss: 0.4263\n",
      "Epoch 10/250, Train Loss: 0.3980, Val Loss: 0.4009\n",
      "Epoch 11/250, Train Loss: 0.3885, Val Loss: 0.4101\n",
      "Epoch 12/250, Train Loss: 0.3773, Val Loss: 0.4003\n",
      "Epoch 13/250, Train Loss: 0.3688, Val Loss: 0.4179\n",
      "Epoch 14/250, Train Loss: 0.3607, Val Loss: 0.3839\n",
      "Epoch 15/250, Train Loss: 0.3536, Val Loss: 0.3648\n",
      "Epoch 16/250, Train Loss: 0.3450, Val Loss: 0.3608\n",
      "Epoch 17/250, Train Loss: 0.3394, Val Loss: 0.3600\n",
      "Epoch 18/250, Train Loss: 0.3323, Val Loss: 0.3716\n",
      "Epoch 19/250, Train Loss: 0.3275, Val Loss: 0.3556\n",
      "Epoch 20/250, Train Loss: 0.3209, Val Loss: 0.3500\n",
      "Epoch 21/250, Train Loss: 0.3160, Val Loss: 0.3410\n",
      "Epoch 22/250, Train Loss: 0.3116, Val Loss: 0.3371\n",
      "Epoch 23/250, Train Loss: 0.3065, Val Loss: 0.3319\n",
      "Epoch 24/250, Train Loss: 0.3016, Val Loss: 0.3294\n",
      "Epoch 25/250, Train Loss: 0.2982, Val Loss: 0.3242\n",
      "Epoch 26/250, Train Loss: 0.2941, Val Loss: 0.3254\n",
      "Epoch 27/250, Train Loss: 0.2899, Val Loss: 0.3226\n",
      "Epoch 28/250, Train Loss: 0.2858, Val Loss: 0.3273\n",
      "Epoch 29/250, Train Loss: 0.2824, Val Loss: 0.3128\n",
      "Epoch 30/250, Train Loss: 0.2796, Val Loss: 0.3195\n",
      "Epoch 31/250, Train Loss: 0.2751, Val Loss: 0.3118\n",
      "Epoch 32/250, Train Loss: 0.2731, Val Loss: 0.3202\n",
      "Epoch 33/250, Train Loss: 0.2681, Val Loss: 0.3063\n",
      "Epoch 34/250, Train Loss: 0.2663, Val Loss: 0.3146\n",
      "Epoch 35/250, Train Loss: 0.2624, Val Loss: 0.3028\n",
      "Epoch 36/250, Train Loss: 0.2603, Val Loss: 0.2992\n",
      "Epoch 37/250, Train Loss: 0.2574, Val Loss: 0.3007\n",
      "Epoch 38/250, Train Loss: 0.2528, Val Loss: 0.2972\n",
      "Epoch 39/250, Train Loss: 0.2505, Val Loss: 0.3017\n",
      "Epoch 40/250, Train Loss: 0.2482, Val Loss: 0.2917\n",
      "Epoch 41/250, Train Loss: 0.2456, Val Loss: 0.2941\n",
      "Epoch 42/250, Train Loss: 0.2416, Val Loss: 0.2968\n",
      "Epoch 43/250, Train Loss: 0.2404, Val Loss: 0.2928\n",
      "Epoch 44/250, Train Loss: 0.2378, Val Loss: 0.2967\n",
      "Epoch 45/250, Train Loss: 0.2360, Val Loss: 0.2978\n",
      "Epoch 46/250, Train Loss: 0.2329, Val Loss: 0.3000\n",
      "Epoch 47/250, Train Loss: 0.2132, Val Loss: 0.2740\n",
      "Epoch 48/250, Train Loss: 0.2109, Val Loss: 0.2755\n",
      "Epoch 49/250, Train Loss: 0.2104, Val Loss: 0.2728\n",
      "Epoch 50/250, Train Loss: 0.2098, Val Loss: 0.2746\n",
      "Epoch 51/250, Train Loss: 0.2093, Val Loss: 0.2733\n",
      "Epoch 52/250, Train Loss: 0.2087, Val Loss: 0.2728\n",
      "Epoch 53/250, Train Loss: 0.2084, Val Loss: 0.2731\n",
      "Epoch 54/250, Train Loss: 0.2079, Val Loss: 0.2731\n",
      "Epoch 55/250, Train Loss: 0.2075, Val Loss: 0.2738\n",
      "Epoch 56/250, Train Loss: 0.2054, Val Loss: 0.2733\n",
      "Epoch 57/250, Train Loss: 0.2052, Val Loss: 0.2730\n",
      "Epoch 58/250, Train Loss: 0.2051, Val Loss: 0.2727\n",
      "Epoch 59/250, Train Loss: 0.2050, Val Loss: 0.2729\n",
      "Epoch 60/250, Train Loss: 0.2050, Val Loss: 0.2729\n",
      "Epoch 61/250, Train Loss: 0.2049, Val Loss: 0.2727\n",
      "Epoch 62/250, Train Loss: 0.2048, Val Loss: 0.2727\n",
      "Epoch 63/250, Train Loss: 0.2048, Val Loss: 0.2727\n",
      "Epoch 64/250, Train Loss: 0.2047, Val Loss: 0.2727\n",
      "Epoch 65/250, Train Loss: 0.2047, Val Loss: 0.2727\n",
      "Epoch 66/250, Train Loss: 0.2047, Val Loss: 0.2726\n",
      "Epoch 67/250, Train Loss: 0.2046, Val Loss: 0.2727\n",
      "Epoch 68/250, Train Loss: 0.2046, Val Loss: 0.2726\n",
      "Epoch 69/250, Train Loss: 0.2045, Val Loss: 0.2727\n",
      "Epoch 70/250, Train Loss: 0.2045, Val Loss: 0.2727\n",
      "Epoch 71/250, Train Loss: 0.2044, Val Loss: 0.2728\n",
      "Epoch 72/250, Train Loss: 0.2044, Val Loss: 0.2726\n",
      "Epoch 73/250, Train Loss: 0.2044, Val Loss: 0.2728\n",
      "Epoch 74/250, Train Loss: 0.2043, Val Loss: 0.2727\n",
      "Epoch 75/250, Train Loss: 0.2041, Val Loss: 0.2727\n",
      "Epoch 76/250, Train Loss: 0.2040, Val Loss: 0.2727\n",
      "Epoch 77/250, Train Loss: 0.2040, Val Loss: 0.2726\n",
      "Epoch 78/250, Train Loss: 0.2040, Val Loss: 0.2726\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: avg, Optimizer: SGD, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 1.1157, Val Loss: 0.6849\n",
      "Epoch 2/350, Train Loss: 0.6282, Val Loss: 0.5914\n",
      "Epoch 3/350, Train Loss: 0.5675, Val Loss: 0.5903\n",
      "Epoch 4/350, Train Loss: 0.5294, Val Loss: 0.5134\n",
      "Epoch 5/350, Train Loss: 0.4982, Val Loss: 0.5202\n",
      "Epoch 6/350, Train Loss: 0.4724, Val Loss: 0.4917\n",
      "Epoch 7/350, Train Loss: 0.4521, Val Loss: 0.4913\n",
      "Epoch 8/350, Train Loss: 0.4346, Val Loss: 0.4448\n",
      "Epoch 9/350, Train Loss: 0.4196, Val Loss: 0.4471\n",
      "Epoch 10/350, Train Loss: 0.4063, Val Loss: 0.4341\n",
      "Epoch 11/350, Train Loss: 0.3934, Val Loss: 0.4440\n",
      "Epoch 12/350, Train Loss: 0.3838, Val Loss: 0.3997\n",
      "Epoch 13/350, Train Loss: 0.3752, Val Loss: 0.4377\n",
      "Epoch 14/350, Train Loss: 0.3665, Val Loss: 0.3803\n",
      "Epoch 15/350, Train Loss: 0.3589, Val Loss: 0.3946\n",
      "Epoch 16/350, Train Loss: 0.3522, Val Loss: 0.4004\n",
      "Epoch 17/350, Train Loss: 0.3452, Val Loss: 0.3669\n",
      "Epoch 18/350, Train Loss: 0.3376, Val Loss: 0.3770\n",
      "Epoch 19/350, Train Loss: 0.3330, Val Loss: 0.3596\n",
      "Epoch 20/350, Train Loss: 0.3274, Val Loss: 0.3566\n",
      "Epoch 21/350, Train Loss: 0.3216, Val Loss: 0.3631\n",
      "Epoch 22/350, Train Loss: 0.3167, Val Loss: 0.3366\n",
      "Epoch 23/350, Train Loss: 0.3122, Val Loss: 0.3737\n",
      "Epoch 24/350, Train Loss: 0.3074, Val Loss: 0.3371\n",
      "Epoch 25/350, Train Loss: 0.3024, Val Loss: 0.3341\n",
      "Epoch 26/350, Train Loss: 0.2998, Val Loss: 0.3439\n",
      "Epoch 27/350, Train Loss: 0.2948, Val Loss: 0.3445\n",
      "Epoch 28/350, Train Loss: 0.2916, Val Loss: 0.3336\n",
      "Epoch 29/350, Train Loss: 0.2879, Val Loss: 0.3213\n",
      "Epoch 30/350, Train Loss: 0.2845, Val Loss: 0.3151\n",
      "Epoch 31/350, Train Loss: 0.2815, Val Loss: 0.3219\n",
      "Epoch 32/350, Train Loss: 0.2775, Val Loss: 0.3136\n",
      "Epoch 33/350, Train Loss: 0.2749, Val Loss: 0.3158\n",
      "Epoch 34/350, Train Loss: 0.2719, Val Loss: 0.3042\n",
      "Epoch 35/350, Train Loss: 0.2679, Val Loss: 0.3005\n",
      "Epoch 36/350, Train Loss: 0.2651, Val Loss: 0.3091\n",
      "Epoch 37/350, Train Loss: 0.2628, Val Loss: 0.3003\n",
      "Epoch 38/350, Train Loss: 0.2586, Val Loss: 0.3090\n",
      "Epoch 39/350, Train Loss: 0.2565, Val Loss: 0.3109\n",
      "Epoch 40/350, Train Loss: 0.2540, Val Loss: 0.2940\n",
      "Epoch 41/350, Train Loss: 0.2518, Val Loss: 0.2945\n",
      "Epoch 42/350, Train Loss: 0.2489, Val Loss: 0.3088\n",
      "Epoch 43/350, Train Loss: 0.2466, Val Loss: 0.2955\n",
      "Epoch 44/350, Train Loss: 0.2438, Val Loss: 0.3101\n",
      "Epoch 45/350, Train Loss: 0.2409, Val Loss: 0.2995\n",
      "Epoch 46/350, Train Loss: 0.2382, Val Loss: 0.2958\n",
      "Epoch 47/350, Train Loss: 0.2195, Val Loss: 0.2758\n",
      "Epoch 48/350, Train Loss: 0.2168, Val Loss: 0.2762\n",
      "Epoch 49/350, Train Loss: 0.2158, Val Loss: 0.2751\n",
      "Epoch 50/350, Train Loss: 0.2154, Val Loss: 0.2762\n",
      "Epoch 51/350, Train Loss: 0.2149, Val Loss: 0.2756\n",
      "Epoch 52/350, Train Loss: 0.2144, Val Loss: 0.2752\n",
      "Epoch 53/350, Train Loss: 0.2141, Val Loss: 0.2756\n",
      "Epoch 54/350, Train Loss: 0.2136, Val Loss: 0.2757\n",
      "Epoch 55/350, Train Loss: 0.2133, Val Loss: 0.2746\n",
      "Epoch 56/350, Train Loss: 0.2129, Val Loss: 0.2746\n",
      "Epoch 57/350, Train Loss: 0.2124, Val Loss: 0.2752\n",
      "Epoch 58/350, Train Loss: 0.2120, Val Loss: 0.2741\n",
      "Epoch 59/350, Train Loss: 0.2118, Val Loss: 0.2751\n",
      "Epoch 60/350, Train Loss: 0.2114, Val Loss: 0.2750\n",
      "Epoch 61/350, Train Loss: 0.2109, Val Loss: 0.2753\n",
      "Epoch 62/350, Train Loss: 0.2104, Val Loss: 0.2747\n",
      "Epoch 63/350, Train Loss: 0.2103, Val Loss: 0.2737\n",
      "Epoch 64/350, Train Loss: 0.2097, Val Loss: 0.2739\n",
      "Epoch 65/350, Train Loss: 0.2097, Val Loss: 0.2746\n",
      "Epoch 66/350, Train Loss: 0.2092, Val Loss: 0.2757\n",
      "Epoch 67/350, Train Loss: 0.2087, Val Loss: 0.2742\n",
      "Epoch 68/350, Train Loss: 0.2083, Val Loss: 0.2749\n",
      "Epoch 69/350, Train Loss: 0.2082, Val Loss: 0.2746\n",
      "Epoch 70/350, Train Loss: 0.2059, Val Loss: 0.2732\n",
      "Epoch 71/350, Train Loss: 0.2055, Val Loss: 0.2734\n",
      "Epoch 72/350, Train Loss: 0.2055, Val Loss: 0.2732\n",
      "Epoch 73/350, Train Loss: 0.2054, Val Loss: 0.2730\n",
      "Epoch 74/350, Train Loss: 0.2053, Val Loss: 0.2732\n",
      "Epoch 75/350, Train Loss: 0.2053, Val Loss: 0.2733\n",
      "Epoch 76/350, Train Loss: 0.2052, Val Loss: 0.2730\n",
      "Epoch 77/350, Train Loss: 0.2052, Val Loss: 0.2733\n",
      "Epoch 78/350, Train Loss: 0.2052, Val Loss: 0.2731\n",
      "Epoch 79/350, Train Loss: 0.2051, Val Loss: 0.2730\n",
      "Epoch 80/350, Train Loss: 0.2048, Val Loss: 0.2730\n",
      "Epoch 81/350, Train Loss: 0.2048, Val Loss: 0.2730\n",
      "Epoch 82/350, Train Loss: 0.2048, Val Loss: 0.2730\n",
      "Epoch 83/350, Train Loss: 0.2048, Val Loss: 0.2730\n",
      "Epoch 84/350, Train Loss: 0.2048, Val Loss: 0.2730\n",
      "Epoch 85/350, Train Loss: 0.2048, Val Loss: 0.2730\n",
      "Epoch 86/350, Train Loss: 0.2047, Val Loss: 0.2730\n",
      "Epoch 87/350, Train Loss: 0.2047, Val Loss: 0.2730\n",
      "Epoch 88/350, Train Loss: 0.2047, Val Loss: 0.2730\n",
      "Epoch 89/350, Train Loss: 0.2047, Val Loss: 0.2730\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: avg, Optimizer: RMSProp, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 4.4652, Val Loss: 0.4107\n",
      "Epoch 2/5, Train Loss: 0.4644, Val Loss: 0.3925\n",
      "Epoch 3/5, Train Loss: 0.3349, Val Loss: 0.3261\n",
      "Epoch 4/5, Train Loss: 0.3497, Val Loss: 0.3820\n",
      "Epoch 5/5, Train Loss: 0.2824, Val Loss: 0.3358\n",
      "Kernel: 3, Pooling: avg, Optimizer: RMSProp, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 1.7789, Val Loss: 0.4457\n",
      "Epoch 2/50, Train Loss: 0.5224, Val Loss: 0.3906\n",
      "Epoch 3/50, Train Loss: 0.3428, Val Loss: 0.3609\n",
      "Epoch 4/50, Train Loss: 0.3162, Val Loss: 0.3279\n",
      "Epoch 5/50, Train Loss: 0.2799, Val Loss: 0.3313\n",
      "Epoch 6/50, Train Loss: 0.2636, Val Loss: 0.3349\n",
      "Epoch 7/50, Train Loss: 0.2698, Val Loss: 0.3355\n",
      "Epoch 8/50, Train Loss: 0.2400, Val Loss: 0.3379\n",
      "Epoch 9/50, Train Loss: 0.2272, Val Loss: 0.3310\n",
      "Epoch 10/50, Train Loss: 0.2186, Val Loss: 0.3297\n",
      "Epoch 11/50, Train Loss: 0.1491, Val Loss: 0.2911\n",
      "Epoch 12/50, Train Loss: 0.1344, Val Loss: 0.3044\n",
      "Epoch 13/50, Train Loss: 0.1262, Val Loss: 0.3072\n",
      "Epoch 14/50, Train Loss: 0.1191, Val Loss: 0.3118\n",
      "Epoch 15/50, Train Loss: 0.1141, Val Loss: 0.3185\n",
      "Epoch 16/50, Train Loss: 0.1085, Val Loss: 0.3215\n",
      "Epoch 17/50, Train Loss: 0.1037, Val Loss: 0.3354\n",
      "Epoch 18/50, Train Loss: 0.0933, Val Loss: 0.3367\n",
      "Epoch 19/50, Train Loss: 0.0917, Val Loss: 0.3398\n",
      "Epoch 20/50, Train Loss: 0.0910, Val Loss: 0.3413\n",
      "Epoch 21/50, Train Loss: 0.0903, Val Loss: 0.3430\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: avg, Optimizer: RMSProp, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 5.0242, Val Loss: 0.5907\n",
      "Epoch 2/100, Train Loss: 0.4895, Val Loss: 0.4092\n",
      "Epoch 3/100, Train Loss: 0.5520, Val Loss: 0.4125\n",
      "Epoch 4/100, Train Loss: 0.3750, Val Loss: 0.3737\n",
      "Epoch 5/100, Train Loss: 0.3390, Val Loss: 0.3157\n",
      "Epoch 6/100, Train Loss: 0.3061, Val Loss: 0.3019\n",
      "Epoch 7/100, Train Loss: 0.2869, Val Loss: 0.3661\n",
      "Epoch 8/100, Train Loss: 0.2769, Val Loss: 0.3261\n",
      "Epoch 9/100, Train Loss: 0.2481, Val Loss: 0.3301\n",
      "Epoch 10/100, Train Loss: 0.2366, Val Loss: 0.3129\n",
      "Epoch 11/100, Train Loss: 0.2356, Val Loss: 0.3030\n",
      "Epoch 12/100, Train Loss: 0.2174, Val Loss: 0.3119\n",
      "Epoch 13/100, Train Loss: 0.1472, Val Loss: 0.2940\n",
      "Epoch 14/100, Train Loss: 0.1323, Val Loss: 0.2986\n",
      "Epoch 15/100, Train Loss: 0.1246, Val Loss: 0.3135\n",
      "Epoch 16/100, Train Loss: 0.1192, Val Loss: 0.3061\n",
      "Epoch 17/100, Train Loss: 0.1141, Val Loss: 0.3124\n",
      "Epoch 18/100, Train Loss: 0.1097, Val Loss: 0.3220\n",
      "Epoch 19/100, Train Loss: 0.1046, Val Loss: 0.3257\n",
      "Epoch 20/100, Train Loss: 0.0952, Val Loss: 0.3303\n",
      "Epoch 21/100, Train Loss: 0.0935, Val Loss: 0.3320\n",
      "Epoch 22/100, Train Loss: 0.0928, Val Loss: 0.3347\n",
      "Epoch 23/100, Train Loss: 0.0922, Val Loss: 0.3322\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: avg, Optimizer: RMSProp, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 3.4447, Val Loss: 0.4656\n",
      "Epoch 2/250, Train Loss: 0.4602, Val Loss: 0.3890\n",
      "Epoch 3/250, Train Loss: 0.3968, Val Loss: 0.3690\n",
      "Epoch 4/250, Train Loss: 0.3073, Val Loss: 0.3362\n",
      "Epoch 5/250, Train Loss: 0.3140, Val Loss: 0.2993\n",
      "Epoch 6/250, Train Loss: 0.2923, Val Loss: 0.3041\n",
      "Epoch 7/250, Train Loss: 0.2469, Val Loss: 0.3208\n",
      "Epoch 8/250, Train Loss: 0.2369, Val Loss: 0.3152\n",
      "Epoch 9/250, Train Loss: 0.2243, Val Loss: 0.3093\n",
      "Epoch 10/250, Train Loss: 0.2388, Val Loss: 0.3158\n",
      "Epoch 11/250, Train Loss: 0.2078, Val Loss: 0.3377\n",
      "Epoch 12/250, Train Loss: 0.1392, Val Loss: 0.2861\n",
      "Epoch 13/250, Train Loss: 0.1224, Val Loss: 0.2895\n",
      "Epoch 14/250, Train Loss: 0.1144, Val Loss: 0.2963\n",
      "Epoch 15/250, Train Loss: 0.1084, Val Loss: 0.3012\n",
      "Epoch 16/250, Train Loss: 0.1029, Val Loss: 0.3105\n",
      "Epoch 17/250, Train Loss: 0.0979, Val Loss: 0.3239\n",
      "Epoch 18/250, Train Loss: 0.0928, Val Loss: 0.3303\n",
      "Epoch 19/250, Train Loss: 0.0833, Val Loss: 0.3305\n",
      "Epoch 20/250, Train Loss: 0.0818, Val Loss: 0.3327\n",
      "Epoch 21/250, Train Loss: 0.0810, Val Loss: 0.3346\n",
      "Epoch 22/250, Train Loss: 0.0804, Val Loss: 0.3356\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: avg, Optimizer: RMSProp, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 2.7067, Val Loss: 0.6502\n",
      "Epoch 2/350, Train Loss: 0.4306, Val Loss: 0.3652\n",
      "Epoch 3/350, Train Loss: 0.4468, Val Loss: 0.3795\n",
      "Epoch 4/350, Train Loss: 0.3316, Val Loss: 0.3270\n",
      "Epoch 5/350, Train Loss: 0.3008, Val Loss: 0.3301\n",
      "Epoch 6/350, Train Loss: 0.2885, Val Loss: 0.3359\n",
      "Epoch 7/350, Train Loss: 0.2613, Val Loss: 0.3054\n",
      "Epoch 8/350, Train Loss: 0.2492, Val Loss: 0.3020\n",
      "Epoch 9/350, Train Loss: 0.2358, Val Loss: 0.3237\n",
      "Epoch 10/350, Train Loss: 0.2249, Val Loss: 0.3162\n",
      "Epoch 11/350, Train Loss: 0.2175, Val Loss: 0.3450\n",
      "Epoch 12/350, Train Loss: 0.2092, Val Loss: 0.3261\n",
      "Epoch 13/350, Train Loss: 0.2060, Val Loss: 0.3448\n",
      "Epoch 14/350, Train Loss: 0.2189, Val Loss: 0.3375\n",
      "Epoch 15/350, Train Loss: 0.1358, Val Loss: 0.3235\n",
      "Epoch 16/350, Train Loss: 0.1184, Val Loss: 0.3315\n",
      "Epoch 17/350, Train Loss: 0.1113, Val Loss: 0.3387\n",
      "Epoch 18/350, Train Loss: 0.1061, Val Loss: 0.3472\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: avg, Optimizer: Adam, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 0.4786, Val Loss: 0.3818\n",
      "Epoch 2/5, Train Loss: 0.3338, Val Loss: 0.3473\n",
      "Epoch 3/5, Train Loss: 0.2994, Val Loss: 0.3187\n",
      "Epoch 4/5, Train Loss: 0.2886, Val Loss: 0.3190\n",
      "Epoch 5/5, Train Loss: 0.2659, Val Loss: 0.3341\n",
      "Kernel: 3, Pooling: avg, Optimizer: Adam, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 0.4881, Val Loss: 0.3626\n",
      "Epoch 2/50, Train Loss: 0.3179, Val Loss: 0.3203\n",
      "Epoch 3/50, Train Loss: 0.2804, Val Loss: 0.3047\n",
      "Epoch 4/50, Train Loss: 0.2520, Val Loss: 0.2936\n",
      "Epoch 5/50, Train Loss: 0.2372, Val Loss: 0.2961\n",
      "Epoch 6/50, Train Loss: 0.2241, Val Loss: 0.3056\n",
      "Epoch 7/50, Train Loss: 0.2131, Val Loss: 0.3010\n",
      "Epoch 8/50, Train Loss: 0.2048, Val Loss: 0.3093\n",
      "Epoch 9/50, Train Loss: 0.2030, Val Loss: 0.2928\n",
      "Epoch 10/50, Train Loss: 0.1886, Val Loss: 0.3541\n",
      "Epoch 11/50, Train Loss: 0.1811, Val Loss: 0.3308\n",
      "Epoch 12/50, Train Loss: 0.1805, Val Loss: 0.3353\n",
      "Epoch 13/50, Train Loss: 0.1687, Val Loss: 0.4051\n",
      "Epoch 14/50, Train Loss: 0.1718, Val Loss: 0.3611\n",
      "Epoch 15/50, Train Loss: 0.1616, Val Loss: 0.3679\n",
      "Epoch 16/50, Train Loss: 0.1043, Val Loss: 0.3519\n",
      "Epoch 17/50, Train Loss: 0.0852, Val Loss: 0.3632\n",
      "Epoch 18/50, Train Loss: 0.0772, Val Loss: 0.3796\n",
      "Epoch 19/50, Train Loss: 0.0714, Val Loss: 0.3903\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: avg, Optimizer: Adam, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 0.5849, Val Loss: 0.4485\n",
      "Epoch 2/100, Train Loss: 0.4200, Val Loss: 0.4152\n",
      "Epoch 3/100, Train Loss: 0.3873, Val Loss: 0.3836\n",
      "Epoch 4/100, Train Loss: 0.3677, Val Loss: 0.3958\n",
      "Epoch 5/100, Train Loss: 0.3532, Val Loss: 0.3713\n",
      "Epoch 6/100, Train Loss: 0.3512, Val Loss: 0.3773\n",
      "Epoch 7/100, Train Loss: 0.3413, Val Loss: 0.3688\n",
      "Epoch 8/100, Train Loss: 0.3309, Val Loss: 0.3726\n",
      "Epoch 9/100, Train Loss: 0.3272, Val Loss: 0.3850\n",
      "Epoch 10/100, Train Loss: 0.3200, Val Loss: 0.3667\n",
      "Epoch 11/100, Train Loss: 0.3208, Val Loss: 0.3593\n",
      "Epoch 12/100, Train Loss: 0.3107, Val Loss: 0.3613\n",
      "Epoch 13/100, Train Loss: 0.3097, Val Loss: 0.3721\n",
      "Epoch 14/100, Train Loss: 0.3080, Val Loss: 0.3816\n",
      "Epoch 15/100, Train Loss: 0.2993, Val Loss: 0.3747\n",
      "Epoch 16/100, Train Loss: 0.2961, Val Loss: 0.3922\n",
      "Epoch 17/100, Train Loss: 0.2952, Val Loss: 0.3791\n",
      "Epoch 18/100, Train Loss: 0.2408, Val Loss: 0.3312\n",
      "Epoch 19/100, Train Loss: 0.2274, Val Loss: 0.3311\n",
      "Epoch 20/100, Train Loss: 0.2215, Val Loss: 0.3286\n",
      "Epoch 21/100, Train Loss: 0.2186, Val Loss: 0.3250\n",
      "Epoch 22/100, Train Loss: 0.2151, Val Loss: 0.3268\n",
      "Epoch 23/100, Train Loss: 0.2124, Val Loss: 0.3258\n",
      "Epoch 24/100, Train Loss: 0.2096, Val Loss: 0.3323\n",
      "Epoch 25/100, Train Loss: 0.2077, Val Loss: 0.3349\n",
      "Epoch 26/100, Train Loss: 0.2065, Val Loss: 0.3313\n",
      "Epoch 27/100, Train Loss: 0.2037, Val Loss: 0.3306\n",
      "Epoch 28/100, Train Loss: 0.1958, Val Loss: 0.3293\n",
      "Epoch 29/100, Train Loss: 0.1945, Val Loss: 0.3311\n",
      "Epoch 30/100, Train Loss: 0.1940, Val Loss: 0.3299\n",
      "Epoch 31/100, Train Loss: 0.1936, Val Loss: 0.3332\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: avg, Optimizer: Adam, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 0.4610, Val Loss: 0.3456\n",
      "Epoch 2/250, Train Loss: 0.3069, Val Loss: 0.3125\n",
      "Epoch 3/250, Train Loss: 0.2726, Val Loss: 0.2861\n",
      "Epoch 4/250, Train Loss: 0.2448, Val Loss: 0.2975\n",
      "Epoch 5/250, Train Loss: 0.2287, Val Loss: 0.2975\n",
      "Epoch 6/250, Train Loss: 0.2171, Val Loss: 0.3044\n",
      "Epoch 7/250, Train Loss: 0.2075, Val Loss: 0.3154\n",
      "Epoch 8/250, Train Loss: 0.1954, Val Loss: 0.3678\n",
      "Epoch 9/250, Train Loss: 0.1905, Val Loss: 0.3275\n",
      "Epoch 10/250, Train Loss: 0.1268, Val Loss: 0.2834\n",
      "Epoch 11/250, Train Loss: 0.1050, Val Loss: 0.3004\n",
      "Epoch 12/250, Train Loss: 0.0954, Val Loss: 0.3092\n",
      "Epoch 13/250, Train Loss: 0.0879, Val Loss: 0.3159\n",
      "Epoch 14/250, Train Loss: 0.0809, Val Loss: 0.3243\n",
      "Epoch 15/250, Train Loss: 0.0746, Val Loss: 0.3420\n",
      "Epoch 16/250, Train Loss: 0.0690, Val Loss: 0.3610\n",
      "Epoch 17/250, Train Loss: 0.0589, Val Loss: 0.3623\n",
      "Epoch 18/250, Train Loss: 0.0572, Val Loss: 0.3639\n",
      "Epoch 19/250, Train Loss: 0.0562, Val Loss: 0.3677\n",
      "Epoch 20/250, Train Loss: 0.0555, Val Loss: 0.3715\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 3, Pooling: avg, Optimizer: Adam, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 0.4959, Val Loss: 0.4069\n",
      "Epoch 2/350, Train Loss: 0.3358, Val Loss: 0.3305\n",
      "Epoch 3/350, Train Loss: 0.2945, Val Loss: 0.3045\n",
      "Epoch 4/350, Train Loss: 0.2697, Val Loss: 0.3244\n",
      "Epoch 5/350, Train Loss: 0.2569, Val Loss: 0.3311\n",
      "Epoch 6/350, Train Loss: 0.2440, Val Loss: 0.3181\n",
      "Epoch 7/350, Train Loss: 0.2354, Val Loss: 0.2829\n",
      "Epoch 8/350, Train Loss: 0.2245, Val Loss: 0.3244\n",
      "Epoch 9/350, Train Loss: 0.2180, Val Loss: 0.2987\n",
      "Epoch 10/350, Train Loss: 0.2099, Val Loss: 0.3274\n",
      "Epoch 11/350, Train Loss: 0.2021, Val Loss: 0.2997\n",
      "Epoch 12/350, Train Loss: 0.1962, Val Loss: 0.3356\n",
      "Epoch 13/350, Train Loss: 0.1919, Val Loss: 0.3268\n",
      "Epoch 14/350, Train Loss: 0.1292, Val Loss: 0.3050\n",
      "Epoch 15/350, Train Loss: 0.1126, Val Loss: 0.3130\n",
      "Epoch 16/350, Train Loss: 0.1053, Val Loss: 0.3226\n",
      "Epoch 17/350, Train Loss: 0.0990, Val Loss: 0.3374\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: max, Optimizer: SGD, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 0.9746, Val Loss: 0.6222\n",
      "Epoch 2/5, Train Loss: 0.5497, Val Loss: 0.4996\n",
      "Epoch 3/5, Train Loss: 0.4701, Val Loss: 0.4428\n",
      "Epoch 4/5, Train Loss: 0.4226, Val Loss: 0.4233\n",
      "Epoch 5/5, Train Loss: 0.3884, Val Loss: 0.3894\n",
      "Kernel: 5, Pooling: max, Optimizer: SGD, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 0.9496, Val Loss: 0.6247\n",
      "Epoch 2/50, Train Loss: 0.5662, Val Loss: 0.5237\n",
      "Epoch 3/50, Train Loss: 0.4834, Val Loss: 0.4731\n",
      "Epoch 4/50, Train Loss: 0.4312, Val Loss: 0.4380\n",
      "Epoch 5/50, Train Loss: 0.3975, Val Loss: 0.4299\n",
      "Epoch 6/50, Train Loss: 0.3728, Val Loss: 0.3782\n",
      "Epoch 7/50, Train Loss: 0.3530, Val Loss: 0.4067\n",
      "Epoch 8/50, Train Loss: 0.3373, Val Loss: 0.3652\n",
      "Epoch 9/50, Train Loss: 0.3225, Val Loss: 0.3422\n",
      "Epoch 10/50, Train Loss: 0.3100, Val Loss: 0.3320\n",
      "Epoch 11/50, Train Loss: 0.2998, Val Loss: 0.3615\n",
      "Epoch 12/50, Train Loss: 0.2890, Val Loss: 0.3243\n",
      "Epoch 13/50, Train Loss: 0.2784, Val Loss: 0.3242\n",
      "Epoch 14/50, Train Loss: 0.2705, Val Loss: 0.3105\n",
      "Epoch 15/50, Train Loss: 0.2642, Val Loss: 0.2945\n",
      "Epoch 16/50, Train Loss: 0.2572, Val Loss: 0.2932\n",
      "Epoch 17/50, Train Loss: 0.2502, Val Loss: 0.3025\n",
      "Epoch 18/50, Train Loss: 0.2433, Val Loss: 0.2897\n",
      "Epoch 19/50, Train Loss: 0.2375, Val Loss: 0.2798\n",
      "Epoch 20/50, Train Loss: 0.2337, Val Loss: 0.2751\n",
      "Epoch 21/50, Train Loss: 0.2285, Val Loss: 0.2865\n",
      "Epoch 22/50, Train Loss: 0.2240, Val Loss: 0.2767\n",
      "Epoch 23/50, Train Loss: 0.2170, Val Loss: 0.2810\n",
      "Epoch 24/50, Train Loss: 0.2122, Val Loss: 0.2746\n",
      "Epoch 25/50, Train Loss: 0.2079, Val Loss: 0.2775\n",
      "Epoch 26/50, Train Loss: 0.2045, Val Loss: 0.2588\n",
      "Epoch 27/50, Train Loss: 0.1991, Val Loss: 0.2699\n",
      "Epoch 28/50, Train Loss: 0.1968, Val Loss: 0.2606\n",
      "Epoch 29/50, Train Loss: 0.1910, Val Loss: 0.2530\n",
      "Epoch 30/50, Train Loss: 0.1881, Val Loss: 0.2641\n",
      "Epoch 31/50, Train Loss: 0.1834, Val Loss: 0.2556\n",
      "Epoch 32/50, Train Loss: 0.1803, Val Loss: 0.2679\n",
      "Epoch 33/50, Train Loss: 0.1755, Val Loss: 0.2623\n",
      "Epoch 34/50, Train Loss: 0.1728, Val Loss: 0.2442\n",
      "Epoch 35/50, Train Loss: 0.1695, Val Loss: 0.2480\n",
      "Epoch 36/50, Train Loss: 0.1656, Val Loss: 0.2439\n",
      "Epoch 37/50, Train Loss: 0.1618, Val Loss: 0.2569\n",
      "Epoch 38/50, Train Loss: 0.1584, Val Loss: 0.2610\n",
      "Epoch 39/50, Train Loss: 0.1540, Val Loss: 0.2481\n",
      "Epoch 40/50, Train Loss: 0.1514, Val Loss: 0.2422\n",
      "Epoch 41/50, Train Loss: 0.1470, Val Loss: 0.2476\n",
      "Epoch 42/50, Train Loss: 0.1452, Val Loss: 0.2462\n",
      "Epoch 43/50, Train Loss: 0.1409, Val Loss: 0.2607\n",
      "Epoch 44/50, Train Loss: 0.1377, Val Loss: 0.2483\n",
      "Epoch 45/50, Train Loss: 0.1349, Val Loss: 0.2412\n",
      "Epoch 46/50, Train Loss: 0.1315, Val Loss: 0.2453\n",
      "Epoch 47/50, Train Loss: 0.1281, Val Loss: 0.2462\n",
      "Epoch 48/50, Train Loss: 0.1242, Val Loss: 0.2381\n",
      "Epoch 49/50, Train Loss: 0.1210, Val Loss: 0.2488\n",
      "Epoch 50/50, Train Loss: 0.1185, Val Loss: 0.2439\n",
      "Kernel: 5, Pooling: max, Optimizer: SGD, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 0.9553, Val Loss: 0.6177\n",
      "Epoch 2/100, Train Loss: 0.5439, Val Loss: 0.4929\n",
      "Epoch 3/100, Train Loss: 0.4660, Val Loss: 0.4542\n",
      "Epoch 4/100, Train Loss: 0.4210, Val Loss: 0.4560\n",
      "Epoch 5/100, Train Loss: 0.3883, Val Loss: 0.4021\n",
      "Epoch 6/100, Train Loss: 0.3636, Val Loss: 0.3776\n",
      "Epoch 7/100, Train Loss: 0.3463, Val Loss: 0.3660\n",
      "Epoch 8/100, Train Loss: 0.3308, Val Loss: 0.3476\n",
      "Epoch 9/100, Train Loss: 0.3174, Val Loss: 0.3406\n",
      "Epoch 10/100, Train Loss: 0.3048, Val Loss: 0.3362\n",
      "Epoch 11/100, Train Loss: 0.2934, Val Loss: 0.3250\n",
      "Epoch 12/100, Train Loss: 0.2835, Val Loss: 0.3101\n",
      "Epoch 13/100, Train Loss: 0.2752, Val Loss: 0.3238\n",
      "Epoch 14/100, Train Loss: 0.2669, Val Loss: 0.2980\n",
      "Epoch 15/100, Train Loss: 0.2605, Val Loss: 0.2922\n",
      "Epoch 16/100, Train Loss: 0.2529, Val Loss: 0.3077\n",
      "Epoch 17/100, Train Loss: 0.2472, Val Loss: 0.2826\n",
      "Epoch 18/100, Train Loss: 0.2405, Val Loss: 0.2928\n",
      "Epoch 19/100, Train Loss: 0.2347, Val Loss: 0.2757\n",
      "Epoch 20/100, Train Loss: 0.2292, Val Loss: 0.2830\n",
      "Epoch 21/100, Train Loss: 0.2256, Val Loss: 0.2802\n",
      "Epoch 22/100, Train Loss: 0.2212, Val Loss: 0.2861\n",
      "Epoch 23/100, Train Loss: 0.2148, Val Loss: 0.2769\n",
      "Epoch 24/100, Train Loss: 0.2113, Val Loss: 0.2625\n",
      "Epoch 25/100, Train Loss: 0.2059, Val Loss: 0.2750\n",
      "Epoch 26/100, Train Loss: 0.2026, Val Loss: 0.2563\n",
      "Epoch 27/100, Train Loss: 0.1975, Val Loss: 0.2652\n",
      "Epoch 28/100, Train Loss: 0.1933, Val Loss: 0.2578\n",
      "Epoch 29/100, Train Loss: 0.1895, Val Loss: 0.2620\n",
      "Epoch 30/100, Train Loss: 0.1858, Val Loss: 0.2551\n",
      "Epoch 31/100, Train Loss: 0.1809, Val Loss: 0.2567\n",
      "Epoch 32/100, Train Loss: 0.1761, Val Loss: 0.2581\n",
      "Epoch 33/100, Train Loss: 0.1726, Val Loss: 0.2629\n",
      "Epoch 34/100, Train Loss: 0.1702, Val Loss: 0.2457\n",
      "Epoch 35/100, Train Loss: 0.1674, Val Loss: 0.2548\n",
      "Epoch 36/100, Train Loss: 0.1624, Val Loss: 0.2637\n",
      "Epoch 37/100, Train Loss: 0.1595, Val Loss: 0.2512\n",
      "Epoch 38/100, Train Loss: 0.1540, Val Loss: 0.2524\n",
      "Epoch 39/100, Train Loss: 0.1522, Val Loss: 0.2602\n",
      "Epoch 40/100, Train Loss: 0.1481, Val Loss: 0.2563\n",
      "Epoch 41/100, Train Loss: 0.1254, Val Loss: 0.2391\n",
      "Epoch 42/100, Train Loss: 0.1228, Val Loss: 0.2426\n",
      "Epoch 43/100, Train Loss: 0.1220, Val Loss: 0.2398\n",
      "Epoch 44/100, Train Loss: 0.1213, Val Loss: 0.2403\n",
      "Epoch 45/100, Train Loss: 0.1206, Val Loss: 0.2409\n",
      "Epoch 46/100, Train Loss: 0.1199, Val Loss: 0.2418\n",
      "Epoch 47/100, Train Loss: 0.1195, Val Loss: 0.2401\n",
      "Epoch 48/100, Train Loss: 0.1171, Val Loss: 0.2397\n",
      "Epoch 49/100, Train Loss: 0.1169, Val Loss: 0.2400\n",
      "Epoch 50/100, Train Loss: 0.1168, Val Loss: 0.2399\n",
      "Epoch 51/100, Train Loss: 0.1167, Val Loss: 0.2401\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: max, Optimizer: SGD, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 0.9518, Val Loss: 0.6005\n",
      "Epoch 2/250, Train Loss: 0.5446, Val Loss: 0.5178\n",
      "Epoch 3/250, Train Loss: 0.4644, Val Loss: 0.4506\n",
      "Epoch 4/250, Train Loss: 0.4182, Val Loss: 0.4681\n",
      "Epoch 5/250, Train Loss: 0.3877, Val Loss: 0.3889\n",
      "Epoch 6/250, Train Loss: 0.3639, Val Loss: 0.3819\n",
      "Epoch 7/250, Train Loss: 0.3469, Val Loss: 0.3511\n",
      "Epoch 8/250, Train Loss: 0.3311, Val Loss: 0.3397\n",
      "Epoch 9/250, Train Loss: 0.3188, Val Loss: 0.3464\n",
      "Epoch 10/250, Train Loss: 0.3064, Val Loss: 0.3298\n",
      "Epoch 11/250, Train Loss: 0.2972, Val Loss: 0.3388\n",
      "Epoch 12/250, Train Loss: 0.2868, Val Loss: 0.3073\n",
      "Epoch 13/250, Train Loss: 0.2783, Val Loss: 0.3174\n",
      "Epoch 14/250, Train Loss: 0.2710, Val Loss: 0.3141\n",
      "Epoch 15/250, Train Loss: 0.2633, Val Loss: 0.2920\n",
      "Epoch 16/250, Train Loss: 0.2560, Val Loss: 0.2962\n",
      "Epoch 17/250, Train Loss: 0.2491, Val Loss: 0.2949\n",
      "Epoch 18/250, Train Loss: 0.2430, Val Loss: 0.2991\n",
      "Epoch 19/250, Train Loss: 0.2372, Val Loss: 0.2766\n",
      "Epoch 20/250, Train Loss: 0.2320, Val Loss: 0.2920\n",
      "Epoch 21/250, Train Loss: 0.2260, Val Loss: 0.2839\n",
      "Epoch 22/250, Train Loss: 0.2223, Val Loss: 0.2708\n",
      "Epoch 23/250, Train Loss: 0.2163, Val Loss: 0.2613\n",
      "Epoch 24/250, Train Loss: 0.2100, Val Loss: 0.2899\n",
      "Epoch 25/250, Train Loss: 0.2077, Val Loss: 0.2697\n",
      "Epoch 26/250, Train Loss: 0.2025, Val Loss: 0.2624\n",
      "Epoch 27/250, Train Loss: 0.1988, Val Loss: 0.2542\n",
      "Epoch 28/250, Train Loss: 0.1945, Val Loss: 0.2521\n",
      "Epoch 29/250, Train Loss: 0.1913, Val Loss: 0.2625\n",
      "Epoch 30/250, Train Loss: 0.1865, Val Loss: 0.2602\n",
      "Epoch 31/250, Train Loss: 0.1828, Val Loss: 0.2584\n",
      "Epoch 32/250, Train Loss: 0.1786, Val Loss: 0.2553\n",
      "Epoch 33/250, Train Loss: 0.1744, Val Loss: 0.2518\n",
      "Epoch 34/250, Train Loss: 0.1706, Val Loss: 0.2845\n",
      "Epoch 35/250, Train Loss: 0.1676, Val Loss: 0.2543\n",
      "Epoch 36/250, Train Loss: 0.1641, Val Loss: 0.2501\n",
      "Epoch 37/250, Train Loss: 0.1598, Val Loss: 0.2504\n",
      "Epoch 38/250, Train Loss: 0.1567, Val Loss: 0.2481\n",
      "Epoch 39/250, Train Loss: 0.1533, Val Loss: 0.2730\n",
      "Epoch 40/250, Train Loss: 0.1498, Val Loss: 0.2501\n",
      "Epoch 41/250, Train Loss: 0.1472, Val Loss: 0.2443\n",
      "Epoch 42/250, Train Loss: 0.1436, Val Loss: 0.2620\n",
      "Epoch 43/250, Train Loss: 0.1401, Val Loss: 0.2536\n",
      "Epoch 44/250, Train Loss: 0.1369, Val Loss: 0.2494\n",
      "Epoch 45/250, Train Loss: 0.1329, Val Loss: 0.2476\n",
      "Epoch 46/250, Train Loss: 0.1293, Val Loss: 0.2443\n",
      "Epoch 47/250, Train Loss: 0.1260, Val Loss: 0.2555\n",
      "Epoch 48/250, Train Loss: 0.1051, Val Loss: 0.2360\n",
      "Epoch 49/250, Train Loss: 0.1019, Val Loss: 0.2370\n",
      "Epoch 50/250, Train Loss: 0.1011, Val Loss: 0.2358\n",
      "Epoch 51/250, Train Loss: 0.1004, Val Loss: 0.2371\n",
      "Epoch 52/250, Train Loss: 0.0996, Val Loss: 0.2368\n",
      "Epoch 53/250, Train Loss: 0.0991, Val Loss: 0.2365\n",
      "Epoch 54/250, Train Loss: 0.0985, Val Loss: 0.2377\n",
      "Epoch 55/250, Train Loss: 0.0979, Val Loss: 0.2380\n",
      "Epoch 56/250, Train Loss: 0.0975, Val Loss: 0.2382\n",
      "Epoch 57/250, Train Loss: 0.0954, Val Loss: 0.2377\n",
      "Epoch 58/250, Train Loss: 0.0951, Val Loss: 0.2374\n",
      "Epoch 59/250, Train Loss: 0.0950, Val Loss: 0.2374\n",
      "Epoch 60/250, Train Loss: 0.0949, Val Loss: 0.2376\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: max, Optimizer: SGD, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 0.9430, Val Loss: 0.6277\n",
      "Epoch 2/350, Train Loss: 0.5538, Val Loss: 0.5125\n",
      "Epoch 3/350, Train Loss: 0.4725, Val Loss: 0.4561\n",
      "Epoch 4/350, Train Loss: 0.4248, Val Loss: 0.4165\n",
      "Epoch 5/350, Train Loss: 0.3904, Val Loss: 0.3923\n",
      "Epoch 6/350, Train Loss: 0.3666, Val Loss: 0.3800\n",
      "Epoch 7/350, Train Loss: 0.3475, Val Loss: 0.3709\n",
      "Epoch 8/350, Train Loss: 0.3344, Val Loss: 0.3466\n",
      "Epoch 9/350, Train Loss: 0.3209, Val Loss: 0.3405\n",
      "Epoch 10/350, Train Loss: 0.3085, Val Loss: 0.3309\n",
      "Epoch 11/350, Train Loss: 0.2979, Val Loss: 0.3306\n",
      "Epoch 12/350, Train Loss: 0.2879, Val Loss: 0.3259\n",
      "Epoch 13/350, Train Loss: 0.2786, Val Loss: 0.3058\n",
      "Epoch 14/350, Train Loss: 0.2720, Val Loss: 0.3057\n",
      "Epoch 15/350, Train Loss: 0.2636, Val Loss: 0.2952\n",
      "Epoch 16/350, Train Loss: 0.2565, Val Loss: 0.2966\n",
      "Epoch 17/350, Train Loss: 0.2516, Val Loss: 0.2812\n",
      "Epoch 18/350, Train Loss: 0.2455, Val Loss: 0.2861\n",
      "Epoch 19/350, Train Loss: 0.2383, Val Loss: 0.2943\n",
      "Epoch 20/350, Train Loss: 0.2338, Val Loss: 0.2867\n",
      "Epoch 21/350, Train Loss: 0.2285, Val Loss: 0.2730\n",
      "Epoch 22/350, Train Loss: 0.2239, Val Loss: 0.2857\n",
      "Epoch 23/350, Train Loss: 0.2193, Val Loss: 0.2690\n",
      "Epoch 24/350, Train Loss: 0.2140, Val Loss: 0.2705\n",
      "Epoch 25/350, Train Loss: 0.2098, Val Loss: 0.2684\n",
      "Epoch 26/350, Train Loss: 0.2051, Val Loss: 0.2589\n",
      "Epoch 27/350, Train Loss: 0.1991, Val Loss: 0.2634\n",
      "Epoch 28/350, Train Loss: 0.1962, Val Loss: 0.2561\n",
      "Epoch 29/350, Train Loss: 0.1930, Val Loss: 0.3032\n",
      "Epoch 30/350, Train Loss: 0.1890, Val Loss: 0.2564\n",
      "Epoch 31/350, Train Loss: 0.1847, Val Loss: 0.2533\n",
      "Epoch 32/350, Train Loss: 0.1812, Val Loss: 0.2681\n",
      "Epoch 33/350, Train Loss: 0.1774, Val Loss: 0.2565\n",
      "Epoch 34/350, Train Loss: 0.1733, Val Loss: 0.2587\n",
      "Epoch 35/350, Train Loss: 0.1688, Val Loss: 0.2454\n",
      "Epoch 36/350, Train Loss: 0.1663, Val Loss: 0.2452\n",
      "Epoch 37/350, Train Loss: 0.1619, Val Loss: 0.2473\n",
      "Epoch 38/350, Train Loss: 0.1591, Val Loss: 0.2479\n",
      "Epoch 39/350, Train Loss: 0.1552, Val Loss: 0.2455\n",
      "Epoch 40/350, Train Loss: 0.1517, Val Loss: 0.2499\n",
      "Epoch 41/350, Train Loss: 0.1479, Val Loss: 0.2602\n",
      "Epoch 42/350, Train Loss: 0.1447, Val Loss: 0.2496\n",
      "Epoch 43/350, Train Loss: 0.1225, Val Loss: 0.2343\n",
      "Epoch 44/350, Train Loss: 0.1201, Val Loss: 0.2345\n",
      "Epoch 45/350, Train Loss: 0.1189, Val Loss: 0.2356\n",
      "Epoch 46/350, Train Loss: 0.1182, Val Loss: 0.2349\n",
      "Epoch 47/350, Train Loss: 0.1174, Val Loss: 0.2349\n",
      "Epoch 48/350, Train Loss: 0.1169, Val Loss: 0.2372\n",
      "Epoch 49/350, Train Loss: 0.1163, Val Loss: 0.2355\n",
      "Epoch 50/350, Train Loss: 0.1142, Val Loss: 0.2346\n",
      "Epoch 51/350, Train Loss: 0.1139, Val Loss: 0.2345\n",
      "Epoch 52/350, Train Loss: 0.1138, Val Loss: 0.2348\n",
      "Epoch 53/350, Train Loss: 0.1137, Val Loss: 0.2349\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: max, Optimizer: RMSProp, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 15.6681, Val Loss: 2.3034\n",
      "Epoch 2/5, Train Loss: 2.3036, Val Loss: 2.3040\n",
      "Epoch 3/5, Train Loss: 2.3350, Val Loss: 2.3030\n",
      "Epoch 4/5, Train Loss: 2.3033, Val Loss: 2.3041\n",
      "Epoch 5/5, Train Loss: 2.3036, Val Loss: 2.3034\n",
      "Kernel: 5, Pooling: max, Optimizer: RMSProp, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 21.5159, Val Loss: 0.5325\n",
      "Epoch 2/50, Train Loss: 0.8148, Val Loss: 0.4955\n",
      "Epoch 3/50, Train Loss: 0.5844, Val Loss: 12.1380\n",
      "Epoch 4/50, Train Loss: 0.6551, Val Loss: 0.4672\n",
      "Epoch 5/50, Train Loss: 0.4301, Val Loss: 0.4152\n",
      "Epoch 6/50, Train Loss: 0.4116, Val Loss: 0.4684\n",
      "Epoch 7/50, Train Loss: 0.4208, Val Loss: 0.4125\n",
      "Epoch 8/50, Train Loss: 0.3829, Val Loss: 0.4452\n",
      "Epoch 9/50, Train Loss: 0.3788, Val Loss: 0.4135\n",
      "Epoch 10/50, Train Loss: 0.3854, Val Loss: 0.4451\n",
      "Epoch 11/50, Train Loss: 0.3665, Val Loss: 0.5359\n",
      "Epoch 12/50, Train Loss: 0.5178, Val Loss: 0.5789\n",
      "Epoch 13/50, Train Loss: 0.3641, Val Loss: 0.4087\n",
      "Epoch 14/50, Train Loss: 0.3673, Val Loss: 0.4316\n",
      "Epoch 15/50, Train Loss: 0.3572, Val Loss: 0.4155\n",
      "Epoch 16/50, Train Loss: 0.3653, Val Loss: 0.4536\n",
      "Epoch 17/50, Train Loss: 0.3614, Val Loss: 0.4772\n",
      "Epoch 18/50, Train Loss: 0.6768, Val Loss: 0.4713\n",
      "Epoch 19/50, Train Loss: 0.3932, Val Loss: 0.5811\n",
      "Epoch 20/50, Train Loss: 0.2728, Val Loss: 0.3970\n",
      "Epoch 21/50, Train Loss: 0.2352, Val Loss: 0.4228\n",
      "Epoch 22/50, Train Loss: 0.2248, Val Loss: 0.4119\n",
      "Epoch 23/50, Train Loss: 0.2160, Val Loss: 0.4040\n",
      "Epoch 24/50, Train Loss: 0.2100, Val Loss: 0.4304\n",
      "Epoch 25/50, Train Loss: 0.2050, Val Loss: 0.4195\n",
      "Epoch 26/50, Train Loss: 0.2009, Val Loss: 0.4230\n",
      "Epoch 27/50, Train Loss: 0.1885, Val Loss: 0.4308\n",
      "Epoch 28/50, Train Loss: 0.1857, Val Loss: 0.4366\n",
      "Epoch 29/50, Train Loss: 0.1845, Val Loss: 0.4380\n",
      "Epoch 30/50, Train Loss: 0.1835, Val Loss: 0.4408\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: max, Optimizer: RMSProp, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 8.4697, Val Loss: 0.5725\n",
      "Epoch 2/100, Train Loss: 0.6826, Val Loss: 0.9644\n",
      "Epoch 3/100, Train Loss: 0.5882, Val Loss: 0.4289\n",
      "Epoch 4/100, Train Loss: 0.4627, Val Loss: 0.4193\n",
      "Epoch 5/100, Train Loss: 0.4585, Val Loss: 0.5132\n",
      "Epoch 6/100, Train Loss: 0.3990, Val Loss: 0.4257\n",
      "Epoch 7/100, Train Loss: 0.3892, Val Loss: 0.4058\n",
      "Epoch 8/100, Train Loss: 0.3839, Val Loss: 0.4689\n",
      "Epoch 9/100, Train Loss: 0.3929, Val Loss: 0.4002\n",
      "Epoch 10/100, Train Loss: 0.3817, Val Loss: 0.4454\n",
      "Epoch 11/100, Train Loss: 0.3629, Val Loss: 0.4208\n",
      "Epoch 12/100, Train Loss: 0.3930, Val Loss: 0.5714\n",
      "Epoch 13/100, Train Loss: 0.4089, Val Loss: 0.5121\n",
      "Epoch 14/100, Train Loss: 0.3672, Val Loss: 0.4948\n",
      "Epoch 15/100, Train Loss: 0.3604, Val Loss: 0.4569\n",
      "Epoch 16/100, Train Loss: 0.2727, Val Loss: 0.3742\n",
      "Epoch 17/100, Train Loss: 0.2464, Val Loss: 0.3686\n",
      "Epoch 18/100, Train Loss: 0.2346, Val Loss: 0.3781\n",
      "Epoch 19/100, Train Loss: 0.2253, Val Loss: 0.3720\n",
      "Epoch 20/100, Train Loss: 0.2190, Val Loss: 0.3698\n",
      "Epoch 21/100, Train Loss: 0.2123, Val Loss: 0.3826\n",
      "Epoch 22/100, Train Loss: 0.2075, Val Loss: 0.3965\n",
      "Epoch 23/100, Train Loss: 0.2021, Val Loss: 0.4002\n",
      "Epoch 24/100, Train Loss: 0.1902, Val Loss: 0.4027\n",
      "Epoch 25/100, Train Loss: 0.1872, Val Loss: 0.4056\n",
      "Epoch 26/100, Train Loss: 0.1859, Val Loss: 0.4095\n",
      "Epoch 27/100, Train Loss: 0.1851, Val Loss: 0.4136\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: max, Optimizer: RMSProp, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 30.9825, Val Loss: 0.8031\n",
      "Epoch 2/250, Train Loss: 1.2446, Val Loss: 0.6087\n",
      "Epoch 3/250, Train Loss: 0.6411, Val Loss: 0.4549\n",
      "Epoch 4/250, Train Loss: 0.6041, Val Loss: 0.4789\n",
      "Epoch 5/250, Train Loss: 0.4415, Val Loss: 0.4517\n",
      "Epoch 6/250, Train Loss: 0.4166, Val Loss: 0.4826\n",
      "Epoch 7/250, Train Loss: 0.4014, Val Loss: 0.4749\n",
      "Epoch 8/250, Train Loss: 0.3901, Val Loss: 0.4368\n",
      "Epoch 9/250, Train Loss: 0.3832, Val Loss: 0.4207\n",
      "Epoch 10/250, Train Loss: 0.3825, Val Loss: 0.4461\n",
      "Epoch 11/250, Train Loss: 0.3711, Val Loss: 0.4576\n",
      "Epoch 12/250, Train Loss: 0.3792, Val Loss: 0.4377\n",
      "Epoch 13/250, Train Loss: 0.3736, Val Loss: 0.4104\n",
      "Epoch 14/250, Train Loss: 0.3720, Val Loss: 0.4289\n",
      "Epoch 15/250, Train Loss: 0.3616, Val Loss: 0.4173\n",
      "Epoch 16/250, Train Loss: 0.3778, Val Loss: 0.4115\n",
      "Epoch 17/250, Train Loss: 0.3820, Val Loss: 0.5147\n",
      "Epoch 18/250, Train Loss: 0.3732, Val Loss: 0.4364\n",
      "Epoch 19/250, Train Loss: 0.5013, Val Loss: 0.5223\n",
      "Epoch 20/250, Train Loss: 0.3454, Val Loss: 0.3996\n",
      "Epoch 21/250, Train Loss: 0.2754, Val Loss: 0.3985\n",
      "Epoch 22/250, Train Loss: 0.2565, Val Loss: 0.3836\n",
      "Epoch 23/250, Train Loss: 0.2465, Val Loss: 0.4070\n",
      "Epoch 24/250, Train Loss: 0.2400, Val Loss: 0.3983\n",
      "Epoch 25/250, Train Loss: 0.2321, Val Loss: 0.4190\n",
      "Epoch 26/250, Train Loss: 0.2263, Val Loss: 0.3988\n",
      "Epoch 27/250, Train Loss: 0.2223, Val Loss: 0.4203\n",
      "Epoch 28/250, Train Loss: 0.2154, Val Loss: 0.4377\n",
      "Epoch 29/250, Train Loss: 0.2035, Val Loss: 0.4360\n",
      "Epoch 30/250, Train Loss: 0.2009, Val Loss: 0.4354\n",
      "Epoch 31/250, Train Loss: 0.1995, Val Loss: 0.4365\n",
      "Epoch 32/250, Train Loss: 0.1986, Val Loss: 0.4365\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: max, Optimizer: RMSProp, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 12.0715, Val Loss: 2.3029\n",
      "Epoch 2/350, Train Loss: 2.3038, Val Loss: 2.3032\n",
      "Epoch 3/350, Train Loss: 2.3052, Val Loss: 2.3035\n",
      "Epoch 4/350, Train Loss: 2.3036, Val Loss: 2.3054\n",
      "Epoch 5/350, Train Loss: 2.3035, Val Loss: 2.3035\n",
      "Epoch 6/350, Train Loss: 2.3038, Val Loss: 2.3035\n",
      "Epoch 7/350, Train Loss: 2.3037, Val Loss: 2.3035\n",
      "Epoch 8/350, Train Loss: 2.3029, Val Loss: 2.3028\n",
      "Epoch 9/350, Train Loss: 2.3027, Val Loss: 2.3026\n",
      "Epoch 10/350, Train Loss: 2.3027, Val Loss: 2.3028\n",
      "Epoch 11/350, Train Loss: 2.3027, Val Loss: 2.3028\n",
      "Epoch 12/350, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 13/350, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 14/350, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 15/350, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 16/350, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 17/350, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 18/350, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 19/350, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: max, Optimizer: Adam, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 0.5678, Val Loss: 0.4799\n",
      "Epoch 2/5, Train Loss: 0.4312, Val Loss: 0.4845\n",
      "Epoch 3/5, Train Loss: 0.4263, Val Loss: 0.4287\n",
      "Epoch 4/5, Train Loss: 0.4000, Val Loss: 0.4175\n",
      "Epoch 5/5, Train Loss: 0.3922, Val Loss: 0.4161\n",
      "Kernel: 5, Pooling: max, Optimizer: Adam, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 0.5757, Val Loss: 0.4824\n",
      "Epoch 2/50, Train Loss: 0.4051, Val Loss: 0.4713\n",
      "Epoch 3/50, Train Loss: 0.3834, Val Loss: 0.4139\n",
      "Epoch 4/50, Train Loss: 0.3687, Val Loss: 0.3903\n",
      "Epoch 5/50, Train Loss: 0.3617, Val Loss: 0.3868\n",
      "Epoch 6/50, Train Loss: 0.3481, Val Loss: 0.3979\n",
      "Epoch 7/50, Train Loss: 0.3401, Val Loss: 0.3948\n",
      "Epoch 8/50, Train Loss: 0.3418, Val Loss: 0.4073\n",
      "Epoch 9/50, Train Loss: 0.3334, Val Loss: 0.3967\n",
      "Epoch 10/50, Train Loss: 0.3305, Val Loss: 0.3754\n",
      "Epoch 11/50, Train Loss: 0.3274, Val Loss: 0.3836\n",
      "Epoch 12/50, Train Loss: 0.3312, Val Loss: 0.3729\n",
      "Epoch 13/50, Train Loss: 0.3179, Val Loss: 0.3923\n",
      "Epoch 14/50, Train Loss: 0.3255, Val Loss: 0.4330\n",
      "Epoch 15/50, Train Loss: 0.3215, Val Loss: 0.3926\n",
      "Epoch 16/50, Train Loss: 0.3169, Val Loss: 0.3950\n",
      "Epoch 17/50, Train Loss: 0.3141, Val Loss: 0.3955\n",
      "Epoch 18/50, Train Loss: 0.3268, Val Loss: 0.4045\n",
      "Epoch 19/50, Train Loss: 0.2555, Val Loss: 0.3411\n",
      "Epoch 20/50, Train Loss: 0.2354, Val Loss: 0.3438\n",
      "Epoch 21/50, Train Loss: 0.2257, Val Loss: 0.3414\n",
      "Epoch 22/50, Train Loss: 0.2187, Val Loss: 0.3457\n",
      "Epoch 23/50, Train Loss: 0.2128, Val Loss: 0.3471\n",
      "Epoch 24/50, Train Loss: 0.2075, Val Loss: 0.3515\n",
      "Epoch 25/50, Train Loss: 0.2029, Val Loss: 0.3612\n",
      "Epoch 26/50, Train Loss: 0.1922, Val Loss: 0.3545\n",
      "Epoch 27/50, Train Loss: 0.1900, Val Loss: 0.3567\n",
      "Epoch 28/50, Train Loss: 0.1890, Val Loss: 0.3589\n",
      "Epoch 29/50, Train Loss: 0.1882, Val Loss: 0.3595\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: max, Optimizer: Adam, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 0.5078, Val Loss: 0.4212\n",
      "Epoch 2/100, Train Loss: 0.3827, Val Loss: 0.4014\n",
      "Epoch 3/100, Train Loss: 0.3606, Val Loss: 0.3775\n",
      "Epoch 4/100, Train Loss: 0.3457, Val Loss: 0.3862\n",
      "Epoch 5/100, Train Loss: 0.3404, Val Loss: 0.3962\n",
      "Epoch 6/100, Train Loss: 0.3275, Val Loss: 0.3604\n",
      "Epoch 7/100, Train Loss: 0.3190, Val Loss: 0.3672\n",
      "Epoch 8/100, Train Loss: 0.3113, Val Loss: 0.3649\n",
      "Epoch 9/100, Train Loss: 0.3168, Val Loss: 0.3980\n",
      "Epoch 10/100, Train Loss: 0.3120, Val Loss: 0.4045\n",
      "Epoch 11/100, Train Loss: 0.3180, Val Loss: 0.3818\n",
      "Epoch 12/100, Train Loss: 0.3036, Val Loss: 0.3848\n",
      "Epoch 13/100, Train Loss: 0.2273, Val Loss: 0.3270\n",
      "Epoch 14/100, Train Loss: 0.2034, Val Loss: 0.3239\n",
      "Epoch 15/100, Train Loss: 0.1924, Val Loss: 0.3296\n",
      "Epoch 16/100, Train Loss: 0.1851, Val Loss: 0.3296\n",
      "Epoch 17/100, Train Loss: 0.1775, Val Loss: 0.3331\n",
      "Epoch 18/100, Train Loss: 0.1711, Val Loss: 0.3497\n",
      "Epoch 19/100, Train Loss: 0.1655, Val Loss: 0.3524\n",
      "Epoch 20/100, Train Loss: 0.1600, Val Loss: 0.3556\n",
      "Epoch 21/100, Train Loss: 0.1486, Val Loss: 0.3582\n",
      "Epoch 22/100, Train Loss: 0.1456, Val Loss: 0.3614\n",
      "Epoch 23/100, Train Loss: 0.1446, Val Loss: 0.3639\n",
      "Epoch 24/100, Train Loss: 0.1438, Val Loss: 0.3665\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: max, Optimizer: Adam, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 0.5537, Val Loss: 0.4568\n",
      "Epoch 2/250, Train Loss: 0.4257, Val Loss: 0.4463\n",
      "Epoch 3/250, Train Loss: 0.4058, Val Loss: 0.4201\n",
      "Epoch 4/250, Train Loss: 0.3943, Val Loss: 0.4241\n",
      "Epoch 5/250, Train Loss: 0.3804, Val Loss: 0.4383\n",
      "Epoch 6/250, Train Loss: 0.3821, Val Loss: 0.4531\n",
      "Epoch 7/250, Train Loss: 0.3792, Val Loss: 0.4059\n",
      "Epoch 8/250, Train Loss: 0.3686, Val Loss: 0.4048\n",
      "Epoch 9/250, Train Loss: 0.3666, Val Loss: 0.3915\n",
      "Epoch 10/250, Train Loss: 0.3615, Val Loss: 0.4126\n",
      "Epoch 11/250, Train Loss: 0.3600, Val Loss: 0.4020\n",
      "Epoch 12/250, Train Loss: 0.3599, Val Loss: 0.4022\n",
      "Epoch 13/250, Train Loss: 0.3557, Val Loss: 0.3940\n",
      "Epoch 14/250, Train Loss: 0.3533, Val Loss: 0.4085\n",
      "Epoch 15/250, Train Loss: 0.3519, Val Loss: 0.3856\n",
      "Epoch 16/250, Train Loss: 0.3440, Val Loss: 0.4169\n",
      "Epoch 17/250, Train Loss: 0.3417, Val Loss: 0.4539\n",
      "Epoch 18/250, Train Loss: 0.3448, Val Loss: 0.4038\n",
      "Epoch 19/250, Train Loss: 0.3378, Val Loss: 0.4735\n",
      "Epoch 20/250, Train Loss: 0.3467, Val Loss: 0.4064\n",
      "Epoch 21/250, Train Loss: 0.3309, Val Loss: 0.4047\n",
      "Epoch 22/250, Train Loss: 0.2647, Val Loss: 0.3422\n",
      "Epoch 23/250, Train Loss: 0.2472, Val Loss: 0.3393\n",
      "Epoch 24/250, Train Loss: 0.2392, Val Loss: 0.3445\n",
      "Epoch 25/250, Train Loss: 0.2326, Val Loss: 0.3457\n",
      "Epoch 26/250, Train Loss: 0.2273, Val Loss: 0.3487\n",
      "Epoch 27/250, Train Loss: 0.2222, Val Loss: 0.3556\n",
      "Epoch 28/250, Train Loss: 0.2181, Val Loss: 0.3637\n",
      "Epoch 29/250, Train Loss: 0.2146, Val Loss: 0.3630\n",
      "Epoch 30/250, Train Loss: 0.2039, Val Loss: 0.3618\n",
      "Epoch 31/250, Train Loss: 0.2023, Val Loss: 0.3631\n",
      "Epoch 32/250, Train Loss: 0.2015, Val Loss: 0.3643\n",
      "Epoch 33/250, Train Loss: 0.2008, Val Loss: 0.3644\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: max, Optimizer: Adam, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 0.5884, Val Loss: 0.4788\n",
      "Epoch 2/350, Train Loss: 0.4340, Val Loss: 0.4254\n",
      "Epoch 3/350, Train Loss: 0.4059, Val Loss: 0.4115\n",
      "Epoch 4/350, Train Loss: 0.3914, Val Loss: 0.4060\n",
      "Epoch 5/350, Train Loss: 0.3843, Val Loss: 0.4333\n",
      "Epoch 6/350, Train Loss: 0.3782, Val Loss: 0.4153\n",
      "Epoch 7/350, Train Loss: 0.3745, Val Loss: 0.4031\n",
      "Epoch 8/350, Train Loss: 0.3816, Val Loss: 0.4238\n",
      "Epoch 9/350, Train Loss: 0.3697, Val Loss: 0.4010\n",
      "Epoch 10/350, Train Loss: 0.3702, Val Loss: 0.4125\n",
      "Epoch 11/350, Train Loss: 0.3680, Val Loss: 0.4448\n",
      "Epoch 12/350, Train Loss: 0.3631, Val Loss: 0.4031\n",
      "Epoch 13/350, Train Loss: 0.3603, Val Loss: 0.4555\n",
      "Epoch 14/350, Train Loss: 0.3569, Val Loss: 0.4102\n",
      "Epoch 15/350, Train Loss: 0.3559, Val Loss: 0.4070\n",
      "Epoch 16/350, Train Loss: 0.2922, Val Loss: 0.3450\n",
      "Epoch 17/350, Train Loss: 0.2712, Val Loss: 0.3441\n",
      "Epoch 18/350, Train Loss: 0.2612, Val Loss: 0.3439\n",
      "Epoch 19/350, Train Loss: 0.2553, Val Loss: 0.3433\n",
      "Epoch 20/350, Train Loss: 0.2501, Val Loss: 0.3376\n",
      "Epoch 21/350, Train Loss: 0.2458, Val Loss: 0.3490\n",
      "Epoch 22/350, Train Loss: 0.2422, Val Loss: 0.3465\n",
      "Epoch 23/350, Train Loss: 0.2391, Val Loss: 0.3494\n",
      "Epoch 24/350, Train Loss: 0.2357, Val Loss: 0.3467\n",
      "Epoch 25/350, Train Loss: 0.2322, Val Loss: 0.3547\n",
      "Epoch 26/350, Train Loss: 0.2298, Val Loss: 0.3528\n",
      "Epoch 27/350, Train Loss: 0.2171, Val Loss: 0.3503\n",
      "Epoch 28/350, Train Loss: 0.2151, Val Loss: 0.3490\n",
      "Epoch 29/350, Train Loss: 0.2141, Val Loss: 0.3501\n",
      "Epoch 30/350, Train Loss: 0.2134, Val Loss: 0.3508\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: avg, Optimizer: SGD, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 1.0275, Val Loss: 0.7022\n",
      "Epoch 2/5, Train Loss: 0.6391, Val Loss: 0.6280\n",
      "Epoch 3/5, Train Loss: 0.5684, Val Loss: 0.5586\n",
      "Epoch 4/5, Train Loss: 0.5141, Val Loss: 0.4912\n",
      "Epoch 5/5, Train Loss: 0.4768, Val Loss: 0.4741\n",
      "Kernel: 5, Pooling: avg, Optimizer: SGD, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 1.0706, Val Loss: 0.6992\n",
      "Epoch 2/50, Train Loss: 0.6325, Val Loss: 0.5908\n",
      "Epoch 3/50, Train Loss: 0.5587, Val Loss: 0.5589\n",
      "Epoch 4/50, Train Loss: 0.5081, Val Loss: 0.4966\n",
      "Epoch 5/50, Train Loss: 0.4696, Val Loss: 0.4850\n",
      "Epoch 6/50, Train Loss: 0.4428, Val Loss: 0.4432\n",
      "Epoch 7/50, Train Loss: 0.4222, Val Loss: 0.4393\n",
      "Epoch 8/50, Train Loss: 0.4070, Val Loss: 0.4172\n",
      "Epoch 9/50, Train Loss: 0.3911, Val Loss: 0.4066\n",
      "Epoch 10/50, Train Loss: 0.3804, Val Loss: 0.3990\n",
      "Epoch 11/50, Train Loss: 0.3683, Val Loss: 0.3871\n",
      "Epoch 12/50, Train Loss: 0.3585, Val Loss: 0.3876\n",
      "Epoch 13/50, Train Loss: 0.3503, Val Loss: 0.3711\n",
      "Epoch 14/50, Train Loss: 0.3425, Val Loss: 0.3720\n",
      "Epoch 15/50, Train Loss: 0.3349, Val Loss: 0.3679\n",
      "Epoch 16/50, Train Loss: 0.3271, Val Loss: 0.3461\n",
      "Epoch 17/50, Train Loss: 0.3214, Val Loss: 0.3512\n",
      "Epoch 18/50, Train Loss: 0.3142, Val Loss: 0.3456\n",
      "Epoch 19/50, Train Loss: 0.3096, Val Loss: 0.3424\n",
      "Epoch 20/50, Train Loss: 0.3031, Val Loss: 0.3468\n",
      "Epoch 21/50, Train Loss: 0.2991, Val Loss: 0.3273\n",
      "Epoch 22/50, Train Loss: 0.2928, Val Loss: 0.3257\n",
      "Epoch 23/50, Train Loss: 0.2894, Val Loss: 0.3406\n",
      "Epoch 24/50, Train Loss: 0.2845, Val Loss: 0.3304\n",
      "Epoch 25/50, Train Loss: 0.2799, Val Loss: 0.3168\n",
      "Epoch 26/50, Train Loss: 0.2753, Val Loss: 0.3164\n",
      "Epoch 27/50, Train Loss: 0.2719, Val Loss: 0.3145\n",
      "Epoch 28/50, Train Loss: 0.2682, Val Loss: 0.3065\n",
      "Epoch 29/50, Train Loss: 0.2649, Val Loss: 0.3151\n",
      "Epoch 30/50, Train Loss: 0.2607, Val Loss: 0.3073\n",
      "Epoch 31/50, Train Loss: 0.2579, Val Loss: 0.2980\n",
      "Epoch 32/50, Train Loss: 0.2539, Val Loss: 0.3014\n",
      "Epoch 33/50, Train Loss: 0.2508, Val Loss: 0.3102\n",
      "Epoch 34/50, Train Loss: 0.2475, Val Loss: 0.3005\n",
      "Epoch 35/50, Train Loss: 0.2444, Val Loss: 0.2989\n",
      "Epoch 36/50, Train Loss: 0.2413, Val Loss: 0.3008\n",
      "Epoch 37/50, Train Loss: 0.2391, Val Loss: 0.2914\n",
      "Epoch 38/50, Train Loss: 0.2354, Val Loss: 0.2946\n",
      "Epoch 39/50, Train Loss: 0.2329, Val Loss: 0.2842\n",
      "Epoch 40/50, Train Loss: 0.2309, Val Loss: 0.2944\n",
      "Epoch 41/50, Train Loss: 0.2276, Val Loss: 0.2932\n",
      "Epoch 42/50, Train Loss: 0.2241, Val Loss: 0.2860\n",
      "Epoch 43/50, Train Loss: 0.2227, Val Loss: 0.2807\n",
      "Epoch 44/50, Train Loss: 0.2192, Val Loss: 0.2824\n",
      "Epoch 45/50, Train Loss: 0.2167, Val Loss: 0.2818\n",
      "Epoch 46/50, Train Loss: 0.2138, Val Loss: 0.2874\n",
      "Epoch 47/50, Train Loss: 0.2129, Val Loss: 0.2836\n",
      "Epoch 48/50, Train Loss: 0.2099, Val Loss: 0.2770\n",
      "Epoch 49/50, Train Loss: 0.2072, Val Loss: 0.2757\n",
      "Epoch 50/50, Train Loss: 0.2055, Val Loss: 0.2892\n",
      "Kernel: 5, Pooling: avg, Optimizer: SGD, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 1.0397, Val Loss: 0.7067\n",
      "Epoch 2/100, Train Loss: 0.6478, Val Loss: 0.6182\n",
      "Epoch 3/100, Train Loss: 0.5699, Val Loss: 0.5626\n",
      "Epoch 4/100, Train Loss: 0.5189, Val Loss: 0.5049\n",
      "Epoch 5/100, Train Loss: 0.4777, Val Loss: 0.4673\n",
      "Epoch 6/100, Train Loss: 0.4495, Val Loss: 0.4420\n",
      "Epoch 7/100, Train Loss: 0.4265, Val Loss: 0.4325\n",
      "Epoch 8/100, Train Loss: 0.4093, Val Loss: 0.4459\n",
      "Epoch 9/100, Train Loss: 0.3940, Val Loss: 0.4164\n",
      "Epoch 10/100, Train Loss: 0.3831, Val Loss: 0.4090\n",
      "Epoch 11/100, Train Loss: 0.3712, Val Loss: 0.3859\n",
      "Epoch 12/100, Train Loss: 0.3638, Val Loss: 0.3760\n",
      "Epoch 13/100, Train Loss: 0.3547, Val Loss: 0.3912\n",
      "Epoch 14/100, Train Loss: 0.3454, Val Loss: 0.3710\n",
      "Epoch 15/100, Train Loss: 0.3378, Val Loss: 0.3618\n",
      "Epoch 16/100, Train Loss: 0.3319, Val Loss: 0.3604\n",
      "Epoch 17/100, Train Loss: 0.3238, Val Loss: 0.3503\n",
      "Epoch 18/100, Train Loss: 0.3192, Val Loss: 0.3449\n",
      "Epoch 19/100, Train Loss: 0.3117, Val Loss: 0.3422\n",
      "Epoch 20/100, Train Loss: 0.3079, Val Loss: 0.3422\n",
      "Epoch 21/100, Train Loss: 0.3026, Val Loss: 0.3361\n",
      "Epoch 22/100, Train Loss: 0.2980, Val Loss: 0.3303\n",
      "Epoch 23/100, Train Loss: 0.2933, Val Loss: 0.3345\n",
      "Epoch 24/100, Train Loss: 0.2891, Val Loss: 0.3196\n",
      "Epoch 25/100, Train Loss: 0.2848, Val Loss: 0.3321\n",
      "Epoch 26/100, Train Loss: 0.2809, Val Loss: 0.3170\n",
      "Epoch 27/100, Train Loss: 0.2772, Val Loss: 0.3174\n",
      "Epoch 28/100, Train Loss: 0.2728, Val Loss: 0.3183\n",
      "Epoch 29/100, Train Loss: 0.2687, Val Loss: 0.3107\n",
      "Epoch 30/100, Train Loss: 0.2666, Val Loss: 0.3073\n",
      "Epoch 31/100, Train Loss: 0.2625, Val Loss: 0.3071\n",
      "Epoch 32/100, Train Loss: 0.2592, Val Loss: 0.3128\n",
      "Epoch 33/100, Train Loss: 0.2559, Val Loss: 0.3103\n",
      "Epoch 34/100, Train Loss: 0.2534, Val Loss: 0.3042\n",
      "Epoch 35/100, Train Loss: 0.2500, Val Loss: 0.3027\n",
      "Epoch 36/100, Train Loss: 0.2469, Val Loss: 0.2945\n",
      "Epoch 37/100, Train Loss: 0.2442, Val Loss: 0.3019\n",
      "Epoch 38/100, Train Loss: 0.2392, Val Loss: 0.2935\n",
      "Epoch 39/100, Train Loss: 0.2389, Val Loss: 0.2971\n",
      "Epoch 40/100, Train Loss: 0.2366, Val Loss: 0.2935\n",
      "Epoch 41/100, Train Loss: 0.2339, Val Loss: 0.2908\n",
      "Epoch 42/100, Train Loss: 0.2298, Val Loss: 0.2872\n",
      "Epoch 43/100, Train Loss: 0.2289, Val Loss: 0.2879\n",
      "Epoch 44/100, Train Loss: 0.2255, Val Loss: 0.2918\n",
      "Epoch 45/100, Train Loss: 0.2221, Val Loss: 0.2818\n",
      "Epoch 46/100, Train Loss: 0.2212, Val Loss: 0.2912\n",
      "Epoch 47/100, Train Loss: 0.2177, Val Loss: 0.2953\n",
      "Epoch 48/100, Train Loss: 0.2163, Val Loss: 0.3086\n",
      "Epoch 49/100, Train Loss: 0.2138, Val Loss: 0.2824\n",
      "Epoch 50/100, Train Loss: 0.2117, Val Loss: 0.2723\n",
      "Epoch 51/100, Train Loss: 0.2089, Val Loss: 0.2976\n",
      "Epoch 52/100, Train Loss: 0.2070, Val Loss: 0.2869\n",
      "Epoch 53/100, Train Loss: 0.2052, Val Loss: 0.2813\n",
      "Epoch 54/100, Train Loss: 0.2019, Val Loss: 0.2804\n",
      "Epoch 55/100, Train Loss: 0.2000, Val Loss: 0.2740\n",
      "Epoch 56/100, Train Loss: 0.1989, Val Loss: 0.3152\n",
      "Epoch 57/100, Train Loss: 0.1779, Val Loss: 0.2655\n",
      "Epoch 58/100, Train Loss: 0.1750, Val Loss: 0.2639\n",
      "Epoch 59/100, Train Loss: 0.1741, Val Loss: 0.2647\n",
      "Epoch 60/100, Train Loss: 0.1736, Val Loss: 0.2652\n",
      "Epoch 61/100, Train Loss: 0.1730, Val Loss: 0.2663\n",
      "Epoch 62/100, Train Loss: 0.1726, Val Loss: 0.2658\n",
      "Epoch 63/100, Train Loss: 0.1720, Val Loss: 0.2657\n",
      "Epoch 64/100, Train Loss: 0.1717, Val Loss: 0.2655\n",
      "Epoch 65/100, Train Loss: 0.1693, Val Loss: 0.2648\n",
      "Epoch 66/100, Train Loss: 0.1691, Val Loss: 0.2646\n",
      "Epoch 67/100, Train Loss: 0.1690, Val Loss: 0.2647\n",
      "Epoch 68/100, Train Loss: 0.1689, Val Loss: 0.2647\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: avg, Optimizer: SGD, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 1.1142, Val Loss: 0.6881\n",
      "Epoch 2/250, Train Loss: 0.6393, Val Loss: 0.6017\n",
      "Epoch 3/250, Train Loss: 0.5666, Val Loss: 0.5546\n",
      "Epoch 4/250, Train Loss: 0.5164, Val Loss: 0.5418\n",
      "Epoch 5/250, Train Loss: 0.4802, Val Loss: 0.4783\n",
      "Epoch 6/250, Train Loss: 0.4500, Val Loss: 0.4482\n",
      "Epoch 7/250, Train Loss: 0.4275, Val Loss: 0.4291\n",
      "Epoch 8/250, Train Loss: 0.4085, Val Loss: 0.4259\n",
      "Epoch 9/250, Train Loss: 0.3924, Val Loss: 0.4118\n",
      "Epoch 10/250, Train Loss: 0.3803, Val Loss: 0.3919\n",
      "Epoch 11/250, Train Loss: 0.3698, Val Loss: 0.4091\n",
      "Epoch 12/250, Train Loss: 0.3586, Val Loss: 0.3731\n",
      "Epoch 13/250, Train Loss: 0.3486, Val Loss: 0.3724\n",
      "Epoch 14/250, Train Loss: 0.3410, Val Loss: 0.3678\n",
      "Epoch 15/250, Train Loss: 0.3326, Val Loss: 0.3672\n",
      "Epoch 16/250, Train Loss: 0.3263, Val Loss: 0.3629\n",
      "Epoch 17/250, Train Loss: 0.3190, Val Loss: 0.3439\n",
      "Epoch 18/250, Train Loss: 0.3125, Val Loss: 0.3372\n",
      "Epoch 19/250, Train Loss: 0.3077, Val Loss: 0.3431\n",
      "Epoch 20/250, Train Loss: 0.3014, Val Loss: 0.3459\n",
      "Epoch 21/250, Train Loss: 0.2956, Val Loss: 0.3424\n",
      "Epoch 22/250, Train Loss: 0.2909, Val Loss: 0.3198\n",
      "Epoch 23/250, Train Loss: 0.2855, Val Loss: 0.3253\n",
      "Epoch 24/250, Train Loss: 0.2816, Val Loss: 0.3285\n",
      "Epoch 25/250, Train Loss: 0.2773, Val Loss: 0.3333\n",
      "Epoch 26/250, Train Loss: 0.2743, Val Loss: 0.3128\n",
      "Epoch 27/250, Train Loss: 0.2694, Val Loss: 0.3066\n",
      "Epoch 28/250, Train Loss: 0.2662, Val Loss: 0.3000\n",
      "Epoch 29/250, Train Loss: 0.2624, Val Loss: 0.3100\n",
      "Epoch 30/250, Train Loss: 0.2584, Val Loss: 0.3065\n",
      "Epoch 31/250, Train Loss: 0.2554, Val Loss: 0.2938\n",
      "Epoch 32/250, Train Loss: 0.2510, Val Loss: 0.3484\n",
      "Epoch 33/250, Train Loss: 0.2480, Val Loss: 0.3025\n",
      "Epoch 34/250, Train Loss: 0.2461, Val Loss: 0.3012\n",
      "Epoch 35/250, Train Loss: 0.2417, Val Loss: 0.2952\n",
      "Epoch 36/250, Train Loss: 0.2393, Val Loss: 0.2956\n",
      "Epoch 37/250, Train Loss: 0.2348, Val Loss: 0.3065\n",
      "Epoch 38/250, Train Loss: 0.2163, Val Loss: 0.2805\n",
      "Epoch 39/250, Train Loss: 0.2136, Val Loss: 0.2772\n",
      "Epoch 40/250, Train Loss: 0.2125, Val Loss: 0.2782\n",
      "Epoch 41/250, Train Loss: 0.2121, Val Loss: 0.2769\n",
      "Epoch 42/250, Train Loss: 0.2115, Val Loss: 0.2771\n",
      "Epoch 43/250, Train Loss: 0.2110, Val Loss: 0.2773\n",
      "Epoch 44/250, Train Loss: 0.2105, Val Loss: 0.2775\n",
      "Epoch 45/250, Train Loss: 0.2098, Val Loss: 0.2773\n",
      "Epoch 46/250, Train Loss: 0.2095, Val Loss: 0.2772\n",
      "Epoch 47/250, Train Loss: 0.2090, Val Loss: 0.2764\n",
      "Epoch 48/250, Train Loss: 0.2088, Val Loss: 0.2762\n",
      "Epoch 49/250, Train Loss: 0.2082, Val Loss: 0.2774\n",
      "Epoch 50/250, Train Loss: 0.2077, Val Loss: 0.2768\n",
      "Epoch 51/250, Train Loss: 0.2073, Val Loss: 0.2762\n",
      "Epoch 52/250, Train Loss: 0.2070, Val Loss: 0.2767\n",
      "Epoch 53/250, Train Loss: 0.2065, Val Loss: 0.2781\n",
      "Epoch 54/250, Train Loss: 0.2061, Val Loss: 0.2758\n",
      "Epoch 55/250, Train Loss: 0.2057, Val Loss: 0.2763\n",
      "Epoch 56/250, Train Loss: 0.2052, Val Loss: 0.2748\n",
      "Epoch 57/250, Train Loss: 0.2047, Val Loss: 0.2771\n",
      "Epoch 58/250, Train Loss: 0.2045, Val Loss: 0.2769\n",
      "Epoch 59/250, Train Loss: 0.2039, Val Loss: 0.2758\n",
      "Epoch 60/250, Train Loss: 0.2036, Val Loss: 0.2779\n",
      "Epoch 61/250, Train Loss: 0.2031, Val Loss: 0.2751\n",
      "Epoch 62/250, Train Loss: 0.2028, Val Loss: 0.2750\n",
      "Epoch 63/250, Train Loss: 0.2003, Val Loss: 0.2745\n",
      "Epoch 64/250, Train Loss: 0.2000, Val Loss: 0.2746\n",
      "Epoch 65/250, Train Loss: 0.1999, Val Loss: 0.2746\n",
      "Epoch 66/250, Train Loss: 0.1998, Val Loss: 0.2744\n",
      "Epoch 67/250, Train Loss: 0.1998, Val Loss: 0.2745\n",
      "Epoch 68/250, Train Loss: 0.1997, Val Loss: 0.2746\n",
      "Epoch 69/250, Train Loss: 0.1997, Val Loss: 0.2745\n",
      "Epoch 70/250, Train Loss: 0.1997, Val Loss: 0.2743\n",
      "Epoch 71/250, Train Loss: 0.1996, Val Loss: 0.2743\n",
      "Epoch 72/250, Train Loss: 0.1995, Val Loss: 0.2744\n",
      "Epoch 73/250, Train Loss: 0.1995, Val Loss: 0.2744\n",
      "Epoch 74/250, Train Loss: 0.1995, Val Loss: 0.2745\n",
      "Epoch 75/250, Train Loss: 0.1994, Val Loss: 0.2743\n",
      "Epoch 76/250, Train Loss: 0.1994, Val Loss: 0.2742\n",
      "Epoch 77/250, Train Loss: 0.1993, Val Loss: 0.2743\n",
      "Epoch 78/250, Train Loss: 0.1992, Val Loss: 0.2745\n",
      "Epoch 79/250, Train Loss: 0.1993, Val Loss: 0.2745\n",
      "Epoch 80/250, Train Loss: 0.1992, Val Loss: 0.2744\n",
      "Epoch 81/250, Train Loss: 0.1991, Val Loss: 0.2743\n",
      "Epoch 82/250, Train Loss: 0.1991, Val Loss: 0.2743\n",
      "Epoch 83/250, Train Loss: 0.1988, Val Loss: 0.2743\n",
      "Epoch 84/250, Train Loss: 0.1987, Val Loss: 0.2743\n",
      "Epoch 85/250, Train Loss: 0.1987, Val Loss: 0.2743\n",
      "Epoch 86/250, Train Loss: 0.1987, Val Loss: 0.2743\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: avg, Optimizer: SGD, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 1.1014, Val Loss: 0.7726\n",
      "Epoch 2/350, Train Loss: 0.6498, Val Loss: 0.6025\n",
      "Epoch 3/350, Train Loss: 0.5740, Val Loss: 0.5594\n",
      "Epoch 4/350, Train Loss: 0.5182, Val Loss: 0.5117\n",
      "Epoch 5/350, Train Loss: 0.4788, Val Loss: 0.4903\n",
      "Epoch 6/350, Train Loss: 0.4481, Val Loss: 0.4641\n",
      "Epoch 7/350, Train Loss: 0.4245, Val Loss: 0.4407\n",
      "Epoch 8/350, Train Loss: 0.4081, Val Loss: 0.4852\n",
      "Epoch 9/350, Train Loss: 0.3930, Val Loss: 0.4022\n",
      "Epoch 10/350, Train Loss: 0.3807, Val Loss: 0.4019\n",
      "Epoch 11/350, Train Loss: 0.3695, Val Loss: 0.3876\n",
      "Epoch 12/350, Train Loss: 0.3605, Val Loss: 0.3913\n",
      "Epoch 13/350, Train Loss: 0.3511, Val Loss: 0.3689\n",
      "Epoch 14/350, Train Loss: 0.3425, Val Loss: 0.3730\n",
      "Epoch 15/350, Train Loss: 0.3351, Val Loss: 0.3591\n",
      "Epoch 16/350, Train Loss: 0.3286, Val Loss: 0.3650\n",
      "Epoch 17/350, Train Loss: 0.3224, Val Loss: 0.3564\n",
      "Epoch 18/350, Train Loss: 0.3154, Val Loss: 0.3501\n",
      "Epoch 19/350, Train Loss: 0.3089, Val Loss: 0.3318\n",
      "Epoch 20/350, Train Loss: 0.3047, Val Loss: 0.3328\n",
      "Epoch 21/350, Train Loss: 0.2987, Val Loss: 0.3370\n",
      "Epoch 22/350, Train Loss: 0.2939, Val Loss: 0.3348\n",
      "Epoch 23/350, Train Loss: 0.2890, Val Loss: 0.3357\n",
      "Epoch 24/350, Train Loss: 0.2856, Val Loss: 0.3255\n",
      "Epoch 25/350, Train Loss: 0.2814, Val Loss: 0.3206\n",
      "Epoch 26/350, Train Loss: 0.2762, Val Loss: 0.3218\n",
      "Epoch 27/350, Train Loss: 0.2729, Val Loss: 0.3269\n",
      "Epoch 28/350, Train Loss: 0.2684, Val Loss: 0.3231\n",
      "Epoch 29/350, Train Loss: 0.2647, Val Loss: 0.3144\n",
      "Epoch 30/350, Train Loss: 0.2621, Val Loss: 0.3218\n",
      "Epoch 31/350, Train Loss: 0.2582, Val Loss: 0.3135\n",
      "Epoch 32/350, Train Loss: 0.2558, Val Loss: 0.3023\n",
      "Epoch 33/350, Train Loss: 0.2512, Val Loss: 0.2930\n",
      "Epoch 34/350, Train Loss: 0.2479, Val Loss: 0.3064\n",
      "Epoch 35/350, Train Loss: 0.2438, Val Loss: 0.3092\n",
      "Epoch 36/350, Train Loss: 0.2423, Val Loss: 0.3099\n",
      "Epoch 37/350, Train Loss: 0.2387, Val Loss: 0.3189\n",
      "Epoch 38/350, Train Loss: 0.2358, Val Loss: 0.2924\n",
      "Epoch 39/350, Train Loss: 0.2319, Val Loss: 0.2938\n",
      "Epoch 40/350, Train Loss: 0.2297, Val Loss: 0.2852\n",
      "Epoch 41/350, Train Loss: 0.2282, Val Loss: 0.2928\n",
      "Epoch 42/350, Train Loss: 0.2259, Val Loss: 0.2803\n",
      "Epoch 43/350, Train Loss: 0.2227, Val Loss: 0.2894\n",
      "Epoch 44/350, Train Loss: 0.2193, Val Loss: 0.2806\n",
      "Epoch 45/350, Train Loss: 0.2182, Val Loss: 0.2730\n",
      "Epoch 46/350, Train Loss: 0.2148, Val Loss: 0.2860\n",
      "Epoch 47/350, Train Loss: 0.2125, Val Loss: 0.3090\n",
      "Epoch 48/350, Train Loss: 0.2110, Val Loss: 0.2843\n",
      "Epoch 49/350, Train Loss: 0.2060, Val Loss: 0.2819\n",
      "Epoch 50/350, Train Loss: 0.2055, Val Loss: 0.2775\n",
      "Epoch 51/350, Train Loss: 0.2042, Val Loss: 0.2736\n",
      "Epoch 52/350, Train Loss: 0.1825, Val Loss: 0.2628\n",
      "Epoch 53/350, Train Loss: 0.1801, Val Loss: 0.2633\n",
      "Epoch 54/350, Train Loss: 0.1792, Val Loss: 0.2633\n",
      "Epoch 55/350, Train Loss: 0.1786, Val Loss: 0.2623\n",
      "Epoch 56/350, Train Loss: 0.1783, Val Loss: 0.2626\n",
      "Epoch 57/350, Train Loss: 0.1776, Val Loss: 0.2620\n",
      "Epoch 58/350, Train Loss: 0.1772, Val Loss: 0.2621\n",
      "Epoch 59/350, Train Loss: 0.1767, Val Loss: 0.2621\n",
      "Epoch 60/350, Train Loss: 0.1765, Val Loss: 0.2637\n",
      "Epoch 61/350, Train Loss: 0.1760, Val Loss: 0.2634\n",
      "Epoch 62/350, Train Loss: 0.1756, Val Loss: 0.2642\n",
      "Epoch 63/350, Train Loss: 0.1752, Val Loss: 0.2626\n",
      "Epoch 64/350, Train Loss: 0.1729, Val Loss: 0.2625\n",
      "Epoch 65/350, Train Loss: 0.1727, Val Loss: 0.2622\n",
      "Epoch 66/350, Train Loss: 0.1725, Val Loss: 0.2621\n",
      "Epoch 67/350, Train Loss: 0.1725, Val Loss: 0.2621\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: avg, Optimizer: RMSProp, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 14.8481, Val Loss: 0.5810\n",
      "Epoch 2/5, Train Loss: 0.5368, Val Loss: 0.4660\n",
      "Epoch 3/5, Train Loss: 0.8299, Val Loss: 0.4473\n",
      "Epoch 4/5, Train Loss: 0.4662, Val Loss: 0.4263\n",
      "Epoch 5/5, Train Loss: 0.4158, Val Loss: 0.4048\n",
      "Kernel: 5, Pooling: avg, Optimizer: RMSProp, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 19.2063, Val Loss: 0.5995\n",
      "Epoch 2/50, Train Loss: 0.5410, Val Loss: 0.5005\n",
      "Epoch 3/50, Train Loss: 0.7692, Val Loss: 0.4680\n",
      "Epoch 4/50, Train Loss: 0.6890, Val Loss: 0.5524\n",
      "Epoch 5/50, Train Loss: 0.4596, Val Loss: 0.4251\n",
      "Epoch 6/50, Train Loss: 0.4176, Val Loss: 0.4209\n",
      "Epoch 7/50, Train Loss: 0.3878, Val Loss: 0.3951\n",
      "Epoch 8/50, Train Loss: 0.3989, Val Loss: 0.3805\n",
      "Epoch 9/50, Train Loss: 0.3493, Val Loss: 0.3761\n",
      "Epoch 10/50, Train Loss: 0.3380, Val Loss: 0.4021\n",
      "Epoch 11/50, Train Loss: 0.7279, Val Loss: 0.3672\n",
      "Epoch 12/50, Train Loss: 0.3176, Val Loss: 0.3786\n",
      "Epoch 13/50, Train Loss: 0.3089, Val Loss: 0.3916\n",
      "Epoch 14/50, Train Loss: 0.3144, Val Loss: 0.3981\n",
      "Epoch 15/50, Train Loss: 1.0414, Val Loss: 0.5219\n",
      "Epoch 16/50, Train Loss: 0.3594, Val Loss: 0.3932\n",
      "Epoch 17/50, Train Loss: 0.2954, Val Loss: 0.3773\n",
      "Epoch 18/50, Train Loss: 0.2169, Val Loss: 0.3501\n",
      "Epoch 19/50, Train Loss: 0.1961, Val Loss: 0.3489\n",
      "Epoch 20/50, Train Loss: 0.1849, Val Loss: 0.3659\n",
      "Epoch 21/50, Train Loss: 0.1774, Val Loss: 0.3655\n",
      "Epoch 22/50, Train Loss: 0.1710, Val Loss: 0.3730\n",
      "Epoch 23/50, Train Loss: 0.1651, Val Loss: 0.3885\n",
      "Epoch 24/50, Train Loss: 0.1591, Val Loss: 0.4020\n",
      "Epoch 25/50, Train Loss: 0.1548, Val Loss: 0.4024\n",
      "Epoch 26/50, Train Loss: 0.1428, Val Loss: 0.4126\n",
      "Epoch 27/50, Train Loss: 0.1406, Val Loss: 0.4185\n",
      "Epoch 28/50, Train Loss: 0.1397, Val Loss: 0.4220\n",
      "Epoch 29/50, Train Loss: 0.1388, Val Loss: 0.4220\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: avg, Optimizer: RMSProp, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 32.1915, Val Loss: 0.4549\n",
      "Epoch 2/100, Train Loss: 1.0742, Val Loss: 0.4983\n",
      "Epoch 3/100, Train Loss: 0.6137, Val Loss: 0.4892\n",
      "Epoch 4/100, Train Loss: 0.7935, Val Loss: 0.4050\n",
      "Epoch 5/100, Train Loss: 0.3604, Val Loss: 0.3697\n",
      "Epoch 6/100, Train Loss: 0.4335, Val Loss: 0.5225\n",
      "Epoch 7/100, Train Loss: 0.5489, Val Loss: 0.5021\n",
      "Epoch 8/100, Train Loss: 0.3163, Val Loss: 0.3340\n",
      "Epoch 9/100, Train Loss: 0.3245, Val Loss: 0.3936\n",
      "Epoch 10/100, Train Loss: 0.2992, Val Loss: 0.3568\n",
      "Epoch 11/100, Train Loss: 0.2772, Val Loss: 0.4543\n",
      "Epoch 12/100, Train Loss: 1.4885, Val Loss: 0.4319\n",
      "Epoch 13/100, Train Loss: 0.4309, Val Loss: 0.4404\n",
      "Epoch 14/100, Train Loss: 0.3029, Val Loss: 0.3975\n",
      "Epoch 15/100, Train Loss: 0.2223, Val Loss: 0.3464\n",
      "Epoch 16/100, Train Loss: 0.1880, Val Loss: 0.3382\n",
      "Epoch 17/100, Train Loss: 0.1735, Val Loss: 0.3383\n",
      "Epoch 18/100, Train Loss: 0.1645, Val Loss: 0.3502\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: avg, Optimizer: RMSProp, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 7.1591, Val Loss: 0.4915\n",
      "Epoch 2/250, Train Loss: 0.5289, Val Loss: 0.4772\n",
      "Epoch 3/250, Train Loss: 0.7296, Val Loss: 0.4791\n",
      "Epoch 4/250, Train Loss: 0.5010, Val Loss: 0.4468\n",
      "Epoch 5/250, Train Loss: 0.4042, Val Loss: 0.4062\n",
      "Epoch 6/250, Train Loss: 0.3865, Val Loss: 0.3965\n",
      "Epoch 7/250, Train Loss: 0.3818, Val Loss: 0.3967\n",
      "Epoch 8/250, Train Loss: 0.3700, Val Loss: 0.3726\n",
      "Epoch 9/250, Train Loss: 0.4419, Val Loss: 0.3940\n",
      "Epoch 10/250, Train Loss: 0.4134, Val Loss: 0.3805\n",
      "Epoch 11/250, Train Loss: 0.3375, Val Loss: 0.4221\n",
      "Epoch 12/250, Train Loss: 0.4132, Val Loss: 0.4635\n",
      "Epoch 13/250, Train Loss: 0.3314, Val Loss: 0.4197\n",
      "Epoch 14/250, Train Loss: 0.3185, Val Loss: 0.3720\n",
      "Epoch 15/250, Train Loss: 0.3502, Val Loss: 0.3898\n",
      "Epoch 16/250, Train Loss: 0.3223, Val Loss: 0.3977\n",
      "Epoch 17/250, Train Loss: 0.3066, Val Loss: 0.3898\n",
      "Epoch 18/250, Train Loss: 0.2994, Val Loss: 0.4207\n",
      "Epoch 19/250, Train Loss: 0.2951, Val Loss: 0.7283\n",
      "Epoch 20/250, Train Loss: 0.3963, Val Loss: 0.4213\n",
      "Epoch 21/250, Train Loss: 0.2164, Val Loss: 0.3749\n",
      "Epoch 22/250, Train Loss: 0.1960, Val Loss: 0.3637\n",
      "Epoch 23/250, Train Loss: 0.1856, Val Loss: 0.3659\n",
      "Epoch 24/250, Train Loss: 0.1793, Val Loss: 0.3571\n",
      "Epoch 25/250, Train Loss: 0.1734, Val Loss: 0.3858\n",
      "Epoch 26/250, Train Loss: 0.1685, Val Loss: 0.3965\n",
      "Epoch 27/250, Train Loss: 0.1636, Val Loss: 0.4349\n",
      "Epoch 28/250, Train Loss: 0.1600, Val Loss: 0.3996\n",
      "Epoch 29/250, Train Loss: 0.1557, Val Loss: 0.4214\n",
      "Epoch 30/250, Train Loss: 0.1527, Val Loss: 0.4158\n",
      "Epoch 31/250, Train Loss: 0.1410, Val Loss: 0.4381\n",
      "Epoch 32/250, Train Loss: 0.1389, Val Loss: 0.4380\n",
      "Epoch 33/250, Train Loss: 0.1381, Val Loss: 0.4419\n",
      "Epoch 34/250, Train Loss: 0.1374, Val Loss: 0.4441\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: avg, Optimizer: RMSProp, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 12.5059, Val Loss: 0.5915\n",
      "Epoch 2/350, Train Loss: 0.9004, Val Loss: 0.7811\n",
      "Epoch 3/350, Train Loss: 0.7501, Val Loss: 0.4529\n",
      "Epoch 4/350, Train Loss: 0.4494, Val Loss: 0.5961\n",
      "Epoch 5/350, Train Loss: 0.4353, Val Loss: 0.3743\n",
      "Epoch 6/350, Train Loss: 0.3545, Val Loss: 0.4075\n",
      "Epoch 7/350, Train Loss: 0.3604, Val Loss: 0.3993\n",
      "Epoch 8/350, Train Loss: 0.4099, Val Loss: 0.3796\n",
      "Epoch 9/350, Train Loss: 1.6067, Val Loss: 0.7152\n",
      "Epoch 10/350, Train Loss: 0.4426, Val Loss: 0.3818\n",
      "Epoch 11/350, Train Loss: 0.3203, Val Loss: 0.5452\n",
      "Epoch 12/350, Train Loss: 0.2340, Val Loss: 0.3383\n",
      "Epoch 13/350, Train Loss: 0.2100, Val Loss: 0.3417\n",
      "Epoch 14/350, Train Loss: 0.1977, Val Loss: 0.3483\n",
      "Epoch 15/350, Train Loss: 0.1890, Val Loss: 0.3533\n",
      "Epoch 16/350, Train Loss: 0.1816, Val Loss: 0.3675\n",
      "Epoch 17/350, Train Loss: 0.1751, Val Loss: 0.3620\n",
      "Epoch 18/350, Train Loss: 0.1678, Val Loss: 0.3777\n",
      "Epoch 19/350, Train Loss: 0.1525, Val Loss: 0.3830\n",
      "Epoch 20/350, Train Loss: 0.1502, Val Loss: 0.3826\n",
      "Epoch 21/350, Train Loss: 0.1490, Val Loss: 0.3812\n",
      "Epoch 22/350, Train Loss: 0.1479, Val Loss: 0.3858\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: avg, Optimizer: Adam, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 0.5389, Val Loss: 0.4114\n",
      "Epoch 2/5, Train Loss: 0.3671, Val Loss: 0.3632\n",
      "Epoch 3/5, Train Loss: 0.3383, Val Loss: 0.3740\n",
      "Epoch 4/5, Train Loss: 0.3205, Val Loss: 0.3997\n",
      "Epoch 5/5, Train Loss: 0.3092, Val Loss: 0.3792\n",
      "Kernel: 5, Pooling: avg, Optimizer: Adam, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 0.5640, Val Loss: 0.4023\n",
      "Epoch 2/50, Train Loss: 0.3728, Val Loss: 0.3948\n",
      "Epoch 3/50, Train Loss: 0.3417, Val Loss: 0.3620\n",
      "Epoch 4/50, Train Loss: 0.3237, Val Loss: 0.3477\n",
      "Epoch 5/50, Train Loss: 0.3193, Val Loss: 0.3768\n",
      "Epoch 6/50, Train Loss: 0.3071, Val Loss: 0.3492\n",
      "Epoch 7/50, Train Loss: 0.2930, Val Loss: 0.3251\n",
      "Epoch 8/50, Train Loss: 0.2854, Val Loss: 0.3300\n",
      "Epoch 9/50, Train Loss: 0.2744, Val Loss: 0.3537\n",
      "Epoch 10/50, Train Loss: 0.2816, Val Loss: 0.4543\n",
      "Epoch 11/50, Train Loss: 0.3071, Val Loss: 0.3364\n",
      "Epoch 12/50, Train Loss: 0.2605, Val Loss: 0.3350\n",
      "Epoch 13/50, Train Loss: 0.2578, Val Loss: 0.3438\n",
      "Epoch 14/50, Train Loss: 0.1937, Val Loss: 0.3103\n",
      "Epoch 15/50, Train Loss: 0.1742, Val Loss: 0.3110\n",
      "Epoch 16/50, Train Loss: 0.1655, Val Loss: 0.3111\n",
      "Epoch 17/50, Train Loss: 0.1586, Val Loss: 0.3156\n",
      "Epoch 18/50, Train Loss: 0.1521, Val Loss: 0.3206\n",
      "Epoch 19/50, Train Loss: 0.1474, Val Loss: 0.3306\n",
      "Epoch 20/50, Train Loss: 0.1430, Val Loss: 0.3343\n",
      "Epoch 21/50, Train Loss: 0.1321, Val Loss: 0.3316\n",
      "Epoch 22/50, Train Loss: 0.1300, Val Loss: 0.3329\n",
      "Epoch 23/50, Train Loss: 0.1291, Val Loss: 0.3340\n",
      "Epoch 24/50, Train Loss: 0.1283, Val Loss: 0.3363\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: avg, Optimizer: Adam, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 0.6018, Val Loss: 0.4426\n",
      "Epoch 2/100, Train Loss: 0.4201, Val Loss: 0.4250\n",
      "Epoch 3/100, Train Loss: 0.3871, Val Loss: 0.3939\n",
      "Epoch 4/100, Train Loss: 0.3814, Val Loss: 0.6326\n",
      "Epoch 5/100, Train Loss: 0.3669, Val Loss: 0.4227\n",
      "Epoch 6/100, Train Loss: 0.3438, Val Loss: 0.3781\n",
      "Epoch 7/100, Train Loss: 0.3337, Val Loss: 0.4036\n",
      "Epoch 8/100, Train Loss: 0.3286, Val Loss: 0.3591\n",
      "Epoch 9/100, Train Loss: 0.3212, Val Loss: 0.3565\n",
      "Epoch 10/100, Train Loss: 0.3131, Val Loss: 0.3766\n",
      "Epoch 11/100, Train Loss: 0.3051, Val Loss: 0.3839\n",
      "Epoch 12/100, Train Loss: 0.3015, Val Loss: 0.3642\n",
      "Epoch 13/100, Train Loss: 0.3170, Val Loss: 0.3966\n",
      "Epoch 14/100, Train Loss: 0.2886, Val Loss: 0.3557\n",
      "Epoch 15/100, Train Loss: 0.2858, Val Loss: 0.3814\n",
      "Epoch 16/100, Train Loss: 0.2899, Val Loss: 0.3509\n",
      "Epoch 17/100, Train Loss: 0.2758, Val Loss: 0.3409\n",
      "Epoch 18/100, Train Loss: 0.2790, Val Loss: 0.3584\n",
      "Epoch 19/100, Train Loss: 0.2812, Val Loss: 0.3444\n",
      "Epoch 20/100, Train Loss: 0.2745, Val Loss: 0.3461\n",
      "Epoch 21/100, Train Loss: 0.2626, Val Loss: 0.3672\n",
      "Epoch 22/100, Train Loss: 0.2660, Val Loss: 0.6847\n",
      "Epoch 23/100, Train Loss: 0.2751, Val Loss: 0.3670\n",
      "Epoch 24/100, Train Loss: 0.1979, Val Loss: 0.3301\n",
      "Epoch 25/100, Train Loss: 0.1812, Val Loss: 0.3362\n",
      "Epoch 26/100, Train Loss: 0.1734, Val Loss: 0.3393\n",
      "Epoch 27/100, Train Loss: 0.1681, Val Loss: 0.3498\n",
      "Epoch 28/100, Train Loss: 0.1634, Val Loss: 0.3508\n",
      "Epoch 29/100, Train Loss: 0.1588, Val Loss: 0.3607\n",
      "Epoch 30/100, Train Loss: 0.1553, Val Loss: 0.3612\n",
      "Epoch 31/100, Train Loss: 0.1447, Val Loss: 0.3641\n",
      "Epoch 32/100, Train Loss: 0.1437, Val Loss: 0.3662\n",
      "Epoch 33/100, Train Loss: 0.1430, Val Loss: 0.3674\n",
      "Epoch 34/100, Train Loss: 0.1425, Val Loss: 0.3681\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: avg, Optimizer: Adam, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 0.5090, Val Loss: 0.4042\n",
      "Epoch 2/250, Train Loss: 0.3506, Val Loss: 0.3446\n",
      "Epoch 3/250, Train Loss: 0.3156, Val Loss: 0.3483\n",
      "Epoch 4/250, Train Loss: 0.3096, Val Loss: 0.3770\n",
      "Epoch 5/250, Train Loss: 0.2799, Val Loss: 0.3512\n",
      "Epoch 6/250, Train Loss: 0.2693, Val Loss: 0.3682\n",
      "Epoch 7/250, Train Loss: 0.2619, Val Loss: 0.3634\n",
      "Epoch 8/250, Train Loss: 0.2528, Val Loss: 0.3632\n",
      "Epoch 9/250, Train Loss: 0.1820, Val Loss: 0.3128\n",
      "Epoch 10/250, Train Loss: 0.1534, Val Loss: 0.3204\n",
      "Epoch 11/250, Train Loss: 0.1402, Val Loss: 0.3233\n",
      "Epoch 12/250, Train Loss: 0.1298, Val Loss: 0.3334\n",
      "Epoch 13/250, Train Loss: 0.1208, Val Loss: 0.3551\n",
      "Epoch 14/250, Train Loss: 0.1129, Val Loss: 0.3567\n",
      "Epoch 15/250, Train Loss: 0.1057, Val Loss: 0.3616\n",
      "Epoch 16/250, Train Loss: 0.0923, Val Loss: 0.3676\n",
      "Epoch 17/250, Train Loss: 0.0895, Val Loss: 0.3706\n",
      "Epoch 18/250, Train Loss: 0.0882, Val Loss: 0.3750\n",
      "Epoch 19/250, Train Loss: 0.0872, Val Loss: 0.3764\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 5, Pooling: avg, Optimizer: Adam, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 2.3228, Val Loss: 2.3032\n",
      "Epoch 2/350, Train Loss: 2.3036, Val Loss: 2.3029\n",
      "Epoch 3/350, Train Loss: 2.3034, Val Loss: 2.3041\n",
      "Epoch 4/350, Train Loss: 2.3037, Val Loss: 2.3031\n",
      "Epoch 5/350, Train Loss: 2.3034, Val Loss: 2.3032\n",
      "Epoch 6/350, Train Loss: 2.3035, Val Loss: 2.3036\n",
      "Epoch 7/350, Train Loss: 2.3035, Val Loss: 2.3042\n",
      "Epoch 8/350, Train Loss: 2.3037, Val Loss: 2.3027\n",
      "Epoch 9/350, Train Loss: 2.3028, Val Loss: 2.3027\n",
      "Epoch 10/350, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 11/350, Train Loss: 2.3027, Val Loss: 2.3026\n",
      "Epoch 12/350, Train Loss: 2.3027, Val Loss: 2.3028\n",
      "Epoch 13/350, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 14/350, Train Loss: 2.3027, Val Loss: 2.3028\n",
      "Epoch 15/350, Train Loss: 2.3027, Val Loss: 2.3028\n",
      "Epoch 16/350, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 17/350, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 18/350, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 19/350, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 20/350, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 21/350, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: max, Optimizer: SGD, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 0.9398, Val Loss: 0.6213\n",
      "Epoch 2/5, Train Loss: 0.5484, Val Loss: 0.5145\n",
      "Epoch 3/5, Train Loss: 0.4637, Val Loss: 0.4351\n",
      "Epoch 4/5, Train Loss: 0.4136, Val Loss: 0.4239\n",
      "Epoch 5/5, Train Loss: 0.3820, Val Loss: 0.3834\n",
      "Kernel: 7, Pooling: max, Optimizer: SGD, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 0.8930, Val Loss: 0.5903\n",
      "Epoch 2/50, Train Loss: 0.5357, Val Loss: 0.5057\n",
      "Epoch 3/50, Train Loss: 0.4560, Val Loss: 0.4389\n",
      "Epoch 4/50, Train Loss: 0.4101, Val Loss: 0.4163\n",
      "Epoch 5/50, Train Loss: 0.3791, Val Loss: 0.3892\n",
      "Epoch 6/50, Train Loss: 0.3572, Val Loss: 0.3634\n",
      "Epoch 7/50, Train Loss: 0.3394, Val Loss: 0.3822\n",
      "Epoch 8/50, Train Loss: 0.3246, Val Loss: 0.3382\n",
      "Epoch 9/50, Train Loss: 0.3110, Val Loss: 0.3331\n",
      "Epoch 10/50, Train Loss: 0.3000, Val Loss: 0.3301\n",
      "Epoch 11/50, Train Loss: 0.2910, Val Loss: 0.3342\n",
      "Epoch 12/50, Train Loss: 0.2819, Val Loss: 0.3101\n",
      "Epoch 13/50, Train Loss: 0.2712, Val Loss: 0.3014\n",
      "Epoch 14/50, Train Loss: 0.2647, Val Loss: 0.3025\n",
      "Epoch 15/50, Train Loss: 0.2576, Val Loss: 0.2967\n",
      "Epoch 16/50, Train Loss: 0.2517, Val Loss: 0.2918\n",
      "Epoch 17/50, Train Loss: 0.2438, Val Loss: 0.2877\n",
      "Epoch 18/50, Train Loss: 0.2392, Val Loss: 0.2970\n",
      "Epoch 19/50, Train Loss: 0.2317, Val Loss: 0.2910\n",
      "Epoch 20/50, Train Loss: 0.2270, Val Loss: 0.2814\n",
      "Epoch 21/50, Train Loss: 0.2218, Val Loss: 0.2845\n",
      "Epoch 22/50, Train Loss: 0.2163, Val Loss: 0.2718\n",
      "Epoch 23/50, Train Loss: 0.2119, Val Loss: 0.3092\n",
      "Epoch 24/50, Train Loss: 0.2061, Val Loss: 0.2695\n",
      "Epoch 25/50, Train Loss: 0.2014, Val Loss: 0.2654\n",
      "Epoch 26/50, Train Loss: 0.1960, Val Loss: 0.2641\n",
      "Epoch 27/50, Train Loss: 0.1916, Val Loss: 0.2647\n",
      "Epoch 28/50, Train Loss: 0.1864, Val Loss: 0.2718\n",
      "Epoch 29/50, Train Loss: 0.1833, Val Loss: 0.2718\n",
      "Epoch 30/50, Train Loss: 0.1793, Val Loss: 0.2536\n",
      "Epoch 31/50, Train Loss: 0.1747, Val Loss: 0.2534\n",
      "Epoch 32/50, Train Loss: 0.1697, Val Loss: 0.2544\n",
      "Epoch 33/50, Train Loss: 0.1663, Val Loss: 0.2657\n",
      "Epoch 34/50, Train Loss: 0.1612, Val Loss: 0.2649\n",
      "Epoch 35/50, Train Loss: 0.1569, Val Loss: 0.2693\n",
      "Epoch 36/50, Train Loss: 0.1533, Val Loss: 0.2528\n",
      "Epoch 37/50, Train Loss: 0.1500, Val Loss: 0.2579\n",
      "Epoch 38/50, Train Loss: 0.1457, Val Loss: 0.2578\n",
      "Epoch 39/50, Train Loss: 0.1422, Val Loss: 0.2776\n",
      "Epoch 40/50, Train Loss: 0.1386, Val Loss: 0.2588\n",
      "Epoch 41/50, Train Loss: 0.1336, Val Loss: 0.2734\n",
      "Epoch 42/50, Train Loss: 0.1298, Val Loss: 0.2603\n",
      "Epoch 43/50, Train Loss: 0.1070, Val Loss: 0.2454\n",
      "Epoch 44/50, Train Loss: 0.1042, Val Loss: 0.2458\n",
      "Epoch 45/50, Train Loss: 0.1030, Val Loss: 0.2453\n",
      "Epoch 46/50, Train Loss: 0.1022, Val Loss: 0.2458\n",
      "Epoch 47/50, Train Loss: 0.1015, Val Loss: 0.2469\n",
      "Epoch 48/50, Train Loss: 0.1009, Val Loss: 0.2463\n",
      "Epoch 49/50, Train Loss: 0.1000, Val Loss: 0.2477\n",
      "Epoch 50/50, Train Loss: 0.0995, Val Loss: 0.2471\n",
      "Kernel: 7, Pooling: max, Optimizer: SGD, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 0.9007, Val Loss: 0.6179\n",
      "Epoch 2/100, Train Loss: 0.5492, Val Loss: 0.5048\n",
      "Epoch 3/100, Train Loss: 0.4650, Val Loss: 0.4446\n",
      "Epoch 4/100, Train Loss: 0.4141, Val Loss: 0.4075\n",
      "Epoch 5/100, Train Loss: 0.3802, Val Loss: 0.3879\n",
      "Epoch 6/100, Train Loss: 0.3567, Val Loss: 0.3640\n",
      "Epoch 7/100, Train Loss: 0.3388, Val Loss: 0.3481\n",
      "Epoch 8/100, Train Loss: 0.3236, Val Loss: 0.3461\n",
      "Epoch 9/100, Train Loss: 0.3104, Val Loss: 0.3319\n",
      "Epoch 10/100, Train Loss: 0.2988, Val Loss: 0.3399\n",
      "Epoch 11/100, Train Loss: 0.2880, Val Loss: 0.3318\n",
      "Epoch 12/100, Train Loss: 0.2788, Val Loss: 0.3197\n",
      "Epoch 13/100, Train Loss: 0.2707, Val Loss: 0.3176\n",
      "Epoch 14/100, Train Loss: 0.2618, Val Loss: 0.2949\n",
      "Epoch 15/100, Train Loss: 0.2545, Val Loss: 0.3048\n",
      "Epoch 16/100, Train Loss: 0.2475, Val Loss: 0.2978\n",
      "Epoch 17/100, Train Loss: 0.2417, Val Loss: 0.2840\n",
      "Epoch 18/100, Train Loss: 0.2335, Val Loss: 0.2998\n",
      "Epoch 19/100, Train Loss: 0.2286, Val Loss: 0.2836\n",
      "Epoch 20/100, Train Loss: 0.2232, Val Loss: 0.2985\n",
      "Epoch 21/100, Train Loss: 0.2183, Val Loss: 0.2861\n",
      "Epoch 22/100, Train Loss: 0.2126, Val Loss: 0.2758\n",
      "Epoch 23/100, Train Loss: 0.2082, Val Loss: 0.2799\n",
      "Epoch 24/100, Train Loss: 0.2031, Val Loss: 0.2674\n",
      "Epoch 25/100, Train Loss: 0.1978, Val Loss: 0.2655\n",
      "Epoch 26/100, Train Loss: 0.1936, Val Loss: 0.2682\n",
      "Epoch 27/100, Train Loss: 0.1895, Val Loss: 0.2670\n",
      "Epoch 28/100, Train Loss: 0.1838, Val Loss: 0.2639\n",
      "Epoch 29/100, Train Loss: 0.1799, Val Loss: 0.2712\n",
      "Epoch 30/100, Train Loss: 0.1757, Val Loss: 0.2680\n",
      "Epoch 31/100, Train Loss: 0.1709, Val Loss: 0.2684\n",
      "Epoch 32/100, Train Loss: 0.1667, Val Loss: 0.2561\n",
      "Epoch 33/100, Train Loss: 0.1637, Val Loss: 0.2766\n",
      "Epoch 34/100, Train Loss: 0.1589, Val Loss: 0.2687\n",
      "Epoch 35/100, Train Loss: 0.1551, Val Loss: 0.2601\n",
      "Epoch 36/100, Train Loss: 0.1518, Val Loss: 0.2706\n",
      "Epoch 37/100, Train Loss: 0.1460, Val Loss: 0.2569\n",
      "Epoch 38/100, Train Loss: 0.1429, Val Loss: 0.2513\n",
      "Epoch 39/100, Train Loss: 0.1384, Val Loss: 0.2558\n",
      "Epoch 40/100, Train Loss: 0.1344, Val Loss: 0.2504\n",
      "Epoch 41/100, Train Loss: 0.1318, Val Loss: 0.2697\n",
      "Epoch 42/100, Train Loss: 0.1272, Val Loss: 0.2604\n",
      "Epoch 43/100, Train Loss: 0.1237, Val Loss: 0.2553\n",
      "Epoch 44/100, Train Loss: 0.1200, Val Loss: 0.2627\n",
      "Epoch 45/100, Train Loss: 0.1161, Val Loss: 0.2615\n",
      "Epoch 46/100, Train Loss: 0.1121, Val Loss: 0.2549\n",
      "Epoch 47/100, Train Loss: 0.0887, Val Loss: 0.2487\n",
      "Epoch 48/100, Train Loss: 0.0860, Val Loss: 0.2497\n",
      "Epoch 49/100, Train Loss: 0.0849, Val Loss: 0.2497\n",
      "Epoch 50/100, Train Loss: 0.0841, Val Loss: 0.2497\n",
      "Epoch 51/100, Train Loss: 0.0832, Val Loss: 0.2496\n",
      "Epoch 52/100, Train Loss: 0.0826, Val Loss: 0.2502\n",
      "Epoch 53/100, Train Loss: 0.0820, Val Loss: 0.2526\n",
      "Epoch 54/100, Train Loss: 0.0799, Val Loss: 0.2509\n",
      "Epoch 55/100, Train Loss: 0.0797, Val Loss: 0.2506\n",
      "Epoch 56/100, Train Loss: 0.0796, Val Loss: 0.2505\n",
      "Epoch 57/100, Train Loss: 0.0795, Val Loss: 0.2504\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: max, Optimizer: SGD, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 0.9235, Val Loss: 0.6210\n",
      "Epoch 2/250, Train Loss: 0.5512, Val Loss: 0.5179\n",
      "Epoch 3/250, Train Loss: 0.4682, Val Loss: 0.4696\n",
      "Epoch 4/250, Train Loss: 0.4136, Val Loss: 0.4103\n",
      "Epoch 5/250, Train Loss: 0.3827, Val Loss: 0.4455\n",
      "Epoch 6/250, Train Loss: 0.3593, Val Loss: 0.3625\n",
      "Epoch 7/250, Train Loss: 0.3392, Val Loss: 0.3614\n",
      "Epoch 8/250, Train Loss: 0.3242, Val Loss: 0.3386\n",
      "Epoch 9/250, Train Loss: 0.3112, Val Loss: 0.3354\n",
      "Epoch 10/250, Train Loss: 0.2991, Val Loss: 0.3390\n",
      "Epoch 11/250, Train Loss: 0.2885, Val Loss: 0.3290\n",
      "Epoch 12/250, Train Loss: 0.2793, Val Loss: 0.3262\n",
      "Epoch 13/250, Train Loss: 0.2707, Val Loss: 0.3041\n",
      "Epoch 14/250, Train Loss: 0.2634, Val Loss: 0.2983\n",
      "Epoch 15/250, Train Loss: 0.2558, Val Loss: 0.2918\n",
      "Epoch 16/250, Train Loss: 0.2504, Val Loss: 0.2904\n",
      "Epoch 17/250, Train Loss: 0.2430, Val Loss: 0.2989\n",
      "Epoch 18/250, Train Loss: 0.2362, Val Loss: 0.2853\n",
      "Epoch 19/250, Train Loss: 0.2299, Val Loss: 0.2792\n",
      "Epoch 20/250, Train Loss: 0.2253, Val Loss: 0.2889\n",
      "Epoch 21/250, Train Loss: 0.2196, Val Loss: 0.2787\n",
      "Epoch 22/250, Train Loss: 0.2138, Val Loss: 0.2734\n",
      "Epoch 23/250, Train Loss: 0.2093, Val Loss: 0.2663\n",
      "Epoch 24/250, Train Loss: 0.2038, Val Loss: 0.2710\n",
      "Epoch 25/250, Train Loss: 0.2007, Val Loss: 0.2633\n",
      "Epoch 26/250, Train Loss: 0.1955, Val Loss: 0.2616\n",
      "Epoch 27/250, Train Loss: 0.1905, Val Loss: 0.2621\n",
      "Epoch 28/250, Train Loss: 0.1870, Val Loss: 0.2628\n",
      "Epoch 29/250, Train Loss: 0.1819, Val Loss: 0.2684\n",
      "Epoch 30/250, Train Loss: 0.1777, Val Loss: 0.2564\n",
      "Epoch 31/250, Train Loss: 0.1732, Val Loss: 0.2502\n",
      "Epoch 32/250, Train Loss: 0.1683, Val Loss: 0.2536\n",
      "Epoch 33/250, Train Loss: 0.1644, Val Loss: 0.2694\n",
      "Epoch 34/250, Train Loss: 0.1602, Val Loss: 0.2604\n",
      "Epoch 35/250, Train Loss: 0.1564, Val Loss: 0.2569\n",
      "Epoch 36/250, Train Loss: 0.1527, Val Loss: 0.2540\n",
      "Epoch 37/250, Train Loss: 0.1485, Val Loss: 0.2493\n",
      "Epoch 38/250, Train Loss: 0.1456, Val Loss: 0.3042\n",
      "Epoch 39/250, Train Loss: 0.1414, Val Loss: 0.2507\n",
      "Epoch 40/250, Train Loss: 0.1374, Val Loss: 0.2476\n",
      "Epoch 41/250, Train Loss: 0.1346, Val Loss: 0.2547\n",
      "Epoch 42/250, Train Loss: 0.1287, Val Loss: 0.2527\n",
      "Epoch 43/250, Train Loss: 0.1258, Val Loss: 0.2807\n",
      "Epoch 44/250, Train Loss: 0.1225, Val Loss: 0.2542\n",
      "Epoch 45/250, Train Loss: 0.1180, Val Loss: 0.2558\n",
      "Epoch 46/250, Train Loss: 0.1149, Val Loss: 0.2491\n",
      "Epoch 47/250, Train Loss: 0.0913, Val Loss: 0.2437\n",
      "Epoch 48/250, Train Loss: 0.0885, Val Loss: 0.2434\n",
      "Epoch 49/250, Train Loss: 0.0874, Val Loss: 0.2470\n",
      "Epoch 50/250, Train Loss: 0.0866, Val Loss: 0.2454\n",
      "Epoch 51/250, Train Loss: 0.0858, Val Loss: 0.2466\n",
      "Epoch 52/250, Train Loss: 0.0852, Val Loss: 0.2458\n",
      "Epoch 53/250, Train Loss: 0.0846, Val Loss: 0.2479\n",
      "Epoch 54/250, Train Loss: 0.0841, Val Loss: 0.2480\n",
      "Epoch 55/250, Train Loss: 0.0819, Val Loss: 0.2467\n",
      "Epoch 56/250, Train Loss: 0.0817, Val Loss: 0.2466\n",
      "Epoch 57/250, Train Loss: 0.0816, Val Loss: 0.2469\n",
      "Epoch 58/250, Train Loss: 0.0815, Val Loss: 0.2467\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: max, Optimizer: SGD, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 0.9418, Val Loss: 0.6133\n",
      "Epoch 2/350, Train Loss: 0.5509, Val Loss: 0.5432\n",
      "Epoch 3/350, Train Loss: 0.4662, Val Loss: 0.4612\n",
      "Epoch 4/350, Train Loss: 0.4161, Val Loss: 0.4315\n",
      "Epoch 5/350, Train Loss: 0.3835, Val Loss: 0.3930\n",
      "Epoch 6/350, Train Loss: 0.3610, Val Loss: 0.3644\n",
      "Epoch 7/350, Train Loss: 0.3413, Val Loss: 0.3557\n",
      "Epoch 8/350, Train Loss: 0.3261, Val Loss: 0.3450\n",
      "Epoch 9/350, Train Loss: 0.3131, Val Loss: 0.3328\n",
      "Epoch 10/350, Train Loss: 0.2999, Val Loss: 0.3253\n",
      "Epoch 11/350, Train Loss: 0.2900, Val Loss: 0.3233\n",
      "Epoch 12/350, Train Loss: 0.2813, Val Loss: 0.3065\n",
      "Epoch 13/350, Train Loss: 0.2732, Val Loss: 0.3018\n",
      "Epoch 14/350, Train Loss: 0.2645, Val Loss: 0.2986\n",
      "Epoch 15/350, Train Loss: 0.2578, Val Loss: 0.2991\n",
      "Epoch 16/350, Train Loss: 0.2502, Val Loss: 0.2920\n",
      "Epoch 17/350, Train Loss: 0.2450, Val Loss: 0.2922\n",
      "Epoch 18/350, Train Loss: 0.2386, Val Loss: 0.2888\n",
      "Epoch 19/350, Train Loss: 0.2332, Val Loss: 0.2819\n",
      "Epoch 20/350, Train Loss: 0.2276, Val Loss: 0.2816\n",
      "Epoch 21/350, Train Loss: 0.2224, Val Loss: 0.2800\n",
      "Epoch 22/350, Train Loss: 0.2172, Val Loss: 0.2748\n",
      "Epoch 23/350, Train Loss: 0.2114, Val Loss: 0.2834\n",
      "Epoch 24/350, Train Loss: 0.2053, Val Loss: 0.3165\n",
      "Epoch 25/350, Train Loss: 0.2027, Val Loss: 0.2714\n",
      "Epoch 26/350, Train Loss: 0.1976, Val Loss: 0.2660\n",
      "Epoch 27/350, Train Loss: 0.1917, Val Loss: 0.2595\n",
      "Epoch 28/350, Train Loss: 0.1877, Val Loss: 0.2547\n",
      "Epoch 29/350, Train Loss: 0.1820, Val Loss: 0.2692\n",
      "Epoch 30/350, Train Loss: 0.1794, Val Loss: 0.2586\n",
      "Epoch 31/350, Train Loss: 0.1747, Val Loss: 0.2501\n",
      "Epoch 32/350, Train Loss: 0.1702, Val Loss: 0.2744\n",
      "Epoch 33/350, Train Loss: 0.1672, Val Loss: 0.2640\n",
      "Epoch 34/350, Train Loss: 0.1632, Val Loss: 0.2566\n",
      "Epoch 35/350, Train Loss: 0.1581, Val Loss: 0.2535\n",
      "Epoch 36/350, Train Loss: 0.1528, Val Loss: 0.2696\n",
      "Epoch 37/350, Train Loss: 0.1490, Val Loss: 0.2543\n",
      "Epoch 38/350, Train Loss: 0.1267, Val Loss: 0.2415\n",
      "Epoch 39/350, Train Loss: 0.1240, Val Loss: 0.2406\n",
      "Epoch 40/350, Train Loss: 0.1229, Val Loss: 0.2408\n",
      "Epoch 41/350, Train Loss: 0.1221, Val Loss: 0.2407\n",
      "Epoch 42/350, Train Loss: 0.1213, Val Loss: 0.2416\n",
      "Epoch 43/350, Train Loss: 0.1205, Val Loss: 0.2420\n",
      "Epoch 44/350, Train Loss: 0.1199, Val Loss: 0.2409\n",
      "Epoch 45/350, Train Loss: 0.1192, Val Loss: 0.2415\n",
      "Epoch 46/350, Train Loss: 0.1171, Val Loss: 0.2410\n",
      "Epoch 47/350, Train Loss: 0.1168, Val Loss: 0.2410\n",
      "Epoch 48/350, Train Loss: 0.1167, Val Loss: 0.2412\n",
      "Epoch 49/350, Train Loss: 0.1166, Val Loss: 0.2410\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: max, Optimizer: RMSProp, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 36.3139, Val Loss: 2.3042\n",
      "Epoch 2/5, Train Loss: 2.3040, Val Loss: 2.3038\n",
      "Epoch 3/5, Train Loss: 2.3037, Val Loss: 2.3036\n",
      "Epoch 4/5, Train Loss: 2.3035, Val Loss: 2.3052\n",
      "Epoch 5/5, Train Loss: 2.3036, Val Loss: 2.3045\n",
      "Kernel: 7, Pooling: max, Optimizer: RMSProp, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 48.1492, Val Loss: 0.6334\n",
      "Epoch 2/50, Train Loss: 1.0641, Val Loss: 0.5418\n",
      "Epoch 3/50, Train Loss: 0.8577, Val Loss: 0.5486\n",
      "Epoch 4/50, Train Loss: 0.6628, Val Loss: 0.4846\n",
      "Epoch 5/50, Train Loss: 0.5004, Val Loss: 0.5766\n",
      "Epoch 6/50, Train Loss: 1.1679, Val Loss: 0.5115\n",
      "Epoch 7/50, Train Loss: 0.5199, Val Loss: 0.4553\n",
      "Epoch 8/50, Train Loss: 0.4943, Val Loss: 0.5153\n",
      "Epoch 9/50, Train Loss: 0.4845, Val Loss: 0.5222\n",
      "Epoch 10/50, Train Loss: 0.5048, Val Loss: 0.4451\n",
      "Epoch 11/50, Train Loss: 0.5842, Val Loss: 0.5104\n",
      "Epoch 12/50, Train Loss: 0.5486, Val Loss: 0.4780\n",
      "Epoch 13/50, Train Loss: 0.5145, Val Loss: 0.5490\n",
      "Epoch 14/50, Train Loss: 0.4811, Val Loss: 0.4984\n",
      "Epoch 15/50, Train Loss: 0.4552, Val Loss: 0.4867\n",
      "Epoch 16/50, Train Loss: 0.4685, Val Loss: 0.4657\n",
      "Epoch 17/50, Train Loss: 0.3216, Val Loss: 0.4157\n",
      "Epoch 18/50, Train Loss: 0.2940, Val Loss: 0.3877\n",
      "Epoch 19/50, Train Loss: 0.2813, Val Loss: 0.3975\n",
      "Epoch 20/50, Train Loss: 0.2721, Val Loss: 0.3901\n",
      "Epoch 21/50, Train Loss: 0.2648, Val Loss: 0.3911\n",
      "Epoch 22/50, Train Loss: 0.2610, Val Loss: 0.4053\n",
      "Epoch 23/50, Train Loss: 0.2531, Val Loss: 0.4374\n",
      "Epoch 24/50, Train Loss: 0.2499, Val Loss: 0.3978\n",
      "Epoch 25/50, Train Loss: 0.2355, Val Loss: 0.4124\n",
      "Epoch 26/50, Train Loss: 0.2316, Val Loss: 0.4159\n",
      "Epoch 27/50, Train Loss: 0.2303, Val Loss: 0.4176\n",
      "Epoch 28/50, Train Loss: 0.2290, Val Loss: 0.4218\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: max, Optimizer: RMSProp, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 66.5820, Val Loss: 2.3056\n",
      "Epoch 2/100, Train Loss: 2.3087, Val Loss: 2.3046\n",
      "Epoch 3/100, Train Loss: 2.3043, Val Loss: 2.3036\n",
      "Epoch 4/100, Train Loss: 2.3039, Val Loss: 2.3041\n",
      "Epoch 5/100, Train Loss: 2.3035, Val Loss: 2.3032\n",
      "Epoch 6/100, Train Loss: 2.3036, Val Loss: 2.3033\n",
      "Epoch 7/100, Train Loss: 2.3036, Val Loss: 2.3034\n",
      "Epoch 8/100, Train Loss: 2.3036, Val Loss: 2.3029\n",
      "Epoch 9/100, Train Loss: 2.3036, Val Loss: 2.3028\n",
      "Epoch 10/100, Train Loss: 2.3036, Val Loss: 2.3037\n",
      "Epoch 11/100, Train Loss: 2.3036, Val Loss: 2.3030\n",
      "Epoch 12/100, Train Loss: 2.3037, Val Loss: 2.3030\n",
      "Epoch 13/100, Train Loss: 2.3035, Val Loss: 2.3033\n",
      "Epoch 14/100, Train Loss: 2.3036, Val Loss: 2.3035\n",
      "Epoch 15/100, Train Loss: 2.3029, Val Loss: 2.3028\n",
      "Epoch 16/100, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 17/100, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 18/100, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 19/100, Train Loss: 2.3027, Val Loss: 2.3028\n",
      "Epoch 20/100, Train Loss: 2.3027, Val Loss: 2.3026\n",
      "Epoch 21/100, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 22/100, Train Loss: 2.3027, Val Loss: 2.3028\n",
      "Epoch 23/100, Train Loss: 2.3027, Val Loss: 2.3028\n",
      "Epoch 24/100, Train Loss: 2.3026, Val Loss: 2.3028\n",
      "Epoch 25/100, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 26/100, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 27/100, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 28/100, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 29/100, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 30/100, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: max, Optimizer: RMSProp, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 33.1027, Val Loss: 2.3043\n",
      "Epoch 2/250, Train Loss: 2.3038, Val Loss: 2.3036\n",
      "Epoch 3/250, Train Loss: 2.3037, Val Loss: 2.3033\n",
      "Epoch 4/250, Train Loss: 2.3035, Val Loss: 2.3044\n",
      "Epoch 5/250, Train Loss: 2.3036, Val Loss: 2.3035\n",
      "Epoch 6/250, Train Loss: 2.3035, Val Loss: 2.3034\n",
      "Epoch 7/250, Train Loss: 2.3036, Val Loss: 2.3048\n",
      "Epoch 8/250, Train Loss: 2.3034, Val Loss: 2.3036\n",
      "Epoch 9/250, Train Loss: 2.3037, Val Loss: 2.3034\n",
      "Epoch 10/250, Train Loss: 2.3029, Val Loss: 2.3028\n",
      "Epoch 11/250, Train Loss: 2.3027, Val Loss: 2.3028\n",
      "Epoch 12/250, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 13/250, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 14/250, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 15/250, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 16/250, Train Loss: 2.3027, Val Loss: 2.3028\n",
      "Epoch 17/250, Train Loss: 2.3026, Val Loss: 2.3028\n",
      "Epoch 18/250, Train Loss: 2.3026, Val Loss: 2.3028\n",
      "Epoch 19/250, Train Loss: 2.3026, Val Loss: 2.3028\n",
      "Epoch 20/250, Train Loss: 2.3026, Val Loss: 2.3028\n",
      "Epoch 21/250, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 22/250, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 23/250, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 24/250, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: max, Optimizer: RMSProp, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 57.1321, Val Loss: 0.6767\n",
      "Epoch 2/350, Train Loss: 0.6428, Val Loss: 0.5470\n",
      "Epoch 3/350, Train Loss: 1.2545, Val Loss: 1.2195\n",
      "Epoch 4/350, Train Loss: 0.8461, Val Loss: 0.5881\n",
      "Epoch 5/350, Train Loss: 0.5372, Val Loss: 0.7540\n",
      "Epoch 6/350, Train Loss: 0.4846, Val Loss: 0.4907\n",
      "Epoch 7/350, Train Loss: 0.5156, Val Loss: 0.5044\n",
      "Epoch 8/350, Train Loss: 0.4391, Val Loss: 0.5239\n",
      "Epoch 9/350, Train Loss: 0.4908, Val Loss: 0.4767\n",
      "Epoch 10/350, Train Loss: 0.4374, Val Loss: 0.5104\n",
      "Epoch 11/350, Train Loss: 0.4771, Val Loss: 0.4553\n",
      "Epoch 12/350, Train Loss: 0.5366, Val Loss: 0.4719\n",
      "Epoch 13/350, Train Loss: 0.6814, Val Loss: 1.6569\n",
      "Epoch 14/350, Train Loss: 0.4763, Val Loss: 0.5342\n",
      "Epoch 15/350, Train Loss: 0.4434, Val Loss: 0.4992\n",
      "Epoch 16/350, Train Loss: 0.4266, Val Loss: 0.5174\n",
      "Epoch 17/350, Train Loss: 0.8115, Val Loss: 0.8985\n",
      "Epoch 18/350, Train Loss: 0.3385, Val Loss: 0.4146\n",
      "Epoch 19/350, Train Loss: 0.2856, Val Loss: 0.3900\n",
      "Epoch 20/350, Train Loss: 0.2678, Val Loss: 0.3946\n",
      "Epoch 21/350, Train Loss: 0.2554, Val Loss: 0.3946\n",
      "Epoch 22/350, Train Loss: 0.2443, Val Loss: 0.3946\n",
      "Epoch 23/350, Train Loss: 0.2389, Val Loss: 0.3928\n",
      "Epoch 24/350, Train Loss: 0.2295, Val Loss: 0.4248\n",
      "Epoch 25/350, Train Loss: 0.2240, Val Loss: 0.4332\n",
      "Epoch 26/350, Train Loss: 0.2088, Val Loss: 0.4311\n",
      "Epoch 27/350, Train Loss: 0.2055, Val Loss: 0.4332\n",
      "Epoch 28/350, Train Loss: 0.2036, Val Loss: 0.4401\n",
      "Epoch 29/350, Train Loss: 0.2025, Val Loss: 0.4424\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: max, Optimizer: Adam, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 0.7282, Val Loss: 0.5085\n",
      "Epoch 2/5, Train Loss: 0.4684, Val Loss: 0.4486\n",
      "Epoch 3/5, Train Loss: 0.4496, Val Loss: 0.4988\n",
      "Epoch 4/5, Train Loss: 0.4417, Val Loss: 0.4569\n",
      "Epoch 5/5, Train Loss: 0.4277, Val Loss: 0.4910\n",
      "Kernel: 7, Pooling: max, Optimizer: Adam, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 0.7382, Val Loss: 0.5473\n",
      "Epoch 2/50, Train Loss: 0.5033, Val Loss: 0.5097\n",
      "Epoch 3/50, Train Loss: 0.4681, Val Loss: 0.5234\n",
      "Epoch 4/50, Train Loss: 0.4577, Val Loss: 0.4668\n",
      "Epoch 5/50, Train Loss: 0.4339, Val Loss: 0.4544\n",
      "Epoch 6/50, Train Loss: 0.4322, Val Loss: 0.4794\n",
      "Epoch 7/50, Train Loss: 0.4369, Val Loss: 0.4613\n",
      "Epoch 8/50, Train Loss: 0.4212, Val Loss: 0.4416\n",
      "Epoch 9/50, Train Loss: 0.4220, Val Loss: 0.4561\n",
      "Epoch 10/50, Train Loss: 0.4058, Val Loss: 0.4495\n",
      "Epoch 11/50, Train Loss: 0.4145, Val Loss: 0.4592\n",
      "Epoch 12/50, Train Loss: 0.4133, Val Loss: 0.4650\n",
      "Epoch 13/50, Train Loss: 0.4065, Val Loss: 0.4450\n",
      "Epoch 14/50, Train Loss: 0.3976, Val Loss: 0.4647\n",
      "Epoch 15/50, Train Loss: 0.3204, Val Loss: 0.3743\n",
      "Epoch 16/50, Train Loss: 0.2942, Val Loss: 0.3663\n",
      "Epoch 17/50, Train Loss: 0.2832, Val Loss: 0.3578\n",
      "Epoch 18/50, Train Loss: 0.2756, Val Loss: 0.3598\n",
      "Epoch 19/50, Train Loss: 0.2695, Val Loss: 0.3663\n",
      "Epoch 20/50, Train Loss: 0.2641, Val Loss: 0.3522\n",
      "Epoch 21/50, Train Loss: 0.2579, Val Loss: 0.3612\n",
      "Epoch 22/50, Train Loss: 0.2531, Val Loss: 0.3640\n",
      "Epoch 23/50, Train Loss: 0.2478, Val Loss: 0.3641\n",
      "Epoch 24/50, Train Loss: 0.2439, Val Loss: 0.3613\n",
      "Epoch 25/50, Train Loss: 0.2398, Val Loss: 0.3635\n",
      "Epoch 26/50, Train Loss: 0.2355, Val Loss: 0.3642\n",
      "Epoch 27/50, Train Loss: 0.2231, Val Loss: 0.3661\n",
      "Epoch 28/50, Train Loss: 0.2203, Val Loss: 0.3681\n",
      "Epoch 29/50, Train Loss: 0.2192, Val Loss: 0.3703\n",
      "Epoch 30/50, Train Loss: 0.2183, Val Loss: 0.3715\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: max, Optimizer: Adam, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 0.9849, Val Loss: 0.6227\n",
      "Epoch 2/100, Train Loss: 0.6245, Val Loss: 0.5944\n",
      "Epoch 3/100, Train Loss: 0.5340, Val Loss: 0.5303\n",
      "Epoch 4/100, Train Loss: 0.4936, Val Loss: 0.4806\n",
      "Epoch 5/100, Train Loss: 0.4700, Val Loss: 0.5367\n",
      "Epoch 6/100, Train Loss: 0.4723, Val Loss: 0.5309\n",
      "Epoch 7/100, Train Loss: 0.4673, Val Loss: 0.4785\n",
      "Epoch 8/100, Train Loss: 0.4581, Val Loss: 0.4873\n",
      "Epoch 9/100, Train Loss: 0.4459, Val Loss: 0.4920\n",
      "Epoch 10/100, Train Loss: 0.4482, Val Loss: 0.4780\n",
      "Epoch 11/100, Train Loss: 0.4435, Val Loss: 0.4691\n",
      "Epoch 12/100, Train Loss: 0.4438, Val Loss: 0.4674\n",
      "Epoch 13/100, Train Loss: 0.4421, Val Loss: 0.4632\n",
      "Epoch 14/100, Train Loss: 0.4382, Val Loss: 0.4849\n",
      "Epoch 15/100, Train Loss: 0.4484, Val Loss: 0.4807\n",
      "Epoch 16/100, Train Loss: 0.4395, Val Loss: 0.4697\n",
      "Epoch 17/100, Train Loss: 0.4355, Val Loss: 0.4909\n",
      "Epoch 18/100, Train Loss: 0.4255, Val Loss: 0.4613\n",
      "Epoch 19/100, Train Loss: 0.4272, Val Loss: 0.4918\n",
      "Epoch 20/100, Train Loss: 0.4216, Val Loss: 0.4750\n",
      "Epoch 21/100, Train Loss: 0.4185, Val Loss: 0.4973\n",
      "Epoch 22/100, Train Loss: 0.4264, Val Loss: 0.4673\n",
      "Epoch 23/100, Train Loss: 0.4133, Val Loss: 0.4993\n",
      "Epoch 24/100, Train Loss: 0.4258, Val Loss: 0.5329\n",
      "Epoch 25/100, Train Loss: 0.3475, Val Loss: 0.4146\n",
      "Epoch 26/100, Train Loss: 0.3195, Val Loss: 0.4038\n",
      "Epoch 27/100, Train Loss: 0.3108, Val Loss: 0.4024\n",
      "Epoch 28/100, Train Loss: 0.3035, Val Loss: 0.3988\n",
      "Epoch 29/100, Train Loss: 0.2969, Val Loss: 0.4014\n",
      "Epoch 30/100, Train Loss: 0.2922, Val Loss: 0.3984\n",
      "Epoch 31/100, Train Loss: 0.2878, Val Loss: 0.3997\n",
      "Epoch 32/100, Train Loss: 0.2850, Val Loss: 0.4043\n",
      "Epoch 33/100, Train Loss: 0.2811, Val Loss: 0.4112\n",
      "Epoch 34/100, Train Loss: 0.2776, Val Loss: 0.4100\n",
      "Epoch 35/100, Train Loss: 0.2755, Val Loss: 0.4108\n",
      "Epoch 36/100, Train Loss: 0.2738, Val Loss: 0.4123\n",
      "Epoch 37/100, Train Loss: 0.2612, Val Loss: 0.4128\n",
      "Epoch 38/100, Train Loss: 0.2597, Val Loss: 0.4139\n",
      "Epoch 39/100, Train Loss: 0.2590, Val Loss: 0.4146\n",
      "Epoch 40/100, Train Loss: 0.2583, Val Loss: 0.4165\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: max, Optimizer: Adam, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 0.6320, Val Loss: 0.4816\n",
      "Epoch 2/250, Train Loss: 0.4555, Val Loss: 0.4923\n",
      "Epoch 3/250, Train Loss: 0.4328, Val Loss: 0.4321\n",
      "Epoch 4/250, Train Loss: 0.4224, Val Loss: 0.4347\n",
      "Epoch 5/250, Train Loss: 0.4088, Val Loss: 0.4329\n",
      "Epoch 6/250, Train Loss: 0.4171, Val Loss: 0.4190\n",
      "Epoch 7/250, Train Loss: 0.3921, Val Loss: 0.4027\n",
      "Epoch 8/250, Train Loss: 0.3885, Val Loss: 0.4440\n",
      "Epoch 9/250, Train Loss: 0.3954, Val Loss: 0.4166\n",
      "Epoch 10/250, Train Loss: 0.3980, Val Loss: 0.4375\n",
      "Epoch 11/250, Train Loss: 0.3833, Val Loss: 0.4513\n",
      "Epoch 12/250, Train Loss: 0.3881, Val Loss: 0.4508\n",
      "Epoch 13/250, Train Loss: 0.3898, Val Loss: 0.4532\n",
      "Epoch 14/250, Train Loss: 0.3119, Val Loss: 0.3627\n",
      "Epoch 15/250, Train Loss: 0.2861, Val Loss: 0.3559\n",
      "Epoch 16/250, Train Loss: 0.2753, Val Loss: 0.3518\n",
      "Epoch 17/250, Train Loss: 0.2676, Val Loss: 0.3540\n",
      "Epoch 18/250, Train Loss: 0.2615, Val Loss: 0.3528\n",
      "Epoch 19/250, Train Loss: 0.2567, Val Loss: 0.3539\n",
      "Epoch 20/250, Train Loss: 0.2510, Val Loss: 0.3573\n",
      "Epoch 21/250, Train Loss: 0.2465, Val Loss: 0.3584\n",
      "Epoch 22/250, Train Loss: 0.2416, Val Loss: 0.3647\n",
      "Epoch 23/250, Train Loss: 0.2295, Val Loss: 0.3578\n",
      "Epoch 24/250, Train Loss: 0.2273, Val Loss: 0.3571\n",
      "Epoch 25/250, Train Loss: 0.2263, Val Loss: 0.3578\n",
      "Epoch 26/250, Train Loss: 0.2254, Val Loss: 0.3583\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: max, Optimizer: Adam, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 0.6445, Val Loss: 0.5082\n",
      "Epoch 2/350, Train Loss: 0.4803, Val Loss: 0.5128\n",
      "Epoch 3/350, Train Loss: 0.4480, Val Loss: 0.4642\n",
      "Epoch 4/350, Train Loss: 0.4344, Val Loss: 0.4838\n",
      "Epoch 5/350, Train Loss: 0.4292, Val Loss: 0.4449\n",
      "Epoch 6/350, Train Loss: 0.4104, Val Loss: 0.4376\n",
      "Epoch 7/350, Train Loss: 0.4300, Val Loss: 0.5014\n",
      "Epoch 8/350, Train Loss: 0.4048, Val Loss: 0.4385\n",
      "Epoch 9/350, Train Loss: 0.3958, Val Loss: 0.4464\n",
      "Epoch 10/350, Train Loss: 0.4018, Val Loss: 0.4469\n",
      "Epoch 11/350, Train Loss: 0.4119, Val Loss: 0.4650\n",
      "Epoch 12/350, Train Loss: 0.4017, Val Loss: 0.4789\n",
      "Epoch 13/350, Train Loss: 0.3116, Val Loss: 0.3721\n",
      "Epoch 14/350, Train Loss: 0.2867, Val Loss: 0.3583\n",
      "Epoch 15/350, Train Loss: 0.2753, Val Loss: 0.3586\n",
      "Epoch 16/350, Train Loss: 0.2674, Val Loss: 0.3589\n",
      "Epoch 17/350, Train Loss: 0.2596, Val Loss: 0.3558\n",
      "Epoch 18/350, Train Loss: 0.2541, Val Loss: 0.3606\n",
      "Epoch 19/350, Train Loss: 0.2488, Val Loss: 0.3586\n",
      "Epoch 20/350, Train Loss: 0.2433, Val Loss: 0.3613\n",
      "Epoch 21/350, Train Loss: 0.2395, Val Loss: 0.3590\n",
      "Epoch 22/350, Train Loss: 0.2345, Val Loss: 0.3683\n",
      "Epoch 23/350, Train Loss: 0.2309, Val Loss: 0.3768\n",
      "Epoch 24/350, Train Loss: 0.2188, Val Loss: 0.3673\n",
      "Epoch 25/350, Train Loss: 0.2156, Val Loss: 0.3670\n",
      "Epoch 26/350, Train Loss: 0.2143, Val Loss: 0.3693\n",
      "Epoch 27/350, Train Loss: 0.2134, Val Loss: 0.3698\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: avg, Optimizer: SGD, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 1.1289, Val Loss: 0.6750\n",
      "Epoch 2/5, Train Loss: 0.6188, Val Loss: 0.5846\n",
      "Epoch 3/5, Train Loss: 0.5412, Val Loss: 0.5431\n",
      "Epoch 4/5, Train Loss: 0.4884, Val Loss: 0.4794\n",
      "Epoch 5/5, Train Loss: 0.4527, Val Loss: 0.4485\n",
      "Kernel: 7, Pooling: avg, Optimizer: SGD, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 1.0644, Val Loss: 0.7094\n",
      "Epoch 2/50, Train Loss: 0.6353, Val Loss: 0.6032\n",
      "Epoch 3/50, Train Loss: 0.5610, Val Loss: 0.5646\n",
      "Epoch 4/50, Train Loss: 0.5055, Val Loss: 0.5052\n",
      "Epoch 5/50, Train Loss: 0.4671, Val Loss: 0.4842\n",
      "Epoch 6/50, Train Loss: 0.4366, Val Loss: 0.4570\n",
      "Epoch 7/50, Train Loss: 0.4125, Val Loss: 0.4161\n",
      "Epoch 8/50, Train Loss: 0.3968, Val Loss: 0.4040\n",
      "Epoch 9/50, Train Loss: 0.3807, Val Loss: 0.3997\n",
      "Epoch 10/50, Train Loss: 0.3684, Val Loss: 0.4123\n",
      "Epoch 11/50, Train Loss: 0.3572, Val Loss: 0.4098\n",
      "Epoch 12/50, Train Loss: 0.3473, Val Loss: 0.3806\n",
      "Epoch 13/50, Train Loss: 0.3388, Val Loss: 0.3738\n",
      "Epoch 14/50, Train Loss: 0.3312, Val Loss: 0.3652\n",
      "Epoch 15/50, Train Loss: 0.3234, Val Loss: 0.3560\n",
      "Epoch 16/50, Train Loss: 0.3173, Val Loss: 0.3525\n",
      "Epoch 17/50, Train Loss: 0.3109, Val Loss: 0.3380\n",
      "Epoch 18/50, Train Loss: 0.3053, Val Loss: 0.3465\n",
      "Epoch 19/50, Train Loss: 0.2990, Val Loss: 0.3327\n",
      "Epoch 20/50, Train Loss: 0.2942, Val Loss: 0.3594\n",
      "Epoch 21/50, Train Loss: 0.2889, Val Loss: 0.3404\n",
      "Epoch 22/50, Train Loss: 0.2843, Val Loss: 0.3257\n",
      "Epoch 23/50, Train Loss: 0.2790, Val Loss: 0.3313\n",
      "Epoch 24/50, Train Loss: 0.2755, Val Loss: 0.3310\n",
      "Epoch 25/50, Train Loss: 0.2717, Val Loss: 0.3243\n",
      "Epoch 26/50, Train Loss: 0.2664, Val Loss: 0.3171\n",
      "Epoch 27/50, Train Loss: 0.2630, Val Loss: 0.3121\n",
      "Epoch 28/50, Train Loss: 0.2607, Val Loss: 0.3133\n",
      "Epoch 29/50, Train Loss: 0.2561, Val Loss: 0.3041\n",
      "Epoch 30/50, Train Loss: 0.2525, Val Loss: 0.3071\n",
      "Epoch 31/50, Train Loss: 0.2491, Val Loss: 0.3000\n",
      "Epoch 32/50, Train Loss: 0.2461, Val Loss: 0.3079\n",
      "Epoch 33/50, Train Loss: 0.2429, Val Loss: 0.2940\n",
      "Epoch 34/50, Train Loss: 0.2408, Val Loss: 0.2959\n",
      "Epoch 35/50, Train Loss: 0.2362, Val Loss: 0.2924\n",
      "Epoch 36/50, Train Loss: 0.2329, Val Loss: 0.2931\n",
      "Epoch 37/50, Train Loss: 0.2294, Val Loss: 0.2908\n",
      "Epoch 38/50, Train Loss: 0.2271, Val Loss: 0.2885\n",
      "Epoch 39/50, Train Loss: 0.2247, Val Loss: 0.2914\n",
      "Epoch 40/50, Train Loss: 0.2224, Val Loss: 0.2946\n",
      "Epoch 41/50, Train Loss: 0.2191, Val Loss: 0.2897\n",
      "Epoch 42/50, Train Loss: 0.2165, Val Loss: 0.2837\n",
      "Epoch 43/50, Train Loss: 0.2136, Val Loss: 0.2847\n",
      "Epoch 44/50, Train Loss: 0.2115, Val Loss: 0.2824\n",
      "Epoch 45/50, Train Loss: 0.2086, Val Loss: 0.2993\n",
      "Epoch 46/50, Train Loss: 0.2053, Val Loss: 0.2770\n",
      "Epoch 47/50, Train Loss: 0.2025, Val Loss: 0.3021\n",
      "Epoch 48/50, Train Loss: 0.2007, Val Loss: 0.2857\n",
      "Epoch 49/50, Train Loss: 0.1986, Val Loss: 0.2844\n",
      "Epoch 50/50, Train Loss: 0.1954, Val Loss: 0.2784\n",
      "Kernel: 7, Pooling: avg, Optimizer: SGD, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 1.0026, Val Loss: 0.7334\n",
      "Epoch 2/100, Train Loss: 0.6358, Val Loss: 0.5999\n",
      "Epoch 3/100, Train Loss: 0.5594, Val Loss: 0.5455\n",
      "Epoch 4/100, Train Loss: 0.5065, Val Loss: 0.5012\n",
      "Epoch 5/100, Train Loss: 0.4683, Val Loss: 0.4861\n",
      "Epoch 6/100, Train Loss: 0.4386, Val Loss: 0.4415\n",
      "Epoch 7/100, Train Loss: 0.4168, Val Loss: 0.4462\n",
      "Epoch 8/100, Train Loss: 0.3986, Val Loss: 0.4033\n",
      "Epoch 9/100, Train Loss: 0.3826, Val Loss: 0.4008\n",
      "Epoch 10/100, Train Loss: 0.3722, Val Loss: 0.3809\n",
      "Epoch 11/100, Train Loss: 0.3598, Val Loss: 0.3748\n",
      "Epoch 12/100, Train Loss: 0.3498, Val Loss: 0.3790\n",
      "Epoch 13/100, Train Loss: 0.3394, Val Loss: 0.3696\n",
      "Epoch 14/100, Train Loss: 0.3325, Val Loss: 0.3647\n",
      "Epoch 15/100, Train Loss: 0.3256, Val Loss: 0.3557\n",
      "Epoch 16/100, Train Loss: 0.3183, Val Loss: 0.3577\n",
      "Epoch 17/100, Train Loss: 0.3129, Val Loss: 0.3550\n",
      "Epoch 18/100, Train Loss: 0.3067, Val Loss: 0.3340\n",
      "Epoch 19/100, Train Loss: 0.3006, Val Loss: 0.3501\n",
      "Epoch 20/100, Train Loss: 0.2944, Val Loss: 0.3408\n",
      "Epoch 21/100, Train Loss: 0.2894, Val Loss: 0.3242\n",
      "Epoch 22/100, Train Loss: 0.2856, Val Loss: 0.3234\n",
      "Epoch 23/100, Train Loss: 0.2811, Val Loss: 0.3204\n",
      "Epoch 24/100, Train Loss: 0.2768, Val Loss: 0.3202\n",
      "Epoch 25/100, Train Loss: 0.2711, Val Loss: 0.3249\n",
      "Epoch 26/100, Train Loss: 0.2677, Val Loss: 0.3110\n",
      "Epoch 27/100, Train Loss: 0.2633, Val Loss: 0.3094\n",
      "Epoch 28/100, Train Loss: 0.2589, Val Loss: 0.3176\n",
      "Epoch 29/100, Train Loss: 0.2544, Val Loss: 0.3037\n",
      "Epoch 30/100, Train Loss: 0.2527, Val Loss: 0.3049\n",
      "Epoch 31/100, Train Loss: 0.2486, Val Loss: 0.3077\n",
      "Epoch 32/100, Train Loss: 0.2450, Val Loss: 0.3106\n",
      "Epoch 33/100, Train Loss: 0.2427, Val Loss: 0.2984\n",
      "Epoch 34/100, Train Loss: 0.2389, Val Loss: 0.2928\n",
      "Epoch 35/100, Train Loss: 0.2350, Val Loss: 0.2980\n",
      "Epoch 36/100, Train Loss: 0.2315, Val Loss: 0.2904\n",
      "Epoch 37/100, Train Loss: 0.2302, Val Loss: 0.2924\n",
      "Epoch 38/100, Train Loss: 0.2261, Val Loss: 0.2851\n",
      "Epoch 39/100, Train Loss: 0.2231, Val Loss: 0.2950\n",
      "Epoch 40/100, Train Loss: 0.2201, Val Loss: 0.2953\n",
      "Epoch 41/100, Train Loss: 0.2187, Val Loss: 0.2923\n",
      "Epoch 42/100, Train Loss: 0.2161, Val Loss: 0.2889\n",
      "Epoch 43/100, Train Loss: 0.2121, Val Loss: 0.2956\n",
      "Epoch 44/100, Train Loss: 0.2100, Val Loss: 0.2821\n",
      "Epoch 45/100, Train Loss: 0.2067, Val Loss: 0.2966\n",
      "Epoch 46/100, Train Loss: 0.2048, Val Loss: 0.2886\n",
      "Epoch 47/100, Train Loss: 0.2018, Val Loss: 0.2918\n",
      "Epoch 48/100, Train Loss: 0.1996, Val Loss: 0.2869\n",
      "Epoch 49/100, Train Loss: 0.1972, Val Loss: 0.2862\n",
      "Epoch 50/100, Train Loss: 0.1952, Val Loss: 0.2808\n",
      "Epoch 51/100, Train Loss: 0.1913, Val Loss: 0.2803\n",
      "Epoch 52/100, Train Loss: 0.1909, Val Loss: 0.2795\n",
      "Epoch 53/100, Train Loss: 0.1870, Val Loss: 0.2895\n",
      "Epoch 54/100, Train Loss: 0.1853, Val Loss: 0.2761\n",
      "Epoch 55/100, Train Loss: 0.1825, Val Loss: 0.2889\n",
      "Epoch 56/100, Train Loss: 0.1801, Val Loss: 0.2720\n",
      "Epoch 57/100, Train Loss: 0.1776, Val Loss: 0.2818\n",
      "Epoch 58/100, Train Loss: 0.1754, Val Loss: 0.2698\n",
      "Epoch 59/100, Train Loss: 0.1742, Val Loss: 0.2768\n",
      "Epoch 60/100, Train Loss: 0.1715, Val Loss: 0.2753\n",
      "Epoch 61/100, Train Loss: 0.1697, Val Loss: 0.2717\n",
      "Epoch 62/100, Train Loss: 0.1667, Val Loss: 0.2915\n",
      "Epoch 63/100, Train Loss: 0.1653, Val Loss: 0.2725\n",
      "Epoch 64/100, Train Loss: 0.1622, Val Loss: 0.2773\n",
      "Epoch 65/100, Train Loss: 0.1409, Val Loss: 0.2617\n",
      "Epoch 66/100, Train Loss: 0.1379, Val Loss: 0.2632\n",
      "Epoch 67/100, Train Loss: 0.1367, Val Loss: 0.2646\n",
      "Epoch 68/100, Train Loss: 0.1361, Val Loss: 0.2640\n",
      "Epoch 69/100, Train Loss: 0.1356, Val Loss: 0.2632\n",
      "Epoch 70/100, Train Loss: 0.1349, Val Loss: 0.2653\n",
      "Epoch 71/100, Train Loss: 0.1345, Val Loss: 0.2654\n",
      "Epoch 72/100, Train Loss: 0.1322, Val Loss: 0.2640\n",
      "Epoch 73/100, Train Loss: 0.1319, Val Loss: 0.2641\n",
      "Epoch 74/100, Train Loss: 0.1318, Val Loss: 0.2642\n",
      "Epoch 75/100, Train Loss: 0.1317, Val Loss: 0.2643\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: avg, Optimizer: SGD, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 1.0133, Val Loss: 0.7225\n",
      "Epoch 2/250, Train Loss: 0.6246, Val Loss: 0.5914\n",
      "Epoch 3/250, Train Loss: 0.5468, Val Loss: 0.5439\n",
      "Epoch 4/250, Train Loss: 0.4931, Val Loss: 0.4922\n",
      "Epoch 5/250, Train Loss: 0.4548, Val Loss: 0.4585\n",
      "Epoch 6/250, Train Loss: 0.4316, Val Loss: 0.4487\n",
      "Epoch 7/250, Train Loss: 0.4114, Val Loss: 0.4335\n",
      "Epoch 8/250, Train Loss: 0.3944, Val Loss: 0.4115\n",
      "Epoch 9/250, Train Loss: 0.3815, Val Loss: 0.3923\n",
      "Epoch 10/250, Train Loss: 0.3682, Val Loss: 0.3928\n",
      "Epoch 11/250, Train Loss: 0.3581, Val Loss: 0.3826\n",
      "Epoch 12/250, Train Loss: 0.3481, Val Loss: 0.3688\n",
      "Epoch 13/250, Train Loss: 0.3394, Val Loss: 0.3699\n",
      "Epoch 14/250, Train Loss: 0.3312, Val Loss: 0.3582\n",
      "Epoch 15/250, Train Loss: 0.3242, Val Loss: 0.3645\n",
      "Epoch 16/250, Train Loss: 0.3167, Val Loss: 0.3420\n",
      "Epoch 17/250, Train Loss: 0.3100, Val Loss: 0.3382\n",
      "Epoch 18/250, Train Loss: 0.3059, Val Loss: 0.3377\n",
      "Epoch 19/250, Train Loss: 0.2996, Val Loss: 0.3475\n",
      "Epoch 20/250, Train Loss: 0.2946, Val Loss: 0.3301\n",
      "Epoch 21/250, Train Loss: 0.2890, Val Loss: 0.3373\n",
      "Epoch 22/250, Train Loss: 0.2832, Val Loss: 0.3299\n",
      "Epoch 23/250, Train Loss: 0.2796, Val Loss: 0.3318\n",
      "Epoch 24/250, Train Loss: 0.2752, Val Loss: 0.3219\n",
      "Epoch 25/250, Train Loss: 0.2706, Val Loss: 0.3141\n",
      "Epoch 26/250, Train Loss: 0.2666, Val Loss: 0.3245\n",
      "Epoch 27/250, Train Loss: 0.2627, Val Loss: 0.3224\n",
      "Epoch 28/250, Train Loss: 0.2596, Val Loss: 0.3024\n",
      "Epoch 29/250, Train Loss: 0.2558, Val Loss: 0.3097\n",
      "Epoch 30/250, Train Loss: 0.2519, Val Loss: 0.3043\n",
      "Epoch 31/250, Train Loss: 0.2484, Val Loss: 0.3072\n",
      "Epoch 32/250, Train Loss: 0.2455, Val Loss: 0.3050\n",
      "Epoch 33/250, Train Loss: 0.2422, Val Loss: 0.3000\n",
      "Epoch 34/250, Train Loss: 0.2387, Val Loss: 0.2970\n",
      "Epoch 35/250, Train Loss: 0.2366, Val Loss: 0.3041\n",
      "Epoch 36/250, Train Loss: 0.2326, Val Loss: 0.2997\n",
      "Epoch 37/250, Train Loss: 0.2296, Val Loss: 0.2923\n",
      "Epoch 38/250, Train Loss: 0.2274, Val Loss: 0.2897\n",
      "Epoch 39/250, Train Loss: 0.2249, Val Loss: 0.2968\n",
      "Epoch 40/250, Train Loss: 0.2217, Val Loss: 0.2834\n",
      "Epoch 41/250, Train Loss: 0.2185, Val Loss: 0.2894\n",
      "Epoch 42/250, Train Loss: 0.2153, Val Loss: 0.2890\n",
      "Epoch 43/250, Train Loss: 0.2130, Val Loss: 0.2932\n",
      "Epoch 44/250, Train Loss: 0.2103, Val Loss: 0.2932\n",
      "Epoch 45/250, Train Loss: 0.2078, Val Loss: 0.2825\n",
      "Epoch 46/250, Train Loss: 0.2051, Val Loss: 0.2789\n",
      "Epoch 47/250, Train Loss: 0.2025, Val Loss: 0.2980\n",
      "Epoch 48/250, Train Loss: 0.1997, Val Loss: 0.2953\n",
      "Epoch 49/250, Train Loss: 0.1973, Val Loss: 0.2835\n",
      "Epoch 50/250, Train Loss: 0.1953, Val Loss: 0.2979\n",
      "Epoch 51/250, Train Loss: 0.1932, Val Loss: 0.2783\n",
      "Epoch 52/250, Train Loss: 0.1896, Val Loss: 0.2838\n",
      "Epoch 53/250, Train Loss: 0.1877, Val Loss: 0.2790\n",
      "Epoch 54/250, Train Loss: 0.1855, Val Loss: 0.2827\n",
      "Epoch 55/250, Train Loss: 0.1827, Val Loss: 0.2742\n",
      "Epoch 56/250, Train Loss: 0.1806, Val Loss: 0.2833\n",
      "Epoch 57/250, Train Loss: 0.1792, Val Loss: 0.2741\n",
      "Epoch 58/250, Train Loss: 0.1766, Val Loss: 0.2775\n",
      "Epoch 59/250, Train Loss: 0.1739, Val Loss: 0.2708\n",
      "Epoch 60/250, Train Loss: 0.1714, Val Loss: 0.2726\n",
      "Epoch 61/250, Train Loss: 0.1692, Val Loss: 0.2893\n",
      "Epoch 62/250, Train Loss: 0.1679, Val Loss: 0.2712\n",
      "Epoch 63/250, Train Loss: 0.1645, Val Loss: 0.2944\n",
      "Epoch 64/250, Train Loss: 0.1630, Val Loss: 0.2768\n",
      "Epoch 65/250, Train Loss: 0.1603, Val Loss: 0.2788\n",
      "Epoch 66/250, Train Loss: 0.1400, Val Loss: 0.2630\n",
      "Epoch 67/250, Train Loss: 0.1363, Val Loss: 0.2638\n",
      "Epoch 68/250, Train Loss: 0.1351, Val Loss: 0.2643\n",
      "Epoch 69/250, Train Loss: 0.1345, Val Loss: 0.2641\n",
      "Epoch 70/250, Train Loss: 0.1337, Val Loss: 0.2658\n",
      "Epoch 71/250, Train Loss: 0.1332, Val Loss: 0.2643\n",
      "Epoch 72/250, Train Loss: 0.1327, Val Loss: 0.2657\n",
      "Epoch 73/250, Train Loss: 0.1306, Val Loss: 0.2648\n",
      "Epoch 74/250, Train Loss: 0.1302, Val Loss: 0.2648\n",
      "Epoch 75/250, Train Loss: 0.1301, Val Loss: 0.2648\n",
      "Epoch 76/250, Train Loss: 0.1300, Val Loss: 0.2649\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: avg, Optimizer: SGD, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 0.9933, Val Loss: 0.6936\n",
      "Epoch 2/350, Train Loss: 0.6269, Val Loss: 0.6136\n",
      "Epoch 3/350, Train Loss: 0.5484, Val Loss: 0.5662\n",
      "Epoch 4/350, Train Loss: 0.4938, Val Loss: 0.5009\n",
      "Epoch 5/350, Train Loss: 0.4560, Val Loss: 0.4600\n",
      "Epoch 6/350, Train Loss: 0.4276, Val Loss: 0.4734\n",
      "Epoch 7/350, Train Loss: 0.4052, Val Loss: 0.4111\n",
      "Epoch 8/350, Train Loss: 0.3896, Val Loss: 0.3965\n",
      "Epoch 9/350, Train Loss: 0.3761, Val Loss: 0.3839\n",
      "Epoch 10/350, Train Loss: 0.3631, Val Loss: 0.3841\n",
      "Epoch 11/350, Train Loss: 0.3519, Val Loss: 0.3686\n",
      "Epoch 12/350, Train Loss: 0.3430, Val Loss: 0.3733\n",
      "Epoch 13/350, Train Loss: 0.3354, Val Loss: 0.3570\n",
      "Epoch 14/350, Train Loss: 0.3264, Val Loss: 0.3686\n",
      "Epoch 15/350, Train Loss: 0.3204, Val Loss: 0.3423\n",
      "Epoch 16/350, Train Loss: 0.3126, Val Loss: 0.3417\n",
      "Epoch 17/350, Train Loss: 0.3070, Val Loss: 0.3403\n",
      "Epoch 18/350, Train Loss: 0.3001, Val Loss: 0.3435\n",
      "Epoch 19/350, Train Loss: 0.2945, Val Loss: 0.3381\n",
      "Epoch 20/350, Train Loss: 0.2896, Val Loss: 0.3351\n",
      "Epoch 21/350, Train Loss: 0.2847, Val Loss: 0.3288\n",
      "Epoch 22/350, Train Loss: 0.2797, Val Loss: 0.3194\n",
      "Epoch 23/350, Train Loss: 0.2757, Val Loss: 0.3322\n",
      "Epoch 24/350, Train Loss: 0.2719, Val Loss: 0.3158\n",
      "Epoch 25/350, Train Loss: 0.2677, Val Loss: 0.3075\n",
      "Epoch 26/350, Train Loss: 0.2631, Val Loss: 0.3088\n",
      "Epoch 27/350, Train Loss: 0.2598, Val Loss: 0.3009\n",
      "Epoch 28/350, Train Loss: 0.2562, Val Loss: 0.2993\n",
      "Epoch 29/350, Train Loss: 0.2533, Val Loss: 0.3015\n",
      "Epoch 30/350, Train Loss: 0.2494, Val Loss: 0.3040\n",
      "Epoch 31/350, Train Loss: 0.2452, Val Loss: 0.3080\n",
      "Epoch 32/350, Train Loss: 0.2423, Val Loss: 0.2945\n",
      "Epoch 33/350, Train Loss: 0.2399, Val Loss: 0.2938\n",
      "Epoch 34/350, Train Loss: 0.2369, Val Loss: 0.3073\n",
      "Epoch 35/350, Train Loss: 0.2335, Val Loss: 0.2952\n",
      "Epoch 36/350, Train Loss: 0.2307, Val Loss: 0.2840\n",
      "Epoch 37/350, Train Loss: 0.2275, Val Loss: 0.2895\n",
      "Epoch 38/350, Train Loss: 0.2241, Val Loss: 0.2898\n",
      "Epoch 39/350, Train Loss: 0.2216, Val Loss: 0.2889\n",
      "Epoch 40/350, Train Loss: 0.2201, Val Loss: 0.2864\n",
      "Epoch 41/350, Train Loss: 0.2154, Val Loss: 0.2869\n",
      "Epoch 42/350, Train Loss: 0.2136, Val Loss: 0.2816\n",
      "Epoch 43/350, Train Loss: 0.2115, Val Loss: 0.2826\n",
      "Epoch 44/350, Train Loss: 0.2084, Val Loss: 0.2822\n",
      "Epoch 45/350, Train Loss: 0.2062, Val Loss: 0.2870\n",
      "Epoch 46/350, Train Loss: 0.2026, Val Loss: 0.2921\n",
      "Epoch 47/350, Train Loss: 0.2008, Val Loss: 0.2762\n",
      "Epoch 48/350, Train Loss: 0.1979, Val Loss: 0.3059\n",
      "Epoch 49/350, Train Loss: 0.1944, Val Loss: 0.2874\n",
      "Epoch 50/350, Train Loss: 0.1931, Val Loss: 0.2817\n",
      "Epoch 51/350, Train Loss: 0.1912, Val Loss: 0.2822\n",
      "Epoch 52/350, Train Loss: 0.1884, Val Loss: 0.2874\n",
      "Epoch 53/350, Train Loss: 0.1857, Val Loss: 0.2858\n",
      "Epoch 54/350, Train Loss: 0.1655, Val Loss: 0.2678\n",
      "Epoch 55/350, Train Loss: 0.1627, Val Loss: 0.2686\n",
      "Epoch 56/350, Train Loss: 0.1619, Val Loss: 0.2672\n",
      "Epoch 57/350, Train Loss: 0.1612, Val Loss: 0.2669\n",
      "Epoch 58/350, Train Loss: 0.1606, Val Loss: 0.2677\n",
      "Epoch 59/350, Train Loss: 0.1600, Val Loss: 0.2689\n",
      "Epoch 60/350, Train Loss: 0.1596, Val Loss: 0.2690\n",
      "Epoch 61/350, Train Loss: 0.1592, Val Loss: 0.2679\n",
      "Epoch 62/350, Train Loss: 0.1589, Val Loss: 0.2688\n",
      "Epoch 63/350, Train Loss: 0.1583, Val Loss: 0.2690\n",
      "Epoch 64/350, Train Loss: 0.1559, Val Loss: 0.2681\n",
      "Epoch 65/350, Train Loss: 0.1556, Val Loss: 0.2681\n",
      "Epoch 66/350, Train Loss: 0.1556, Val Loss: 0.2682\n",
      "Epoch 67/350, Train Loss: 0.1555, Val Loss: 0.2682\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: avg, Optimizer: RMSProp, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 59.9955, Val Loss: 0.8111\n",
      "Epoch 2/5, Train Loss: 0.6702, Val Loss: 0.5882\n",
      "Epoch 3/5, Train Loss: 1.5072, Val Loss: 0.5791\n",
      "Epoch 4/5, Train Loss: 0.5888, Val Loss: 0.4599\n",
      "Epoch 5/5, Train Loss: 0.6636, Val Loss: 0.4803\n",
      "Kernel: 7, Pooling: avg, Optimizer: RMSProp, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 35.2517, Val Loss: 0.8837\n",
      "Epoch 2/50, Train Loss: 1.1445, Val Loss: 0.8799\n",
      "Epoch 3/50, Train Loss: 0.5892, Val Loss: 0.4783\n",
      "Epoch 4/50, Train Loss: 1.5889, Val Loss: 0.4670\n",
      "Epoch 5/50, Train Loss: 0.4996, Val Loss: 0.4590\n",
      "Epoch 6/50, Train Loss: 0.4804, Val Loss: 0.4165\n",
      "Epoch 7/50, Train Loss: 0.5351, Val Loss: 0.4892\n",
      "Epoch 8/50, Train Loss: 0.4105, Val Loss: 0.4053\n",
      "Epoch 9/50, Train Loss: 0.4511, Val Loss: 0.6099\n",
      "Epoch 10/50, Train Loss: 0.3892, Val Loss: 0.4270\n",
      "Epoch 11/50, Train Loss: 0.4874, Val Loss: 0.5743\n",
      "Epoch 12/50, Train Loss: 0.4101, Val Loss: 0.3980\n",
      "Epoch 13/50, Train Loss: 0.4019, Val Loss: 0.4798\n",
      "Epoch 14/50, Train Loss: 0.3723, Val Loss: 0.4022\n",
      "Epoch 15/50, Train Loss: 0.3926, Val Loss: 0.3817\n",
      "Epoch 16/50, Train Loss: 0.3949, Val Loss: 0.4309\n",
      "Epoch 17/50, Train Loss: 0.3808, Val Loss: 0.4863\n",
      "Epoch 18/50, Train Loss: 0.4070, Val Loss: 0.4052\n",
      "Epoch 19/50, Train Loss: 0.3565, Val Loss: 0.3963\n",
      "Epoch 20/50, Train Loss: 0.4031, Val Loss: 0.4574\n",
      "Epoch 21/50, Train Loss: 0.3564, Val Loss: 0.4435\n",
      "Epoch 22/50, Train Loss: 0.2668, Val Loss: 0.3808\n",
      "Epoch 23/50, Train Loss: 0.2378, Val Loss: 0.3881\n",
      "Epoch 24/50, Train Loss: 0.2260, Val Loss: 0.3881\n",
      "Epoch 25/50, Train Loss: 0.2185, Val Loss: 0.3976\n",
      "Epoch 26/50, Train Loss: 0.2102, Val Loss: 0.3908\n",
      "Epoch 27/50, Train Loss: 0.2044, Val Loss: 0.3950\n",
      "Epoch 28/50, Train Loss: 0.1999, Val Loss: 0.4181\n",
      "Epoch 29/50, Train Loss: 0.1887, Val Loss: 0.4266\n",
      "Epoch 30/50, Train Loss: 0.1854, Val Loss: 0.4239\n",
      "Epoch 31/50, Train Loss: 0.1841, Val Loss: 0.4299\n",
      "Epoch 32/50, Train Loss: 0.1832, Val Loss: 0.4302\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: avg, Optimizer: RMSProp, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 18.8364, Val Loss: 0.7530\n",
      "Epoch 2/100, Train Loss: 0.6631, Val Loss: 0.5647\n",
      "Epoch 3/100, Train Loss: 0.7567, Val Loss: 0.7555\n",
      "Epoch 4/100, Train Loss: 0.5057, Val Loss: 0.4916\n",
      "Epoch 5/100, Train Loss: 0.6340, Val Loss: 0.4957\n",
      "Epoch 6/100, Train Loss: 0.4865, Val Loss: 0.6887\n",
      "Epoch 7/100, Train Loss: 0.4282, Val Loss: 0.5725\n",
      "Epoch 8/100, Train Loss: 0.4092, Val Loss: 0.4429\n",
      "Epoch 9/100, Train Loss: 0.4071, Val Loss: 0.4411\n",
      "Epoch 10/100, Train Loss: 0.4255, Val Loss: 0.4276\n",
      "Epoch 11/100, Train Loss: 0.3869, Val Loss: 0.3849\n",
      "Epoch 12/100, Train Loss: 0.6262, Val Loss: 0.4317\n",
      "Epoch 13/100, Train Loss: 0.3688, Val Loss: 0.3966\n",
      "Epoch 14/100, Train Loss: 0.5110, Val Loss: 0.4234\n",
      "Epoch 15/100, Train Loss: 0.4050, Val Loss: 0.4020\n",
      "Epoch 16/100, Train Loss: 0.3656, Val Loss: 0.4066\n",
      "Epoch 17/100, Train Loss: 0.3656, Val Loss: 0.5495\n",
      "Epoch 18/100, Train Loss: 0.2692, Val Loss: 0.3492\n",
      "Epoch 19/100, Train Loss: 0.2457, Val Loss: 0.3482\n",
      "Epoch 20/100, Train Loss: 0.2351, Val Loss: 0.3505\n",
      "Epoch 21/100, Train Loss: 0.2267, Val Loss: 0.3758\n",
      "Epoch 22/100, Train Loss: 0.2208, Val Loss: 0.3809\n",
      "Epoch 23/100, Train Loss: 0.2158, Val Loss: 0.3773\n",
      "Epoch 24/100, Train Loss: 0.2099, Val Loss: 0.3819\n",
      "Epoch 25/100, Train Loss: 0.2045, Val Loss: 0.3842\n",
      "Epoch 26/100, Train Loss: 0.1918, Val Loss: 0.4005\n",
      "Epoch 27/100, Train Loss: 0.1894, Val Loss: 0.3996\n",
      "Epoch 28/100, Train Loss: 0.1882, Val Loss: 0.4012\n",
      "Epoch 29/100, Train Loss: 0.1873, Val Loss: 0.4015\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: avg, Optimizer: RMSProp, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 19.1257, Val Loss: 0.6310\n",
      "Epoch 2/250, Train Loss: 1.6172, Val Loss: 1.1073\n",
      "Epoch 3/250, Train Loss: 0.9271, Val Loss: 0.5748\n",
      "Epoch 4/250, Train Loss: 0.6890, Val Loss: 0.5281\n",
      "Epoch 5/250, Train Loss: 0.4792, Val Loss: 0.4542\n",
      "Epoch 6/250, Train Loss: 0.4886, Val Loss: 0.4638\n",
      "Epoch 7/250, Train Loss: 0.4936, Val Loss: 0.4413\n",
      "Epoch 8/250, Train Loss: 0.4657, Val Loss: 0.4354\n",
      "Epoch 9/250, Train Loss: 0.4256, Val Loss: 0.4404\n",
      "Epoch 10/250, Train Loss: 0.6325, Val Loss: 0.4268\n",
      "Epoch 11/250, Train Loss: 0.4053, Val Loss: 0.4518\n",
      "Epoch 12/250, Train Loss: 0.3927, Val Loss: 0.4113\n",
      "Epoch 13/250, Train Loss: 0.4463, Val Loss: 0.4099\n",
      "Epoch 14/250, Train Loss: 0.4254, Val Loss: 0.4417\n",
      "Epoch 15/250, Train Loss: 0.3750, Val Loss: 0.4165\n",
      "Epoch 16/250, Train Loss: 0.3724, Val Loss: 0.4159\n",
      "Epoch 17/250, Train Loss: 0.4586, Val Loss: 0.5049\n",
      "Epoch 18/250, Train Loss: 0.4105, Val Loss: 0.4065\n",
      "Epoch 19/250, Train Loss: 0.3736, Val Loss: 0.3929\n",
      "Epoch 20/250, Train Loss: 0.4488, Val Loss: 0.4442\n",
      "Epoch 21/250, Train Loss: 0.3539, Val Loss: 0.7030\n",
      "Epoch 22/250, Train Loss: 0.3940, Val Loss: 0.4133\n",
      "Epoch 23/250, Train Loss: 0.3641, Val Loss: 0.4548\n",
      "Epoch 24/250, Train Loss: 0.3749, Val Loss: 0.4658\n",
      "Epoch 25/250, Train Loss: 0.3595, Val Loss: 0.4312\n",
      "Epoch 26/250, Train Loss: 0.2666, Val Loss: 0.3928\n",
      "Epoch 27/250, Train Loss: 0.2408, Val Loss: 0.3977\n",
      "Epoch 28/250, Train Loss: 0.2297, Val Loss: 0.4191\n",
      "Epoch 29/250, Train Loss: 0.2222, Val Loss: 0.4239\n",
      "Epoch 30/250, Train Loss: 0.2150, Val Loss: 0.4646\n",
      "Epoch 31/250, Train Loss: 0.2093, Val Loss: 0.4516\n",
      "Epoch 32/250, Train Loss: 0.2048, Val Loss: 0.4504\n",
      "Epoch 33/250, Train Loss: 0.1934, Val Loss: 0.4684\n",
      "Epoch 34/250, Train Loss: 0.1901, Val Loss: 0.4756\n",
      "Epoch 35/250, Train Loss: 0.1889, Val Loss: 0.4771\n",
      "Epoch 36/250, Train Loss: 0.1879, Val Loss: 0.4807\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: avg, Optimizer: RMSProp, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 24.5378, Val Loss: 0.5973\n",
      "Epoch 2/350, Train Loss: 1.4572, Val Loss: 0.6208\n",
      "Epoch 3/350, Train Loss: 0.8340, Val Loss: 0.6032\n",
      "Epoch 4/350, Train Loss: 0.5528, Val Loss: 0.5840\n",
      "Epoch 5/350, Train Loss: 0.7741, Val Loss: 0.6569\n",
      "Epoch 6/350, Train Loss: 0.5047, Val Loss: 0.4515\n",
      "Epoch 7/350, Train Loss: 0.4402, Val Loss: 0.4432\n",
      "Epoch 8/350, Train Loss: 0.4535, Val Loss: 0.5525\n",
      "Epoch 9/350, Train Loss: 0.3960, Val Loss: 0.4553\n",
      "Epoch 10/350, Train Loss: 0.4631, Val Loss: 0.7850\n",
      "Epoch 11/350, Train Loss: 0.4927, Val Loss: 0.4221\n",
      "Epoch 12/350, Train Loss: 0.4070, Val Loss: 0.4118\n",
      "Epoch 13/350, Train Loss: 0.4027, Val Loss: 0.4393\n",
      "Epoch 14/350, Train Loss: 0.3865, Val Loss: 0.4301\n",
      "Epoch 15/350, Train Loss: 0.4159, Val Loss: 0.4476\n",
      "Epoch 16/350, Train Loss: 0.5434, Val Loss: 0.5206\n",
      "Epoch 17/350, Train Loss: 0.4835, Val Loss: 0.5068\n",
      "Epoch 18/350, Train Loss: 0.3881, Val Loss: 0.4204\n",
      "Epoch 19/350, Train Loss: 0.2752, Val Loss: 0.3562\n",
      "Epoch 20/350, Train Loss: 0.2529, Val Loss: 0.3503\n",
      "Epoch 21/350, Train Loss: 0.2424, Val Loss: 0.3543\n",
      "Epoch 22/350, Train Loss: 0.2344, Val Loss: 0.3550\n",
      "Epoch 23/350, Train Loss: 0.2291, Val Loss: 0.3572\n",
      "Epoch 24/350, Train Loss: 0.2232, Val Loss: 0.3627\n",
      "Epoch 25/350, Train Loss: 0.2170, Val Loss: 0.3774\n",
      "Epoch 26/350, Train Loss: 0.2124, Val Loss: 0.3729\n",
      "Epoch 27/350, Train Loss: 0.1988, Val Loss: 0.3775\n",
      "Epoch 28/350, Train Loss: 0.1965, Val Loss: 0.3810\n",
      "Epoch 29/350, Train Loss: 0.1954, Val Loss: 0.3811\n",
      "Epoch 30/350, Train Loss: 0.1945, Val Loss: 0.3815\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: avg, Optimizer: Adam, Epochs: 5\n",
      "Epoch 1/5, Train Loss: 0.6947, Val Loss: 0.5046\n",
      "Epoch 2/5, Train Loss: 0.4426, Val Loss: 0.4242\n",
      "Epoch 3/5, Train Loss: 0.4077, Val Loss: 0.4188\n",
      "Epoch 4/5, Train Loss: 0.3959, Val Loss: 0.4189\n",
      "Epoch 5/5, Train Loss: 0.3761, Val Loss: 0.3876\n",
      "Kernel: 7, Pooling: avg, Optimizer: Adam, Epochs: 50\n",
      "Epoch 1/50, Train Loss: 0.5831, Val Loss: 0.4252\n",
      "Epoch 2/50, Train Loss: 0.4086, Val Loss: 0.3784\n",
      "Epoch 3/50, Train Loss: 0.3737, Val Loss: 0.4016\n",
      "Epoch 4/50, Train Loss: 0.3477, Val Loss: 0.3970\n",
      "Epoch 5/50, Train Loss: 0.3357, Val Loss: 0.3795\n",
      "Epoch 6/50, Train Loss: 0.3502, Val Loss: 0.3519\n",
      "Epoch 7/50, Train Loss: 0.3128, Val Loss: 0.3632\n",
      "Epoch 8/50, Train Loss: 0.3017, Val Loss: 0.3681\n",
      "Epoch 9/50, Train Loss: 0.3488, Val Loss: 0.3928\n",
      "Epoch 10/50, Train Loss: 0.2995, Val Loss: 0.3726\n",
      "Epoch 11/50, Train Loss: 0.2926, Val Loss: 0.4037\n",
      "Epoch 12/50, Train Loss: 0.3121, Val Loss: 0.3622\n",
      "Epoch 13/50, Train Loss: 0.2217, Val Loss: 0.3260\n",
      "Epoch 14/50, Train Loss: 0.2022, Val Loss: 0.3245\n",
      "Epoch 15/50, Train Loss: 0.1932, Val Loss: 0.3288\n",
      "Epoch 16/50, Train Loss: 0.1858, Val Loss: 0.3303\n",
      "Epoch 17/50, Train Loss: 0.1796, Val Loss: 0.3315\n",
      "Epoch 18/50, Train Loss: 0.1735, Val Loss: 0.3422\n",
      "Epoch 19/50, Train Loss: 0.1680, Val Loss: 0.3480\n",
      "Epoch 20/50, Train Loss: 0.1630, Val Loss: 0.3492\n",
      "Epoch 21/50, Train Loss: 0.1511, Val Loss: 0.3516\n",
      "Epoch 22/50, Train Loss: 0.1487, Val Loss: 0.3541\n",
      "Epoch 23/50, Train Loss: 0.1475, Val Loss: 0.3560\n",
      "Epoch 24/50, Train Loss: 0.1466, Val Loss: 0.3584\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: avg, Optimizer: Adam, Epochs: 100\n",
      "Epoch 1/100, Train Loss: 0.6071, Val Loss: 0.4768\n",
      "Epoch 2/100, Train Loss: 0.4186, Val Loss: 0.4367\n",
      "Epoch 3/100, Train Loss: 0.3878, Val Loss: 0.4508\n",
      "Epoch 4/100, Train Loss: 0.3681, Val Loss: 0.4376\n",
      "Epoch 5/100, Train Loss: 0.3537, Val Loss: 0.3701\n",
      "Epoch 6/100, Train Loss: 0.3378, Val Loss: 0.3989\n",
      "Epoch 7/100, Train Loss: 0.3365, Val Loss: 0.3821\n",
      "Epoch 8/100, Train Loss: 0.3201, Val Loss: 0.3982\n",
      "Epoch 9/100, Train Loss: 0.3175, Val Loss: 0.3963\n",
      "Epoch 10/100, Train Loss: 0.3256, Val Loss: 0.4051\n",
      "Epoch 11/100, Train Loss: 0.3084, Val Loss: 0.4087\n",
      "Epoch 12/100, Train Loss: 0.2360, Val Loss: 0.3393\n",
      "Epoch 13/100, Train Loss: 0.2123, Val Loss: 0.3414\n",
      "Epoch 14/100, Train Loss: 0.2028, Val Loss: 0.3457\n",
      "Epoch 15/100, Train Loss: 0.1942, Val Loss: 0.3497\n",
      "Epoch 16/100, Train Loss: 0.1869, Val Loss: 0.3599\n",
      "Epoch 17/100, Train Loss: 0.1812, Val Loss: 0.3624\n",
      "Epoch 18/100, Train Loss: 0.1753, Val Loss: 0.3729\n",
      "Epoch 19/100, Train Loss: 0.1624, Val Loss: 0.3662\n",
      "Epoch 20/100, Train Loss: 0.1603, Val Loss: 0.3690\n",
      "Epoch 21/100, Train Loss: 0.1592, Val Loss: 0.3704\n",
      "Epoch 22/100, Train Loss: 0.1583, Val Loss: 0.3738\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: avg, Optimizer: Adam, Epochs: 250\n",
      "Epoch 1/250, Train Loss: 0.5896, Val Loss: 0.4455\n",
      "Epoch 2/250, Train Loss: 0.4185, Val Loss: 0.4237\n",
      "Epoch 3/250, Train Loss: 0.3886, Val Loss: 0.3836\n",
      "Epoch 4/250, Train Loss: 0.3614, Val Loss: 0.3811\n",
      "Epoch 5/250, Train Loss: 0.3474, Val Loss: 0.3814\n",
      "Epoch 6/250, Train Loss: 0.3535, Val Loss: 0.4080\n",
      "Epoch 7/250, Train Loss: 0.3340, Val Loss: 0.3691\n",
      "Epoch 8/250, Train Loss: 0.3191, Val Loss: 0.4259\n",
      "Epoch 9/250, Train Loss: 0.3186, Val Loss: 0.3973\n",
      "Epoch 10/250, Train Loss: 0.3180, Val Loss: 0.4208\n",
      "Epoch 11/250, Train Loss: 0.3235, Val Loss: 0.3874\n",
      "Epoch 12/250, Train Loss: 0.3009, Val Loss: 0.3714\n",
      "Epoch 13/250, Train Loss: 0.3085, Val Loss: 0.4019\n",
      "Epoch 14/250, Train Loss: 0.2382, Val Loss: 0.3316\n",
      "Epoch 15/250, Train Loss: 0.2151, Val Loss: 0.3300\n",
      "Epoch 16/250, Train Loss: 0.2031, Val Loss: 0.3333\n",
      "Epoch 17/250, Train Loss: 0.1955, Val Loss: 0.3346\n",
      "Epoch 18/250, Train Loss: 0.1877, Val Loss: 0.3375\n",
      "Epoch 19/250, Train Loss: 0.1812, Val Loss: 0.3396\n",
      "Epoch 20/250, Train Loss: 0.1757, Val Loss: 0.3480\n",
      "Epoch 21/250, Train Loss: 0.1704, Val Loss: 0.3496\n",
      "Epoch 22/250, Train Loss: 0.1573, Val Loss: 0.3510\n",
      "Epoch 23/250, Train Loss: 0.1555, Val Loss: 0.3526\n",
      "Epoch 24/250, Train Loss: 0.1544, Val Loss: 0.3544\n",
      "Epoch 25/250, Train Loss: 0.1536, Val Loss: 0.3564\n",
      "Early stopping triggered due to no improvement in validation loss.\n",
      "Kernel: 7, Pooling: avg, Optimizer: Adam, Epochs: 350\n",
      "Epoch 1/350, Train Loss: 2.3107, Val Loss: 2.3033\n",
      "Epoch 2/350, Train Loss: 2.3037, Val Loss: 2.3030\n",
      "Epoch 3/350, Train Loss: 2.3035, Val Loss: 2.3051\n",
      "Epoch 4/350, Train Loss: 2.3035, Val Loss: 2.3035\n",
      "Epoch 5/350, Train Loss: 2.3037, Val Loss: 2.3030\n",
      "Epoch 6/350, Train Loss: 2.3035, Val Loss: 2.3036\n",
      "Epoch 7/350, Train Loss: 2.3035, Val Loss: 2.3035\n",
      "Epoch 8/350, Train Loss: 2.3038, Val Loss: 2.3035\n",
      "Epoch 9/350, Train Loss: 2.3029, Val Loss: 2.3028\n",
      "Epoch 10/350, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 11/350, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 12/350, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 13/350, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 14/350, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 15/350, Train Loss: 2.3027, Val Loss: 2.3027\n",
      "Epoch 16/350, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 17/350, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 18/350, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 19/350, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Epoch 20/350, Train Loss: 2.3026, Val Loss: 2.3027\n",
      "Early stopping triggered due to no improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "# Compare models\n",
    "kernel_sizes = [3, 5, 7]\n",
    "pooling_methods = ['max', 'avg']\n",
    "optimizers = {'SGD': optim.SGD, 'RMSProp': optim.RMSprop, 'Adam': optim.Adam}\n",
    "num_epochs = [5, 50, 100, 250, 350]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for kernel_size in kernel_sizes:\n",
    "    for pooling in pooling_methods:\n",
    "        for opt_name, opt_fn in optimizers.items():\n",
    "            for epoch in num_epochs:\n",
    "                print(f\"Kernel: {kernel_size}, Pooling: {pooling}, Optimizer: {opt_name}, Epochs: {epoch}\")\n",
    "\n",
    "                model = CNN(kernel_size=kernel_size, pooling=pooling).to(device)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                optimizer = opt_fn(model.parameters(), lr=0.01)\n",
    "                scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "\n",
    "                train_losses, val_losses = train_model(\n",
    "                    model, optimizer, criterion, scheduler, num_epochs=epoch, early_stopping_patience=10\n",
    "                )\n",
    "\n",
    "                # Save results\n",
    "                results[(kernel_size, pooling, opt_name, epoch)] = (train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All experiments completed.\n",
      "Best Configuration: (5, 'max', 'SGD', 350), Best Validation Loss: 0.2343\n"
     ]
    }
   ],
   "source": [
    "# Save results to a file\n",
    "np.save('cnn_fashionmnist_results.npy', results)  # Ganti nama file untuk mencerminkan dataset\n",
    "print(\"All experiments completed.\")\n",
    "\n",
    "best_config = None\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for config, (train_losses, val_losses) in results.items():\n",
    "    min_val_loss = min(val_losses)\n",
    "    if min_val_loss < best_val_loss:\n",
    "        best_val_loss = min_val_loss\n",
    "        best_config = config\n",
    "\n",
    "print(f\"Best Configuration: {best_config}, Best Validation Loss: {best_val_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
